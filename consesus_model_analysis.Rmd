---
title: "Gitsbe Consensus Model Analysis"
output:
  html_document:
    df_print: paged
    #self_contained: no
---

## Intro

This notebook includes the ensemble model analysis performed on the 7500 
models generated by the `Gitsbe` module when running the DrugLogics 
computational pipeline for finding synergistic drug combinations. All these 
models were trained towards a consesus steady state signaling pattern. The 
input for the simulations and the output data are in the `consensus-2500` 
directory (the 2500 number denotes the number of simulations executed). The 
analysis will be presented step by step in the sections below.

The R version used for this analysis is: **3.4.4 (Someone to Lean On)**.

## Prerequisites

Firstly, we load the relevant helper functions:
```{r Helper functions}
# Set the working directory to the gitsbe-model-analysis folder: 
# setwd("pathTo/gitsbe-model-analysis")
source("Rscripts/input_functions.R")
source("Rscripts/analysis_functions.R")
source("Rscripts/plot_functions.R")
```

## Input

**Two inputs** are used in this analysis:

- The consensus **steady state** file from ~1000 cell lines, which lists the 
nodes of the signaling network along with their (predicted) activity state. The
consensus steady state has been calculated using 
[PARADIGM](https://doi.org/10.1093/bioinformatics/btq182) with the gene 
expression and CNV data from all cell lines of the 
[CCLE](https://www.sevenbridges.com/ccle/), while the majority rule was used to 
derive the activity state of each node - meaning that 
more than half 1's for one node in all cell lines would result in an activity 
state of 1 for that particular node in the consensus steady state profile.
- The **models** directory, which is the same as the models directory produced 
by `Gitsbe` and has one `.gitsbe` file per model that includes the **stable 
state** of the boolean model. Note that a model can have 1 stable state or none 
in our simulations - but the models used in this analysis have been selected 
through a genetic evolution algorithm in `Gitsbe` and so in the end, only those 
with 1 stable state have higher fitness values and remain in the later 
generations. Higher fitness here means a better match of a model's stable state
to the consensus steady state (a perfect match would result in a fitness of 1)
```{r Input: files}
consensus.dir = "consensus-2500"
data.dir = paste0(getwd(), "/", consensus.dir, "/")
steady.state.file = paste0(data.dir, "consensus_steady_state")
models.dir = paste0(data.dir, "models")
```
Now, we parse the data into proper R objects. First, we get the full stable 
state per model:
```{r Input: models stable states}
models = get.model.names(models.dir)
nodes  = get.node.names(models.dir)
models.stable.state = get.stable.state.from.models.dir(models.dir)

# example stable state of the first model (first 24 nodes)
head(models.stable.state[1, ], n = 24)
```
```{r Model Stats}
number.of.nodes = length(nodes)
number.of.models = length(models)
print(paste("Number of nodes:", number.of.nodes, "",
            "Number of models:", number.of.models))
```
Next, we get the consensus steady state. Note that the data and tools used (e.g. 
PARADIGM, CCLE) to derive the activity states of the network nodes produce further 
nodes that are present in the consensus steady state vector (but not in our 
network) and so they need to be discarded. Also, we reorder the columns of the 
consensus vector so as to match the order of nodes as they are in the 
`models.stable.state` object.
```{r Input: consensus steady state}
consensus.steady.state = get.consensus.steady.state(steady.state.file)
consensus.steady.state = 
  prune.to.common.nodes.and.reorder(consensus.steady.state, nodes)

# print the activity values of the first 24 nodes
head(consensus.steady.state, n = 24)
```

## Analysis

Continuing, we compare each of the models' stable state to the consensus one and 
find the percentage of matches for each model (fitness value). Then, we 
calculate the percentage of models that had a fitness match that was larger than
a threshold value (e.g. 0.55 or more than 55% match) and we plot the models' 
percentage results while ranging the fitness threshold value from 0 to 100%:
```{r Model Exceedance}
models.fitness = apply(models.stable.state, 1, function(state) {
  return(get.percentage.of.matches(state, consensus.steady.state)) 
})

print(paste("Minimum fitness:", min(models.fitness), "",
            "Maximum fitness:", max(models.fitness)))

fitness.range = seq(0, 1, 0.001)
models.percentage = sapply(fitness.range, function(fitness.threshold) {
  return(sum(models.fitness > fitness.threshold)/number.of.models)
})

y.axis.values = pretty(models.percentage)
plot(fitness.range, models.percentage, type = "l", yaxt = "n",
     xlab = "Fitness Threshold value",
     ylab = "Percentage of models",
     main = "Exceedance of models matching the Consensus Steady State")
axis(2, at = y.axis.values, lab = paste(y.axis.values * 100, "%"), las = 1)
```

As we can see in the figure above, the models generated by the evolutionary 
algorithm of `Gitsbe` - which are exactly the best fitting ones to the consensus
steady state patttern across all simulations - have a **fitness value between 
0.54 and 0.65**, meaning that in all models, more than half of the network nodes
stabilize in the same activity state as the one from the consensus steady state 
(100% of the models exhibit a match of more than 50% to the consensus steady 
state). Using the same logic and the figure above, we can see that 50% of the 
models exhibit a match of more than 63.4%. So, the models produced in this 
analysis, while trained to a specific steady state signaling pattern, they cover
a broader set of potential states, allowing thus a more robust drug response 
analysis in the respective module of the DrugLogics pipeline (`Drabme`).
```{r Distribution of fitness}
models.stable.state.compressed = apply(models.stable.state, 1, function(state) {
  return(paste(state, collapse = ""))
})

model.count.per.fitness = table(models.fitness)
number.of.unique.fitness.values = length(model.count.per.fitness)
number.of.unique.stable.states = length(unique(models.stable.state.compressed))

print(paste("Unique fitness values:", 
            number.of.unique.fitness.values, "",
            "Unique stable states found by the models:", 
            number.of.unique.stable.states))

y.axis.values = pretty(model.count.per.fitness)
plot(names(model.count.per.fitness), model.count.per.fitness, 
     type = "b",  yaxt = "n",
     xlab = "Fitness",
     ylab = "Number of models",
     main = "Distribution of fitness among models")
axis(2, at = y.axis.values, las = 1)
```

Note that there are **17 unique fitness values** included in the range [0.54, 
0.65], while the distribution of these values among the models can be seen in 
the figure above. Almost **3000 models had a fitness of ~0.64** to the consensus
steady state pattern, marking the area of the highest fitness models in the 
figure. Furthermore, the number of unique stable states found by the models are 
1330. This means that for a specific fitness value there will be many models that 
have a stable state corresponding to it (having the same percentage of matches 
for the activity states of the network nodes compared to the consensus state), 
but the activity of the nodes between these models will be different, allowing a
more diverse attractor landscape to match a specific fitness. To see the 
difference between the stable states of the produced models relating to fitness,
we produce the next heatmap:
```{r Fitness coloring}
rbPal = colorRampPalette(c("green", "black", "red"))
fitness.colors = rbPal(number.of.unique.fitness.values)[
  as.numeric(cut(models.fitness, breaks = number.of.unique.fitness.values))
]
names(fitness.colors) = names(models.fitness)

unique.fitness.colors = rbPal(number.of.unique.fitness.values)
unique.fitness.values = as.numeric(names(model.count.per.fitness))

title = "Color Palette"
xlab  = "Fitness score"
make.color.bar.plot(unique.fitness.colors, 
                    round(unique.fitness.values, digits = 3), 
                    title, xlab)
```

```{r Heatmap, fig.height=7, fig.width=7, dpi = 300}
heatmap.ss = heatmap(models.stable.state,
                     RowSideColors = fitness.colors,
                     scale = "none", labRow = NA,
                     cexCol = 0.4, margins = c(8,2))
```

In the heatmap above, an activity state equal to zero is represented with red 
color while an activity state equal to 1 with yellow. We note the prevalence of 
the highest fitness models across the heatmap as well their differences regarding
the activity states of the network nodes. Though this sample of 7500 models 
represents the *best* models generated through a genetic algorithm that results 
in higher fitness models getting selected because they are more *close* to the 
consensus steady state pattern, they still show diverse individual stable state 
pattern characteristics.
