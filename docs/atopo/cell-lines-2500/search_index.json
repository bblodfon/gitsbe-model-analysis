[
["index.html", "Biomarker Atopo Analysis Intro Note", " Biomarker Atopo Analysis John Zobolas Last updated: 23 September, 2019 Intro This document includes the analysis of 8 ensemble boolean datasets, each one corresponding to a different cell line input. In each case, we have a set of boolean models that were produced by the druglogics software pipeline module Gitsbe (\\(2500\\) simulations, choosing 3 best models out of each one, resulting thus in \\(7500\\) models in total for each cell line), using as input an automated topology (generated by the module Atopo) and a specific activity state profile for each cell line that the models were trained to. In the following chapters, we include more details for the inputs used and the analysis performed for each cell line to identify possible biomarkers. In the last chapter, we conlude the analysis by comparing the results between the 8 cell lines and the random model analysis (where the models were trained to fit a proliferation state) as well. The main purpose of this analysis is two-fold: Show how to use the functions of the emba R package (Zobolas 2019a) on a real dataset. This means that this analysis can be used as a long-form documentation (vignette) for the R package itself. Also, functions from the usefun R package (Zobolas 2019b) are used in this analysis. Investigate if there are common biomarkers between the 8 cell lines Note In the beginning, this analysis included various functions that I had implemented in multiple R scripts. Only later I thought to write a more generic R package (modularizing, extending, documenting and testing the code I already had) that would help me perform this kind of analysis on new boolean model datasets, and which would be easy to use and extend with more features. So, even though all the functions now used in this book are offered/exported by the emba package, I have written additional, more generic ones that execute (almost) the full analysis for each cell line in a simple line (the graphs you can generate from the output data). To refer to these generic analysis functions, check the corresponding documentation: ?emba::biomarker_tp_analysis ?emba::biomarker_mcc_analysis ?emba::biomarker_synergy_analysis An example use of two of these functions is on the Random Model Analysis chapter. "],
["a498-model-analysis.html", "A498 Model Analysis Input Performance Statistics Biomarker analysis", " A498 Model Analysis This chapter includes the ensemble model analysis performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). All these models were trained towards a specific steady state signaling pattern that was derived based on input data (gene expression, CNV) for the A498 cell line (Renal cell carcinoma (RCC), a kidney cancer), the use of the PARADIGM software (Vaske et al. 2010) and a topology that was build for simulating a cancer cell fate decision network. The input for the simulations and the output data are in the atopo/cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input We will define the name of the cell line which must match the name of the directory that has the input files inside the cell-lines-2500 directory. Our analysis in this chapter will be done on the data for the A498 cell line: cell.line = &quot;A498&quot; data.dir = paste0(getwd(), &quot;/&quot;, cell.line, &quot;/&quot;) Three inputs are used in this analysis: The model_predictions file which has for each model the prediction for each drug combination tested (0 = no synergy predicted, 1 = synergy predicted, NA = couldn’t find stable states in either the drug combination inhibited model or in any of the two single-drug inhibited models) The observed_synergies file which lists the drug combinations that were observed as synergistic for the particular cell line. The models directory, which is the same as the models directory produced by Gitsbe and has one .gitsbe file per model that includes this info: The stable state of the boolean model. Note that a model can have 1 stable state or none in our simulations - but the models used in this analysis have been selected through a genetic evolution algorithm in Gitsbe and so in the end, only those with 1 stable state have higher fitness values and remain in the later generations. Higher fitness here means a better match of a model’s stable state to the cell line derived steady state (a perfect match would result in a fitness of 1) The boolean equations of the model models.stable.state.file = paste0(data.dir, &quot;models_stable_state&quot;) observed.synergies.file = paste0(data.dir, &quot;observed_synergies&quot;) model.predictions.file = paste0(data.dir, &quot;model_predictions&quot;) models.equations.file = paste0(data.dir, &quot;models_equations&quot;) models.dir = paste0(data.dir, &quot;models&quot;) Now, we parse the data into proper R objects. First the synergy predictions per model: model.predictions = get_model_predictions(model.predictions.file) # Example: first model&#39;s synergy predictions (first 12 drug combinations) pretty_print_vector_names_and_values(model.predictions[1,], n = 12) 5Z-AK: NA, 5Z-BI: 0, 5Z-CT: NA, 5Z-PD: NA, 5Z-PI: 0, 5Z-PK: 0, 5Z-JN: 0, 5Z-D1: 0, 5Z-60: 0, 5Z-SB: 0, 5Z-RU: 0, 5Z-D4: 0 So, the model.predictions object has the models as rows and each column is a different drug combination that was tested in our simulations. drug.combinations.tested = colnames(model.predictions) models = rownames(model.predictions) nodes = get_node_names(models.dir) number.of.drug.comb.tested = length(drug.combinations.tested) number.of.models = length(models) number.of.nodes = length(nodes) print_model_and_drug_stats(number.of.drug.comb.tested, number.of.models, number.of.nodes, html.output = TRUE) Drug combinations tested: 153Number of models: 7500Number of nodes: 139 Next, we get the full stable state and the equations per model: models.stable.state = as.matrix( read.table(file = models.stable.state.file, check.names = FALSE) ) # Example: first model&#39;s stable state (first 12 nodes) pretty_print_vector_names_and_values(models.stable.state[1,], n = 12) MAP3K7: 1, MAP2K6: 1, MAP2K3: 1, NLK: 1, MAP3K4: 0, MAP2K4: 1, IKBKG: 1, IKBKB: 1, AKT1: 1, BRAF: 0, SMAD3: 1, DAB2IP: 0 The rows of the models.stable.state object represent the models while its columns are the names of the nodes (proteins, genes, etc.) of the cancer cell network under study. So, each model has one stable state which means that in every model, the nodes in the network have reached a state of either 0 (inhibition) or 1 (activation). models.equations = as.matrix( read.table(file = models.equations.file, check.names = FALSE) ) # Example: first model&#39;s link operators (first 12 nodes) pretty_print_vector_names_and_values(models.equations[1,], n = 12) MAP3K4: 0, MAP2K4: 1, IKBKB: 1, AKT1: 1, SMAD3: 1, GSK3B: 1, RAF1: 0, GAB2: 0, CTNNB1: 1, NR3C1: 0, CREB1: 1, RAC1: 1 For the models.equations, if we look at a specific row (a model so to speak), the columns (node names) correspond to the targets of regulation (and the network has been built so that every node is a target - i.e. it has other nodes activating and/or inhibiting it). The general form of a boolean equation is: general.equation = &quot;Target *= (Activator OR Activator OR...) AND NOT (Inhibitor OR Inhibitor OR...)&quot; pretty_print_bold_string(general.equation) Target *= (Activator OR Activator OR…) AND NOT (Inhibitor OR Inhibitor OR…) The difference between the models’ boolean equations is the link operator (OR NOT/AND NOT) which has been mutated (changed) through the evolutionary process of the genetic algorithm in Gitsbe. For example, if a model has for the column ERK_f (of the models.equations object) a value of 1, the correspoding equation is: ERK_f *= (MEK_f) OR NOT ((DUSP6) OR PPP1CA). A value of 0 would correspond to the same equation but having AND NOT as the link operator: ERK_f *= (MEK_f) AND NOT ((DUSP6) OR PPP1CA). Note that the equations that do not have link operators (meaning that they are the same for every model) are discarded (so less columns in this dataset) since in a later section we study only the equations whose link operators differentiate between the models. Lastly, the synergies observed for this particular cell line are: observed.synergies = get_observed_synergies( observed.synergies.file, drug.combinations.tested) number.of.observed.synergies = length(observed.synergies) pretty_print_vector_values(observed.synergies, vector.values.str = &quot;observed synergies&quot;) 17 observed synergies: AK-60, AK-BI, AK-D1, PI-D1, PD-G2, AK-G4, D1-G4, PI-JN, BI-P5, PD-P5, PI-P5, AK-PD, BI-PD, AK-PI, BI-PI, PD-PI, PK-ST Performance Statistics It will be interesting to know the percentage of the above observed synergies that were actually predicted by at least one of the models (there might be combinations that no model in our dataset could predict): # Split model.predictions to positive and negative results observed.model.predictions = get_observed_model_predictions(model.predictions, observed.synergies) unobserved.model.predictions = get_unobserved_model_predictions(model.predictions, observed.synergies) stopifnot(ncol(observed.model.predictions) + ncol(unobserved.model.predictions) == number.of.drug.comb.tested) number.of.models.per.observed.synergy = colSums(observed.model.predictions, na.rm = TRUE) predicted.synergies = names(which(number.of.models.per.observed.synergy &gt; 0)) # predicted synergies is a subset of the observed (positive) ones stopifnot(all(predicted.synergies %in% observed.synergies)) pretty_print_vector_values(predicted.synergies, vector.values.str = &quot;predicted synergies&quot;) 5 predicted synergies: AK-PD, BI-PD, BI-PI, PD-PI, PI-D1 predicted.synergies.percentage = 100 * length(predicted.synergies) / number.of.observed.synergies pretty_print_string(paste0(&quot;Percentage of True Positive predicted synergies: &quot;, specify_decimal(predicted.synergies.percentage, 2), &quot;%&quot;)) Percentage of True Positive predicted synergies: 29.41% So, for this particular cell line, there were indeed observed synergies that no model could predict (e.g.  AK-BI, AK-PI). Next, we would like to know the maximum number of observed synergies predicted by one model alone - can one model by itself predict all the true positive synergies predicted by all the models together or do we need many models to capture this diverse synergy landscape? To do that, we go even further and count the number of models that predict a specific set of observed synergies for every possible combination subset of the predicted.synergies object: # Find the number of predictive models for every synergy subset synergy.subset.stats = get_synergy_subset_stats(observed.model.predictions, predicted.synergies) # Bar plot of the number of models for every possible observed synergy combination set # Tweak the threshold.for.subset.removal and bottom.margin as desired make_barplot_on_synergy_subset_stats(synergy.subset.stats, threshold.for.subset.removal = 1, bottom.margin = 9, cell.line) From the above figure (where we excluded sets of synergies that were predicted by no model by setting the threshold.for.subset.removal value to 1) we observe that: Almost half of the models predict none of the observed synergies The PI-D1 synergy is predicted by almost all the rest of the models Next we calculate the maximum number of correctly predicted synergies (\\(TP\\) - True Positives) per model: # Count the predictions of the observed synergies per model (TP) models.synergies.tp = calculate_models_synergies_tp(observed.model.predictions) models.synergies.tp.stats = table(models.synergies.tp) # Bar plot of number of models vs correctly predicted synergies make_barplot_on_models_stats(models.synergies.tp.stats, cell.line, title = &quot;True Positive Synergy Predictions&quot;, xlab = &quot;Number of maximum correctly predicted synergies&quot;, ylab = &quot;Number of models&quot;) To summarize: There were only 2 models that predicted 3 synergies - the set BI-PD,PD-PI,PI-D1 - which is the maximum number of predicted synergies by an individual model No model could predict all 5 of the total predicted synergies The power of the ensemble model approach lies in the fact that (as we saw from the above figures) even though we may not have individual super models that can predict many observed drug combinations, there are many that predict at least one and which will be used by the drug response analysis module (Drabme) to better infer the synergistic drug combinations. It goes without saying though, that the existance of models that could predict more than a handful of synergies would be beneficial for any approach that performs drug response analysis on a multitude of models. Biomarker analysis Intro-Methods Now, we want to investigate and find possible important nodes - biomarkers - whose activity state either distinguishes good performance models from less performant ones (in terms of a performance metric - e.g. the true positive synergies predicted) or makes some models predict a specific synergy compared to others that can’t (but could predict other synergies). So, we devised two strategies to split the models in our disposal to good and bad ones (but not necessarily all of them), the demarcation line being either a performance metric (the number of \\(TP\\) or the Matthews Correlation Coefficient score) or the prediction or not of a specific synergy. Then, for each group of models (labeled as either good or bad) we find the average activity state of every node in the network (value between 0 and 1) and then we compute the average state difference for each node between the two groups: \\(\\forall i\\in nodes,mean(state_i)_{good} - mean(state_i)_{bad}\\). Our hypothesis is that if the absolute value of these average differences are larger than a user-defined threshold (e.g. 0.7) for a small number of nodes (the less the better) while for the rest of the nodes they remain close to zero, then the former nodes are considered the most important since they define the difference between the average bad model and the average good one in that particular case study. We will also deploy a network visualization method to observe these average differences. True Positives-based analysis Using our first strategy, we will split the models based on the number of true positive predictions. For example, the bad models will be the ones that predicted 0 \\(TP\\) synergies whereas the good models will be the ones that predicted 2 \\(TP\\) (we will denote the grouping as \\((0,2)\\)). This particular classification strategy will be used for every possible combination of the number of \\(TP\\) as given by the models.synergies.tp.stats object and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: diff.tp.results = get_avg_activity_diff_mat_based_on_tp_predictions( models, models.synergies.tp, models.stable.state) tp.densities = apply(abs(diff.tp.results), 1, density) make_multiple_density_plot(tp.densities, legend.title = &quot;True Positives&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) What we are actually looking for is density plots that are largely skewed to the right (so the average absolute differences of these nodes are close to zero) while there are a few areas of non-zero densities which are as close to 1 as possible. So, from the above graph, the density plots that fit this description are the ones marked as \\((1,3)\\) and \\((2,3)\\). We will visualize the nodes’ average state differences in a network graph (Csardi and Nepusz 2006), where the color of each node will denote how much more inhibited or active that node is, in the average good model vs the average bad one. The color of the edges will denote activation (green) or inhibition (red). We first build the network from the node topology (edge list): parent.dir = get_parent_dir(data.dir) topology.file = paste0(parent.dir, &quot;/topology&quot;) coordinates.file = paste0(parent.dir, &quot;/network_xy_coordinates&quot;) net = construct_network(topology.file, models.dir) # a static layout for plotting the same network always (igraph) # nice.layout = layout_nicely(net) nice.layout = as.matrix(read.table(coordinates.file)) In the next colored graphs we can identify the important nodes whose activity state can influence the true positive prediction performance (from 0 true positive synergies to a total of 3): plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,3)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (3 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(1,3)&quot;,], layout = nice.layout, title = &quot;Bad models (1 TP) vs Good models (3 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(2,3)&quot;,], layout = nice.layout, title = &quot;Bad models (2 TP) vs Good models (3 TP)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to the number of true positive synergies that they predict. Comparing the graphs above, we observe that there exist common nodes that maintain the same significant influence in all of the graphs. We set the threshold for the absolute significance level in average state differences to \\(0.7\\). A node will be marked as a biomarker (active or inhibited) if its activity state difference surpassed the aforementioned threshold (positively or negatively) for any of the tested groups (e.g. 2 \\(TP\\) vs 3 \\(TP\\)). So, the nodes that have to be in a more active state are: biomarkers.tp.active = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.tp.active) 13 nodes: PSEN1, CEBPA, MAPK8IP1, MAPK9, JAK1, TYK2, JAK3, IFNGR2/INFGR1, IFNGR1, PTPN11, IFNGR2, IL2RB, IL10RA Also, the nodes that have to be in a more inhibited state are: biomarkers.tp.inhibited = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.tp.inhibited) 17 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, STAT3, RXRA, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1, CASP9 We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.tp = get_common_values(biomarkers.tp.active, biomarkers.tp.inhibited) No common nodes MCC classification-based analysis The previous method to split the models based on the number of true positive predictions is a good metric for absolute performance but a very restricted one since it ignores the other values of the confusion matrix for each model (true negatives, false positives, false negatives). Also, since our dataset is imbalanced in the sense that out of the total drug combinations tested only a few of them are observed as synergistic (and in a hypothetical larger drug screening evaluation it will be even less true positives) we will now devise a method to split the models into different performance categories based on the value of the Matthews Correlation Coefficient (MCC) score which takes into account the balance ratios of all the four confusion matrix values: # Calculate Matthews Correlation Coefficient (MCC) for every model models.mcc = calculate_models_mcc(observed.model.predictions, unobserved.model.predictions, number.of.drug.comb.tested) models.mcc.stats = table(models.mcc, useNA = &quot;ifany&quot;) make_barplot_on_models_stats(models.mcc.stats, cell.line, title = &quot;MCC scores&quot;, xlab = &quot;MCC value&quot;, ylab = &quot;Number of models&quot;, cont.values = TRUE) From the above figure we observe that: There are no relatively bad models (MCC values close to -1) Most of the models (exluding the NaN category) perform a little better than random prediction (\\(MCC&gt;0\\)) There are models that had NaN value for the MCC score Given the MCC formula: \\(MCC = (TP\\cdot TN - FP\\cdot FN)/\\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}\\), we can see that the MCC value can be NaN because of zero devision. Two of the four values in the denominator represent the number of positive \\((TP+FN)\\) and negative \\((TN+FP)\\) observations which are non-zero for every model, since they correspond to the observed and non-obsered synergies in each case. The case where both \\(TN\\) and \\(FN\\) are zero is rare (if non-existent) because of the imbalanced dataset (large proportion of negatives) and the reason that logical models which report no negatives means that they should find fixpoint attractors for every possible drug combination perturbation which also is extremely unlikely. We can actually see that the NaN are produced by models that have both TP and FP equal to zero: models.synergies.fp = calculate_models_synergies_fp(unobserved.model.predictions) pretty_print_string(sum(models.synergies.tp + models.synergies.fp == 0)) 2074 Since these models could intentify no synergies (either correctly or wrongly), we decided to put them as the lowest performant category in our MCC-based analysis. To classify the models based on their MCC score (which takes values in the \\([-1, 1]\\) interval, NaN values excluded), we will perform a univariate k-means clustering to split the previously found MCC values to different classes (Wang and Song 2011). The MCC classification is presented with a histogram: num.of.classes = 5 mcc.class.ids = 1:num.of.classes models.mcc.no.nan = models.mcc[!is.nan(models.mcc)] models.mcc.no.nan.sorted = sort(models.mcc.no.nan) # find the clusters res = Ckmeans.1d.dp(x = models.mcc.no.nan.sorted, k = num.of.classes) models.cluster.ids = res$cluster plot_mcc_classes_hist(models.mcc.no.nan.sorted, models.cluster.ids, num.of.classes, mcc.class.ids) Note that in total we have 6 MCC classes, since the NaN MCC values constitute a class on its own. Following our first strategy, we will split the models based on the MCC performance metric score. For example, the bad models will be the ones that had a NaN MCC score \\((TP+FP = 0)\\) whereas the good models will be the ones that had an MCC score belonging to the first MCC class as seen in the histogram above. This particular classification strategy will be used for every possible combination of the MCC classes and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: # add NaN class (if applicable) if (sum(is.nan(models.mcc)) &gt; 0) { mcc.class.ids = append(mcc.class.ids, values = NaN, after = 0) } mcc.class.id.comb = t(combn(1:length(mcc.class.ids), 2)) diff.mcc.results = apply(mcc.class.id.comb, 1, function(comb) { return(get_avg_activity_diff_based_on_mcc_clustering( models.mcc, models.stable.state, mcc.class.ids, models.cluster.ids, class.id.low = comb[1], class.id.high = comb[2])) }) mcc.classes.comb.names = apply(mcc.class.id.comb, 1, function(comb) { return(paste0(&quot;(&quot;, mcc.class.ids[comb[1]], &quot;,&quot;, mcc.class.ids[comb[2]], &quot;)&quot;)) }) colnames(diff.mcc.results) = mcc.classes.comb.names diff.mcc.results = t(diff.mcc.results) mcc.densities = apply(abs(diff.mcc.results), 1, density) make_multiple_density_plot(mcc.densities, legend.title = &quot;MCC classes&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;, legend.size = 0.7) Many of the density plots above are of interest to us, since they are right skewed. Next, we visualize the average state differences with our network coloring method for 2 of the above cases, in order to identify the important nodes whose activity state can influence the prediction performance based on the MCC classification: plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(1,2)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 1) vs Good models (MCC Class: 2)&quot;) plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(3,4)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 3) vs Good models (MCC Class: 4)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to their MCC classification, using the same method as in the True Positives-based analysis section. First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 14 nodes: MYC, PTEN, JAK1, TYK2, JAK3, IFNGR2/INFGR1, IFNGR1, PTPN11, IFNGR2, IL2RB, IL10RA, SIRT2, CUL1, PPM1A Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 23 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, CREB1, STAT3, MYC, PtsIns(3,4,5)P3, MAPK8IP3, SIRT2, CUL1, PTK2, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1, CASP9 We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.mcc = get_common_values(biomarkers.mcc.active, biomarkers.mcc.inhibited) 3 nodes: MYC, SIRT2, CUL1 Since there are common nodes that were found to surpass the significance threshold level for the average state difference between two MCC classes both negatively and positively, we will keep these biomarkers only in the state which corresponds to the comparison of the highest classification categories. For example, if for the comparison of the MCC classes \\((1,3)\\) the node of interest had an average difference of \\(-0.89\\) while for the comparison of the \\((3,4)\\) MCC classes it had a value of \\(0.91\\), then we will keep that node only in the active biomarker list. The logic behind this is that the higher the MCC classes we compare, the more sure we are that the average state difference corresponds to a better indicator of the state of the biomarker found. # remove the common biomarkers biomarkers.mcc.active = biomarkers.mcc.active[!biomarkers.mcc.active %in% common.biomarkers.mcc] biomarkers.mcc.inhibited = biomarkers.mcc.inhibited[!biomarkers.mcc.inhibited %in% common.biomarkers.mcc] # find the proper state of the biomarkers and add them threshold = 0.7 for (biomarker in common.biomarkers.mcc) { logical.vector = diff.mcc.results[, biomarker] &gt; threshold | diff.mcc.results[, biomarker] &lt; -threshold comparison.index = max(which(logical.vector == TRUE)) if (diff.mcc.results[comparison.index, biomarker] &gt; threshold) biomarkers.mcc.active = append(biomarkers.mcc.active, biomarker) else biomarkers.mcc.inhibited = append(biomarkers.mcc.inhibited, biomarker) } # printing MCC biomarkers pretty_print_vector_values(biomarkers.mcc.active) 11 nodes: PTEN, JAK1, TYK2, JAK3, IFNGR2/INFGR1, IFNGR1, PTPN11, IFNGR2, IL2RB, IL10RA, PPM1A pretty_print_vector_values(biomarkers.mcc.inhibited) 23 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, CREB1, STAT3, PtsIns(3,4,5)P3, MAPK8IP3, PTK2, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1, CASP9, MYC, SIRT2, CUL1 Performance-related biomarkers Comparing the two methods we used for the classification of the models’ prediction performance (TP and MCC), we observe that there exist common biomarkers in both active and inhibited state cases. Also we note that there weren’t any common nodes reported as significantly active in one method which were significantly inhibited in the other, showing that the two methods’ results correlate well: common.biomarkers.mixed.1 = get_common_values(biomarkers.mcc.active, biomarkers.tp.inhibited) No common nodes common.biomarkers.mixed.2 = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.active) No common nodes To sum up, we list the common biomarkers that need to be in a more active state: biomarkers.perf.active = get_common_values(biomarkers.mcc.active, biomarkers.tp.active) 9 nodes: JAK1, TYK2, JAK3, IFNGR2/INFGR1, IFNGR1, PTPN11, IFNGR2, IL2RB, IL10RA We also list the common nodes that have to be in a more inhibited state: biomarkers.perf.inhibited = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.inhibited) 16 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, STAT3, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1, CASP9 Lastly, we will save these common performance-related biomarkers for further analysis and comparison with the results from all the different cell lines: biomarkers.dir = paste0(data.dir, &quot;biomarkers/&quot;) save_vector_to_file(vector = biomarkers.perf.active, file = paste0(biomarkers.dir, &quot;biomarkers_active&quot;)) save_vector_to_file(vector = biomarkers.perf.inhibited, file = paste0(biomarkers.dir, &quot;biomarkers_inhibited&quot;)) Equation-based analysis It will be interesting to see the different patterns in the form of the boolean equations (regarding the mutation of the link operator as mentioned in the Input section) when comparing higher performance models vs the low performant ones. We could also check if any of the biomarkers found above relate to a different link operator on average between models with different performance characteristics (e.g. higher predictive models should have the OR NOT as the link operator in a boolean equation where a specific biomarker is the regulation target) or if they constitute targets of exclusively activating nodes or inhibiting ones (an equation with no link operator). The performance metric we will first use to sort the models is the number of true positive predictions. We will now illustrate the heatmap of the models.equations object raw-order by the number of \\(TP\\) predictions: # order based on number of true positives models.synergies.tp.sorted = sort(models.synergies.tp) models.sorted = names(models.synergies.tp.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring eq.link.colors = c(&quot;red&quot;, &quot;lightyellow&quot;) eq.link.col.fun = colorRamp2(breaks = c(0, 1), colors = eq.link.colors) tp.values = sort(unique(models.synergies.tp)) tp.col.fun = colorRamp2(breaks = c(min(tp.values), max(tp.values)), colors = c(&quot;red&quot;, &quot;green&quot;)) # color biomarker names in the heatmap bottom.nodes.colors = rep(&quot;black&quot;, length(colnames(models.equations.sorted))) names(bottom.nodes.colors) = colnames(models.equations.sorted) bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.active] = &quot;blue&quot; bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.inhibited] = &quot;magenta&quot; # define the TP color bar tp.annot = rowAnnotation( tp = anno_simple(x = models.synergies.tp.sorted, col = tp.col.fun), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (TP sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = tp.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 3 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) tp.values = min(tp.values):max(tp.values) # maybe some integers are missing tp.legend = Legend(at = tp.values, title = &quot;TP&quot;, legend_gp = gpar(fill = tp.col.fun(tp.values))) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, tp.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the heatmap above, an equation whose link operator is AND NOT is represented with red color while an OR NOT link operator is represented with light yellow color. The targets whose equations do not have a link operator are not represented. The rows are ordered by the number of true positive predictions (ascending). We have colored the names of the network nodes that were also found as biomarkers (green color is used for the active biomarkers and red color for the inhibited biomarkers). We observe that: Most of the biomarkers are nodes that do not have both activators and inhibitors and so are absent from the above heatmap There doesn’t seem to exist a pattern between the models’ link operators and their corresponding performance (at least not for all of the nodes) when using the true positive predictions as a classifier for the models There exist a lot of target nodes that need to have the OR NOT link operator in their respective boolean equation in order for the corresponding logical model to show a higher number of true positive predictions. By assigning the OR NOT link operator to a target’s boolean regulation equation, we allow more flexibility to the target’s output active result state - meaning that the inhibitors play less role and the output state has a higher probability of being active - compared to assigning the AND NOT link operator to the equation We will also illustrate the heatmap of the models.equations object raw-order by the MCC score which is a better performance classifier. Models who had a NaN MCC score will be again placed in the lower performant category: # order based on the MCC value models.mcc.sorted = sort(models.mcc, na.last = FALSE) models.sorted = names(models.mcc.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring mcc.col.fun = colorRamp2(breaks = c(min(models.mcc.no.nan), max(models.mcc.no.nan)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define the MCC color bar mcc.annot = rowAnnotation( mcc = anno_simple(x = models.mcc.sorted, col = mcc.col.fun, na_col = &quot;black&quot;), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (MCC sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = mcc.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 4 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) mcc.legend = Legend(title = &quot;MCC&quot;, col_fun = mcc.col.fun) na.legend = Legend(labels = &quot;NA&quot;, legend_gp = gpar(fill = &quot;black&quot;)) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, mcc.legend, na.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the MCC-ordered heatmap above we observe that there is better correlation between the boolean equations’ link operators and the performance of a model compared to the \\(TP\\) classification. For example, the biomarkers STAT3 and JAK1 show distinguished patterns for the higher performance models (use of AND NOT and OR NOT link operators respectively) when the models are sorted by the MCC score. Synergy-prediction based analysis We will now use the second strategy to split the models, based on whether they predict a specific observed synergy or not. This will allow us to find biomarkers that affect the prediction of a specific synergy. For example, the good models could be the ones that predicted the hypothetical synergy A-B while the bad models all the rest that identified the particular combination as non-synergistic. In another case scenario, the good models could be those that predicted a triple synergy set A-B,C-D,A-C, while the bad models could be the ones that predicted the double synergy subset A-B,C-D (excluding the common models that predicted both the triple synergy set and subsequently its given subset). In such a case scenario, we want to find out which nodes are responsible for making the good models predict the extra synergy - in this hypothetical case the synergy A-C - demonstrating thus better model performance. Note that the models selected in each case as good or bad, could have predicted other synergies as well (correctly as \\(TP\\) or wrongly as \\(FP\\)) which means that the biomarker selection method could be somewhat innacurate, since we can’t really know the prediction of which extra synergy or synergies the biomarkers’ state affected. To account for this, we label as good models those that predict large synergy sets (so fewer models) which capture almost all the true positive predictions and also minimize the possible extra different synergies predicted by models of the same classification category (e.g. the good models). Starting with the first model classification method (prediction vs non-prediction of a particular synergy), we generate the density distribution of the nodes’ average state differences between the good and bad models for each predicted synergy: diff.predicted.synergies.results = sapply(predicted.synergies, function(drug.comb) { get_avg_activity_diff_based_on_specific_synergy_prediction( model.predictions, models.stable.state, drug.comb) }) diff.predicted.synergies.results = t(diff.predicted.synergies.results) densities = apply(abs(diff.predicted.synergies.results), 1, density) make_multiple_density_plot(densities, legend.title = &quot;Predicted Synergies&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Next, we will plot the biomarkers with the network visualization method (for all predicted synergies) and output the respective biomarkers in each case. The biomarker results for each predicted synergy will be stored for further comparison with the results from the other cell lines. threshold = 0.7 for (drug.comb in predicted.synergies) { diff = diff.predicted.synergies.results[drug.comb, ] biomarkers.active = diff[diff &gt; threshold] biomarkers.inhibited = diff[diff &lt; -threshold] save_vector_to_file(vector = biomarkers.active, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_active&quot;), with.row.names = TRUE) save_vector_to_file(vector = biomarkers.inhibited, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_inhibited&quot;), with.row.names = TRUE) } threshold = 0.7 for (drug.comb in predicted.synergies) { title.text = paste0(&quot;Prediction of &quot;, drug.comb, &quot; synergy: Good models vs Bad Models&quot;) diff = diff.predicted.synergies.results[drug.comb, ] plot_avg_state_diff_graph(net, diff, layout = nice.layout, title = title.text) } print_biomarkers_per_predicted_synergy(biomarkers.dir, predicted.synergies) Biomarkers for AK-PD synergy predictionActive biomarkers17 nodes: MAP3K11, FGFR1, TAB1, PTPN7, MAX, PIK3CA, MAPK8IP1, MAPK9, JAK1, TYK2, JAK3, IFNGR2/INFGR1, IFNGR1, PTPN11, IFNGR2, IL2RB, IL10RAInhibited biomarkers34 nodes: DLX5, NR3C1, MAPK14, RPS6KA5, STAT3, DUSP1, MAP2K2, PI3K, PIK3CG, RXRA, SOCS3, TGFB1, HSPA1A, SALL4, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1, FOXO3, CASP9Biomarkers for BI-PD synergy predictionActive biomarkers9 nodes: JAK1, TYK2, JAK3, IFNGR2/INFGR1, IFNGR1, PTPN11, IFNGR2, IL2RB, IL10RAInhibited biomarkers15 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, STAT3, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1Biomarkers for BI-PI synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: Biomarkers for PD-PI synergy predictionActive biomarkers0 nodes: Inhibited biomarkers1 node: CASP9Biomarkers for PI-D1 synergy predictionActive biomarkers2 nodes: PTEN, PPM1AInhibited biomarkers3 nodes: CREB1, PtsIns(3,4,5)P3, PTK2 We notice that for some predicted synergies the above method identified zero biomarkers. We will now study cases where the main goal is the better identification and/or refinement of the biomarkers responsible for allowing the models to predict one extra synergy from a specific synergy set. If we find biomarkers for a predicted synergy using this strategy, we compare them to the ones already found with the previous method and if none of them is common we just add the new ones to the list of biomarkers for that specific synergy. On the other hand, if the synergy-set comparison method identifies a subset of the previously found biomarkers for a specific synergy (one common node at least), we will only keep the later method’s biomarkers since we believe that the synergy-set prediction based method is more accurate at identifying biomarkers for a specific synergy because of the fewer models involved in each contrasting category which also minimizes the total false positive synergy predictions taken into account. Note that if the second method finds even more biomarkers than the first, we have the option to prune the end result to only the common biomarkers between the two methods. We will focus our analysis on the predicted synergies PD-PI, BI-PD and BI-PI. Synergy-set prediction based analysis PD-PI synergy The first use case will contrast the models that predicted the synergy set BI-PD,PD-PI,PI-D1 vs the models that predicted the double synergy subset BI-PD,PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PD-PI synergy: synergy.set.str = &quot;BI-PD,PD-PI,PI-D1&quot; synergy.subset.str = &quot;BI-PD,PI-D1&quot; diff.PD.PI = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PD.PI, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.PD.PI.active = diff.PD.PI[diff.PD.PI &gt; threshold] pretty_print_vector_names(biomarkers.PD.PI.active) 2 nodes: PSEN1, CEBPA Note that with the previous method of classifying the models (those that predict the PD-PI synergy and those that don’t), we couldn’t identify the 2 biomarkers that need to be in an active state for the prediction of this particular synergy. The inhibited biomarker is the same one as before: biomarkers.PD.PI.inhibited = diff.PD.PI[diff.PD.PI &lt; -threshold] pretty_print_vector_names(biomarkers.PD.PI.inhibited) 1 node: CASP9 Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;PD-PI&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.PD.PI.active, biomarkers.PD.PI.inhibited) BI-PD synergy The second use case will contrast the models that predicted the synergy set BI-PD,PD-PI,PI-D1 vs the models that predicted the double synergy subset PD-PI,PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-PD synergy: synergy.set.str = &quot;BI-PD,PD-PI,PI-D1&quot; synergy.subset.str = &quot;PD-PI,PI-D1&quot; diff.BI.PD = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PD, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.BI.PD.active = diff.BI.PD[diff.BI.PD &gt; threshold] pretty_print_vector_names(biomarkers.BI.PD.active) 4 nodes: PSEN1, CEBPA, MAPK8IP1, MAPK9 Note that these biomarkers are completely different from the ones found with the previous method. Same is true for the inhibited biomarkers: biomarkers.BI.PD.inhibited = diff.BI.PD[diff.BI.PD &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PD.inhibited) 1 node: RXRA Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-PD&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.PD.active, biomarkers.BI.PD.inhibited) BI-PI synergy The third use case will contrast the models that predicted the synergy set BI-PI,PI-D1 vs the models that predicted the single synergy PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-PI synergy: synergy.set.str = &quot;BI-PI,PI-D1&quot; synergy.subset.str = &quot;PI-D1&quot; diff.BI.PI = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.BI.PI.active = diff.BI.PI[diff.BI.PI &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active) 2 nodes: MAPK8IP1, MAPK9 We also report the inhibited biomarkers: biomarkers.BI.PI.inhibited = diff.BI.PI[diff.BI.PI &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited) 1 node: RXRA Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-PI&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.PI.active, biomarkers.BI.PI.inhibited) Biomarker results In this section, we will compare the biomarkers found per predicted synergy for this particular cell line as well as the performance biomarkers (notated as PERF in the heatmap below) which were found using the common results from the TP and MCC classification-based model analysis: # Biomarkers from sections: # `Synergy-prediction based analysis`, `Synergy-set prediction based analysis` biomarkers.synergy.res = get_synergy_biomarkers_from_dir(predicted.synergies, biomarkers.dir, models.dir) # store biomarkers in one file save_df_to_file(biomarkers.synergy.res, file = paste0(biomarkers.dir, &quot;biomarkers_per_synergy&quot;)) # Biomarkers from section: # `Performance-related biomarkers` biomarkers.res = add_row_to_ternary_df(df = biomarkers.synergy.res, values.pos = biomarkers.perf.active, values.neg = biomarkers.perf.inhibited, row.name = &quot;PERF&quot;) # prune nodes which are not found as biomarkers for any predicted synergy or # for better model performance biomarkers.res = prune_columns_from_df(biomarkers.res, value = 0) # define a coloring biomarkers.col.fun = colorRamp2(c(-1, 0, 1), c(&quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;)) biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.res), col = biomarkers.col.fun, column_title = paste0(&quot;Biomarker results (&quot;, cell.line, &quot;)&quot;), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = &quot;Predicted synergies&quot;, row_order = nrow(biomarkers.res):1, column_dend_height = unit(1, &quot;inches&quot;), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 7), row_names_side = &quot;left&quot;, heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) So, in general we observe that: A total of 63 nodes were found as biomarkers (for at least one synergy) We found a lot of biomarkers for some synergies, but very few for some others. Usually we wouldn’t expect too many biomarkers that are directly related to the prediction of a specific synergy. The abudance of (false positive) biomarkers for some synergies (e.g. AK-PD) relates to the model classification method used, which does not incorporate in its internal logic that the prediction of other synergies than the ones used for the grouping itself can affect the biomarker results obtained from it All the performance-related biomarkers (PERF) were also observed as biomarkers for the prediction of a specific synergy(ies) There exist common biomarkers across different predicted synergies, e.g. RXRA is a common inhibited biomarker across 3 synergistic drug combinations The results between the different synergies correlate in the sense that there is no active biomarker for a particular synergy that was found as inhibited in another and vise versa The biomarkers of the PI-D1 synergy are not shared with any of the other predicted synergies’ biomarkers The synergies BI-PD and AK-PD share many common biomarkers as well as with the performance-related biomarkers "],
["ags-model-analysis.html", "AGS Model Analysis Input Performance Statistics Biomarker analysis", " AGS Model Analysis This chapter includes the ensemble model analysis performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). All these models were trained towards a specific steady state signaling pattern that was derived based on input data (gene expression, CNV) for the AGS cell line (Gastric adenocarcinoma, a stomach cancer), the use of the PARADIGM software (Vaske et al. 2010) and a topology that was build for simulating a cancer cell fate decision network. The input for the simulations and the output data are in the cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input We will define the name of the cell line which must match the name of the directory that has the input files inside the cell-lines-2500 directory. Our analysis in this chapter will be done on the data for the AGS cell line: cell.line = &quot;AGS&quot; data.dir = paste0(getwd(), &quot;/&quot;, cell.line, &quot;/&quot;) Three inputs are used in this analysis: The model_predictions file which has for each model the prediction for each drug combination tested (0 = no synergy predicted, 1 = synergy predicted, NA = couldn’t find stable states in either the drug combination inhibited model or in any of the two single-drug inhibited models) The observed_synergies file which lists the drug combinations that were observed as synergistic for the particular cell line. The models directory, which is the same as the models directory produced by Gitsbe and has one .gitsbe file per model that includes this info: The stable state of the boolean model. Note that a model can have 1 stable state or none in our simulations - but the models used in this analysis have been selected through a genetic evolution algorithm in Gitsbe and so in the end, only those with 1 stable state have higher fitness values and remain in the later generations. Higher fitness here means a better match of a model’s stable state to the cell line derived steady state (a perfect match would result in a fitness of 1) The boolean equations of the model models.stable.state.file = paste0(data.dir, &quot;models_stable_state&quot;) observed.synergies.file = paste0(data.dir, &quot;observed_synergies&quot;) model.predictions.file = paste0(data.dir, &quot;model_predictions&quot;) models.equations.file = paste0(data.dir, &quot;models_equations&quot;) models.dir = paste0(data.dir, &quot;models&quot;) Now, we parse the data into proper R objects. First the synergy predictions per model: model.predictions = get_model_predictions(model.predictions.file) # Example: first model&#39;s synergy predictions (first 12 drug combinations) pretty_print_vector_names_and_values(model.predictions[1,], n = 12) 5Z-AK: 0, 5Z-BI: 0, 5Z-CT: 0, 5Z-PD: 0, 5Z-PI: 0, 5Z-PK: 0, 5Z-JN: 0, 5Z-D1: 0, 5Z-60: 0, 5Z-SB: 0, 5Z-RU: 0, 5Z-D4: 0 So, the model.predictions object has the models as rows and each column is a different drug combination that was tested in our simulations. drug.combinations.tested = colnames(model.predictions) models = rownames(model.predictions) nodes = get_node_names(models.dir) number.of.drug.comb.tested = length(drug.combinations.tested) number.of.models = length(models) number.of.nodes = length(nodes) print_model_and_drug_stats(number.of.drug.comb.tested, number.of.models, number.of.nodes, html.output = TRUE) Drug combinations tested: 153Number of models: 7500Number of nodes: 139 Next, we get the full stable state and the equations per model: models.stable.state = as.matrix( read.table(file = models.stable.state.file, check.names = FALSE) ) # Example: first model&#39;s stable state (first 12 nodes) pretty_print_vector_names_and_values(models.stable.state[1,], n = 12) MAP3K7: 1, MAP2K6: 1, MAP2K3: 1, NLK: 1, MAP3K4: 0, MAP2K4: 1, IKBKG: 1, IKBKB: 0, AKT1: 0, BRAF: 0, SMAD3: 0, DAB2IP: 1 The rows of the models.stable.state object represent the models while its columns are the names of the nodes (proteins, genes, etc.) of the cancer cell network under study. So, each model has one stable state which means that in every model, the nodes in the network have reached a state of either 0 (inhibition) or 1 (activation). models.equations = as.matrix( read.table(file = models.equations.file, check.names = FALSE) ) # Example: first model&#39;s link operators (first 12 nodes) pretty_print_vector_names_and_values(models.equations[1,], n = 12) MAP3K4: 0, MAP2K4: 1, IKBKB: 0, AKT1: 0, SMAD3: 0, GSK3B: 1, RAF1: 0, GAB2: 0, CTNNB1: 0, NR3C1: 0, CREB1: 0, RAC1: 1 For the models.equations, if we look at a specific row (a model so to speak), the columns (node names) correspond to the targets of regulation (and the network has been built so that every node is a target - i.e. it has other nodes activating and/or inhibiting it). The general form of a boolean equation is: general.equation = &quot;Target *= (Activator OR Activator OR...) AND NOT (Inhibitor OR Inhibitor OR...)&quot; pretty_print_bold_string(general.equation) Target *= (Activator OR Activator OR…) AND NOT (Inhibitor OR Inhibitor OR…) The difference between the models’ boolean equations is the link operator (OR NOT/AND NOT) which has been mutated (changed) through the evolutionary process of the genetic algorithm in Gitsbe. For example, if a model has for the column ERK_f (of the models.equations object) a value of 1, the correspoding equation is: ERK_f *= (MEK_f) OR NOT ((DUSP6) OR PPP1CA). A value of 0 would correspond to the same equation but having AND NOT as the link operator: ERK_f *= (MEK_f) AND NOT ((DUSP6) OR PPP1CA). Note that the equations that do not have link operators (meaning that they are the same for every model) are discarded (so less columns in this dataset) since in a later section we study only the equations whose link operators differentiate between the models. Lastly, the synergies observed for this particular cell line are: observed.synergies = get_observed_synergies( observed.synergies.file, drug.combinations.tested) number.of.observed.synergies = length(observed.synergies) pretty_print_vector_values(observed.synergies, vector.values.str = &quot;observed synergies&quot;) 6 observed synergies: AK-BI, 5Z-D1, AK-D1, BI-D1, PI-D1, PK-ST Performance Statistics It will be interesting to know the percentage of the above observed synergies that were actually predicted by at least one of the models (there might be combinations that no model in our dataset could predict): # Split model.predictions to positive and negative results observed.model.predictions = get_observed_model_predictions(model.predictions, observed.synergies) unobserved.model.predictions = get_unobserved_model_predictions(model.predictions, observed.synergies) stopifnot(ncol(observed.model.predictions) + ncol(unobserved.model.predictions) == number.of.drug.comb.tested) number.of.models.per.observed.synergy = colSums(observed.model.predictions, na.rm = TRUE) predicted.synergies = names(which(number.of.models.per.observed.synergy &gt; 0)) # predicted synergies is a subset of the observed (positive) ones stopifnot(all(predicted.synergies %in% observed.synergies)) pretty_print_vector_values(predicted.synergies, vector.values.str = &quot;predicted synergies&quot;) 2 predicted synergies: BI-D1, PI-D1 predicted.synergies.percentage = 100 * length(predicted.synergies) / number.of.observed.synergies pretty_print_string(paste0(&quot;Percentage of True Positive predicted synergies: &quot;, specify_decimal(predicted.synergies.percentage, 2), &quot;%&quot;)) Percentage of True Positive predicted synergies: 33.33% So, for this particular cell line, there were indeed observed synergies that no model could predict (e.g.  5Z-D1, AK-BI). Next, we would like to know the maximum number of observed synergies predicted by one model alone - can one model by itself predict all the true positive synergies predicted by all the models together or do we need many models to capture this diverse synergy landscape? To do that, we go even further and count the number of models that predict a specific set of observed synergies for every possible combination subset of the predicted.synergies object: # Find the number of predictive models for every synergy subset synergy.subset.stats = get_synergy_subset_stats(observed.model.predictions, predicted.synergies) # Bar plot of the number of models for every possible observed synergy combination set # Tweak the threshold.for.subset.removal and bottom.margin as desired make_barplot_on_synergy_subset_stats(synergy.subset.stats, threshold.for.subset.removal = 1, bottom.margin = 6, cell.line) From the above figure (where we excluded sets of synergies that were predicted by no model by setting the threshold.for.subset.removal value to 1) we observe that: Almost half of the models predict none of the observed synergies The PI-D1 synergy is predicted by almost all the rest of the models Next we calculate the maximum number of correctly predicted synergies (\\(TP\\) - True Positives) per model: # Count the predictions of the observed synergies per model (TP) models.synergies.tp = calculate_models_synergies_tp(observed.model.predictions) models.synergies.tp.stats = table(models.synergies.tp) # Bar plot of number of models vs correctly predicted synergies make_barplot_on_models_stats(models.synergies.tp.stats, cell.line, title = &quot;True Positive Synergy Predictions&quot;, xlab = &quot;Number of maximum correctly predicted synergies&quot;, ylab = &quot;Number of models&quot;) To summarize: There were 405 models that predicted 2 synergies - the set BI-D1,PI-D1 - which is the maximum number of predicted synergies by an individual model and also the number of total predicted synergies by all models together The power of the ensemble model approach lies in the fact that (as we saw from the above figures) even though we may not have individual super models that can predict many observed drug combinations, there are many that predict at least one and which will be used by the drug response analysis module (Drabme) to better infer the synergistic drug combinations. It goes without saying though, that the existance of models that could predict more than a handful of synergies would be beneficial for any approach that performs drug response analysis on a multitude of models. Biomarker analysis Intro-Methods Now, we want to investigate and find possible important nodes - biomarkers - whose activity state either distinguishes good performance models from less performant ones (in terms of a performance metric - e.g. the true positive synergies predicted) or makes some models predict a specific synergy compared to others that can’t (but could predict other synergies). So, we devised two strategies to split the models in our disposal to good and bad ones (but not necessarily all of them), the demarcation line being either a performance metric (the number of \\(TP\\) or the Matthews Correlation Coefficient score) or the prediction or not of a specific synergy. Then, for each group of models (labeled as either good or bad) we find the average activity state of every node in the network (value between 0 and 1) and then we compute the average state difference for each node between the two groups: \\(\\forall i\\in nodes,mean(state_i)_{good} - mean(state_i)_{bad}\\). Our hypothesis is that if the absolute value of these average differences are larger than a user-defined threshold (e.g. 0.7) for a small number of nodes (the less the better) while for the rest of the nodes they remain close to zero, then the former nodes are considered the most important since they define the difference between the average bad model and the average good one in that particular case study. We will also deploy a network visualization method to observe these average differences. True Positives-based analysis Using our first strategy, we will split the models based on the number of true positive predictions. For example, the bad models will be the ones that predicted 0 \\(TP\\) synergies whereas the good models will be the ones that predicted 2 \\(TP\\) (we will denote the grouping as \\((0,2)\\)). This particular classification strategy will be used for every possible combination of the number of \\(TP\\) as given by the models.synergies.tp.stats object and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: diff.tp.results = get_avg_activity_diff_mat_based_on_tp_predictions( models, models.synergies.tp, models.stable.state) tp.densities = apply(abs(diff.tp.results), 1, density) make_multiple_density_plot(tp.densities, legend.title = &quot;True Positives&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) What we are actually looking for is density plots that are largely skewed to the right (so the average absolute differences of these nodes are close to zero) while there are a few areas of non-zero densities which are as close to 1 as possible. So, from the above graph, the density plot that fits this description is the one marked as \\((1,2)\\). We will visualize the nodes’ average state differences in a network graph (Csardi and Nepusz 2006), where the color of each node will denote how much more inhibited or active that node is, in the average good model vs the average bad one. The color of the edges will denote activation (green) or inhibition (red). We first build the network from the node topology (edge list): parent.dir = get_parent_dir(data.dir) topology.file = paste0(parent.dir, &quot;/topology&quot;) coordinates.file = paste0(parent.dir, &quot;/network_xy_coordinates&quot;) net = construct_network(topology.file, models.dir) # a static layout for plotting the same network always (igraph) # nice.layout = layout_nicely(net) nice.layout = as.matrix(read.table(coordinates.file)) In the next colored graphs we can identify the important nodes whose activity state can influence the true positive prediction performance (from 0 true positive synergies to a total of 2): plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,1)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (1 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,2)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (2 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(1,2)&quot;,], layout = nice.layout, title = &quot;Bad models (1 TP) vs Good models (2 TP)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to the number of true positive synergies that they predict. Comparing the graphs above, we observe that there exist common nodes that maintain the same significant influence in all of the graphs. We set the threshold for the absolute significance level in average state differences to \\(0.7\\). A node will be marked as a biomarker (active or inhibited) if its activity state difference surpassed the aforementioned threshold (positively or negatively) for any of the tested groups (e.g. 1 \\(TP\\) vs 2 \\(TP\\)). We observe that using the above threshold (which was also used in the other cell lines), no biomarkers can be identified: biomarkers.tp.active = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;positive&quot; ) biomarkers.tp.inhibited = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.tp.active) 0 nodes: pretty_print_vector_values(biomarkers.tp.inhibited) 0 nodes: This happens mainly because of the low number of \\(TP\\) synergies (larger number of \\(TP\\) would allow better performance classification). So, for this cell line, we lower the significance threshold to \\(0.6\\) and thus identify these active biomarkers: biomarkers.tp.active = get_biomarkers_per_type( diff.tp.results, threshold = 0.6, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.tp.active) 3 nodes: MAPK14, RPS6KA5, DUSP1 The inhibited biomarkers that correspond to a \\(0.6\\) threshold, are: biomarkers.tp.inhibited = get_biomarkers_per_type( diff.tp.results, threshold = 0.6, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.tp.inhibited) 7 nodes: FGFR1, TAB1, CASP3, EGFR, PTPN7, MAX, JNK We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.tp = get_common_values(biomarkers.tp.active, biomarkers.tp.inhibited) No common nodes MCC classification-based analysis The previous method to split the models based on the number of true positive predictions is a good metric for absolute performance but a very restricted one since it ignores the other values of the confusion matrix for each model (true negatives, false positives, false negatives). Also, since our dataset is imbalanced in the sense that out of the total drug combinations tested only a few of them are observed as synergistic (and in a hypothetical larger drug screening evaluation it will be even less true positives) we will now devise a method to split the models into different performance categories based on the value of the Matthews Correlation Coefficient (MCC) score which takes into account the balance ratios of all the four confusion matrix values: # Calculate Matthews Correlation Coefficient (MCC) for every model models.mcc = calculate_models_mcc(observed.model.predictions, unobserved.model.predictions, number.of.drug.comb.tested) models.mcc.stats = table(models.mcc, useNA = &quot;ifany&quot;) make_barplot_on_models_stats(models.mcc.stats, cell.line, title = &quot;MCC scores&quot;, xlab = &quot;MCC value&quot;, ylab = &quot;Number of models&quot;, cont.values = TRUE, threshold = 42) Note that for presentation purposes in the figure above, we pruned some MCC-bars with lower model frequency values. We observe that: There are no relatively bad models (MCC values close to -1) Most of the models perform a little better than random prediction (\\(MCC&gt;0\\)) There are models that had NaN value for the MCC score (18 in total but we pruned the bars corresponding to less than 42 models) Given the MCC formula: \\(MCC = (TP\\cdot TN - FP\\cdot FN)/\\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}\\), we can see that the MCC value can be NaN because of zero devision. Two of the four values in the denominator represent the number of positive \\((TP+FN)\\) and negative \\((TN+FP)\\) observations which are non-zero for every model, since they correspond to the observed and non-obsered synergies in each case. The case where both \\(TN\\) and \\(FN\\) are zero is rare (if non-existent) because of the imbalanced dataset (large proportion of negatives) and the reason that logical models which report no negatives means that they should find fixpoint attractors for every possible drug combination perturbation which also is extremely unlikely. We can actually see that the NaN are produced by models that have both TP and FP equal to zero: models.synergies.fp = calculate_models_synergies_fp(unobserved.model.predictions) pretty_print_string(sum(models.synergies.tp + models.synergies.fp == 0)) 18 Since these models could intentify no synergies (either correctly or wrongly), we decided to put them as the lowest performant category in our MCC-based analysis. To classify the models based on their MCC score (which takes values in the \\([-1, 1]\\) interval, NaN values excluded), we will perform a univariate k-means clustering to split the previously found MCC values to different classes (Wang and Song 2011). The MCC classification is presented with a histogram: num.of.classes = 5 mcc.class.ids = 1:num.of.classes models.mcc.no.nan = models.mcc[!is.nan(models.mcc)] models.mcc.no.nan.sorted = sort(models.mcc.no.nan) # find the clusters res = Ckmeans.1d.dp(x = models.mcc.no.nan.sorted, k = num.of.classes) models.cluster.ids = res$cluster plot_mcc_classes_hist(models.mcc.no.nan.sorted, models.cluster.ids, num.of.classes, mcc.class.ids) Note that in total we will have 5 MCC classes in our subsequent analysis, excluding the NaN MCC class, because of the small number of models (18) that belong to this class compared to the other MCC class sizes. Following our first strategy, we will split the models based on the MCC performance metric score. For example, the bad models will be the ones that had an MCC score belonging to the first MCC class whereas the good models will be the ones that had an MCC score belonging to the third MCC class as seen in the histogram above. This particular classification strategy will be used for every possible combination of the MCC classes and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: mcc.class.id.comb = t(combn(1:length(mcc.class.ids), 2)) diff.mcc.results = apply(mcc.class.id.comb, 1, function(comb) { return(get_avg_activity_diff_based_on_mcc_clustering( models.mcc, models.stable.state, mcc.class.ids, models.cluster.ids, class.id.low = comb[1], class.id.high = comb[2])) }) mcc.classes.comb.names = apply(mcc.class.id.comb, 1, function(comb) { return(paste0(&quot;(&quot;, mcc.class.ids[comb[1]], &quot;,&quot;, mcc.class.ids[comb[2]], &quot;)&quot;)) }) colnames(diff.mcc.results) = mcc.classes.comb.names diff.mcc.results = t(diff.mcc.results) mcc.densities = apply(abs(diff.mcc.results), 1, density) make_multiple_density_plot(mcc.densities, legend.title = &quot;MCC classes&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Many of the density plots above are of interest to us, since they are right skewed. Next, we visualize the average state differences with our network coloring method for 2 of the above cases, in order to identify the important nodes whose activity state can influence the prediction performance based on the MCC classification: plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(3,4)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 3) vs Good models (MCC Class: 4)&quot;) plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(2,5)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 2) vs Good models (MCC Class: 5)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to their MCC classification, using the same method as in the True Positives-based analysis section. First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 3 nodes: MAPK14, RPS6KA5, DUSP1 Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 7 nodes: FGFR1, TAB1, CASP3, EGFR, PTPN7, MAX, JNK We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.mcc = get_common_values(biomarkers.mcc.active, biomarkers.mcc.inhibited) No common nodes Performance-related biomarkers Comparing the two methods we used for the classification of the models’ prediction performance (TP and MCC), we observe that there exist common biomarkers in both active and inhibited state cases. Also we note that there weren’t any common nodes reported as significantly active in one method which were significantly inhibited in the other, showing that the two methods’ results correlate well: common.biomarkers.mixed.1 = get_common_values(biomarkers.mcc.active, biomarkers.tp.inhibited) No common nodes common.biomarkers.mixed.2 = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.active) No common nodes To sum up, we list the common biomarkers that need to be in a more active state: biomarkers.perf.active = get_common_values(biomarkers.mcc.active, biomarkers.tp.active) 3 nodes: MAPK14, RPS6KA5, DUSP1 We also list the common nodes that have to be in a more inhibited state: biomarkers.perf.inhibited = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.inhibited) 7 nodes: FGFR1, TAB1, CASP3, EGFR, PTPN7, MAX, JNK Lastly, we will save these common performance-related biomarkers for further analysis and comparison with the results from all the different cell lines: biomarkers.dir = paste0(data.dir, &quot;biomarkers/&quot;) save_vector_to_file(vector = biomarkers.perf.active, file = paste0(biomarkers.dir, &quot;biomarkers_active&quot;)) save_vector_to_file(vector = biomarkers.perf.inhibited, file = paste0(biomarkers.dir, &quot;biomarkers_inhibited&quot;)) Equation-based analysis It will be interesting to see the different patterns in the form of the boolean equations (regarding the mutation of the link operator as mentioned in the Input section) when comparing higher performance models vs the low performant ones. We could also check if any of the biomarkers found above relate to a different link operator on average between models with different performance characteristics (e.g. higher predictive models should have the OR NOT as the link operator in a boolean equation where a specific biomarker is the regulation target) or if they constitute targets of exclusively activating nodes or inhibiting ones (an equation with no link operator). The performance metric we will first use to sort the models is the number of true positive predictions. We will now illustrate the heatmap of the models.equations object raw-order by the number of \\(TP\\) predictions: # order based on number of true positives models.synergies.tp.sorted = sort(models.synergies.tp) models.sorted = names(models.synergies.tp.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring eq.link.colors = c(&quot;red&quot;, &quot;lightyellow&quot;) eq.link.col.fun = colorRamp2(breaks = c(0, 1), colors = eq.link.colors) tp.values = sort(unique(models.synergies.tp)) tp.col.fun = colorRamp2(breaks = c(min(tp.values), max(tp.values)), colors = c(&quot;red&quot;, &quot;green&quot;)) # color biomarker names in the heatmap bottom.nodes.colors = rep(&quot;black&quot;, length(colnames(models.equations.sorted))) names(bottom.nodes.colors) = colnames(models.equations.sorted) bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.active] = &quot;blue&quot; bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.inhibited] = &quot;magenta&quot; # define the TP color bar tp.annot = rowAnnotation( tp = anno_simple(x = models.synergies.tp.sorted, col = tp.col.fun), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (TP sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = tp.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 3 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) tp.values = min(tp.values):max(tp.values) # maybe some integers are missing tp.legend = Legend(at = tp.values, title = &quot;TP&quot;, legend_gp = gpar(fill = tp.col.fun(tp.values))) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, tp.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the heatmap above, an equation whose link operator is AND NOT is represented with red color while an OR NOT link operator is represented with light yellow color. The targets whose equations do not have a link operator are not represented. The rows are ordered by the number of true positive predictions (ascending). We have colored the names of the network nodes that were also found as biomarkers (green color is used for the active biomarkers and red color for the inhibited biomarkers). We observe that: Most of the biomarkers are nodes that do not have both activators and inhibitors and so are absent from the above heatmap There doesn’t seem to exist a pattern between the models’ link operators and their corresponding performance (at least not for all of the nodes) when using the true positive predictions as a classifier for the models There exist a lot of target nodes that need to have the OR NOT link operator in their respective boolean equation in order for the corresponding logical model to show a higher number of true positive predictions. By assigning the OR NOT link operator to a target’s boolean regulation equation, we allow more flexibility to the target’s output active result state - meaning that the inhibitors play less role and the output state has a higher probability of being active - compared to assigning the AND NOT link operator to the equation We will also illustrate the heatmap of the models.equations object raw-order by the MCC score which is a better performance classifier. Models who had a NaN MCC score will be again placed in the lower performant category: # order based on the MCC value models.mcc.sorted = sort(models.mcc, na.last = FALSE) models.sorted = names(models.mcc.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring mcc.col.fun = colorRamp2(breaks = c(min(models.mcc.no.nan), max(models.mcc.no.nan)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define the MCC color bar mcc.annot = rowAnnotation( mcc = anno_simple(x = models.mcc.sorted, col = mcc.col.fun, na_col = &quot;black&quot;), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (MCC sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = mcc.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 4 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) mcc.legend = Legend(title = &quot;MCC&quot;, col_fun = mcc.col.fun) na.legend = Legend(labels = &quot;NA&quot;, legend_gp = gpar(fill = &quot;black&quot;)) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, mcc.legend, na.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the MCC-ordered heatmap above we observe that there is better correlation between the boolean equations’ link operators and the performance of a model compared to the \\(TP\\) classification. For example, the biomarkers EGFR and MAPK14 show distinguished patterns for the higher performance models (use of AND NOT and OR NOT link operators respectively) when the models are sorted by the MCC score. Synergy-prediction based analysis We will now use the second strategy to split the models, based on whether they predict a specific observed synergy or not. This will allow us to find biomarkers that affect the prediction of a specific synergy. For example, the good models could be the ones that predicted the hypothetical synergy A-B while the bad models all the rest that identified the particular combination as non-synergistic. In another case scenario, the good models could be those that predicted a triple synergy set A-B,C-D,A-C, while the bad models could be the ones that predicted the double synergy subset A-B,C-D (excluding the common models that predicted both the triple synergy set and subsequently its given subset). In such a case scenario, we want to find out which nodes are responsible for making the good models predict the extra synergy - in this hypothetical case the synergy A-C - demonstrating thus better model performance. Note that the models selected in each case as good or bad, could have predicted other synergies as well (correctly as \\(TP\\) or wrongly as \\(FP\\)) which means that the biomarker selection method could be somewhat innacurate, since we can’t really know the prediction of which extra synergy or synergies the biomarkers’ state affected. To account for this, we label as good models those that predict large synergy sets (so fewer models) which capture almost all the true positive predictions and also minimize the possible extra different synergies predicted by models of the same classification category (e.g. the good models). Starting with the first model classification method (prediction vs non-prediction of a particular synergy), we generate the density distribution of the nodes’ average state differences between the good and bad models for each predicted synergy: diff.predicted.synergies.results = sapply(predicted.synergies, function(drug.comb) { get_avg_activity_diff_based_on_specific_synergy_prediction( model.predictions, models.stable.state, drug.comb) }) diff.predicted.synergies.results = t(diff.predicted.synergies.results) densities = apply(abs(diff.predicted.synergies.results), 1, density) make_multiple_density_plot(densities, legend.title = &quot;Predicted Synergies&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Next, we will plot the biomarkers with the network visualization method (for all predicted synergies) and output the respective biomarkers in each case. The biomarker results for each predicted synergy will be stored for further comparison with the results from the other cell lines. threshold = 0.7 for (drug.comb in predicted.synergies) { diff = diff.predicted.synergies.results[drug.comb, ] biomarkers.active = diff[diff &gt; threshold] biomarkers.inhibited = diff[diff &lt; -threshold] save_vector_to_file(vector = biomarkers.active, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_active&quot;), with.row.names = TRUE) save_vector_to_file(vector = biomarkers.inhibited, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_inhibited&quot;), with.row.names = TRUE) } threshold = 0.7 for (drug.comb in predicted.synergies) { title.text = paste0(&quot;Prediction of &quot;, drug.comb, &quot; synergy: Good models vs Bad Models&quot;) diff = diff.predicted.synergies.results[drug.comb, ] plot_avg_state_diff_graph(net, diff, layout = nice.layout, title = title.text) } print_biomarkers_per_predicted_synergy(biomarkers.dir, predicted.synergies) Biomarkers for BI-D1 synergy predictionActive biomarkers3 nodes: MAPK14, RPS6KA5, DUSP1Inhibited biomarkers5 nodes: FGFR1, TAB1, PTPN7, MAX, JNKBiomarkers for PI-D1 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: We notice that for some predicted synergies the above method identified zero biomarkers. We will now study cases where the main goal is the better identification and/or refinement of the biomarkers responsible for allowing the models to predict one extra synergy from a specific synergy set. If we find biomarkers for a predicted synergy using this strategy, we compare them to the ones already found with the previous method and if none of them is common we just add the new ones to the list of biomarkers for that specific synergy. On the other hand, if the synergy-set comparison method identifies a subset of the previously found biomarkers for a specific synergy (one common node at least), we will only keep the later method’s biomarkers since we believe that the synergy-set prediction based method is more accurate at identifying biomarkers for a specific synergy because of the fewer models involved in each contrasting category which also minimizes the total false positive synergy predictions taken into account. Note that if the second method finds even more biomarkers than the first, we have the option to prune the end result to only the common biomarkers between the two methods. We will focus our analysis on the predicted synergies BI-D1 and PI-D1. Synergy-set prediction based analysis BI-D1 synergy The first use case will contrast the models that predicted the synergy set BI-D1,PI-D1 vs the models that predicted the single synergy subset PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-D1 synergy: synergy.set.str = &quot;BI-D1,PI-D1&quot; synergy.subset.str = &quot;PI-D1&quot; diff.BI.D1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.D1, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.BI.D1.active = diff.BI.D1[diff.BI.D1 &gt; threshold] pretty_print_vector_names(biomarkers.BI.D1.active) 3 nodes: MAPK14, RPS6KA5, DUSP1 Note that with the previous method of classifying the models (those that predict the BI-D1 synergy and those that don’t), we identified the same 3 active biomarkers. The inhibited biomarkers are the same ones also, with the addition of 2 more nodes: biomarkers.BI.D1.inhibited = diff.BI.D1[diff.BI.D1 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.D1.inhibited) 7 nodes: FGFR1, TAB1, CASP3, EGFR, PTPN7, MAX, JNK Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.D1.active, biomarkers.BI.D1.inhibited) PI-D1 synergy The second use case will contrast the models that predicted the synergy set BI-D1,PI-D1 vs the models that predicted the single synergy BI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PI-D1 synergy: synergy.set.str = &quot;BI-D1,PI-D1&quot; synergy.subset.str = &quot;BI-D1&quot; diff.PI.D1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1, layout = nice.layout, title = title.text) Sadly, no biomarkers were found at the \\(0.7\\) threshold in either active or inhibited states: biomarkers.PI.D1.active = diff.PI.D1[diff.PI.D1 &gt; threshold] pretty_print_vector_names(biomarkers.PI.D1.active) 0 nodes: biomarkers.PI.D1.inhibited = diff.PI.D1[diff.PI.D1 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.D1.inhibited) 0 nodes: Biomarker results In this section, we will compare the biomarkers found per predicted synergy for this particular cell line as well as the performance biomarkers (notated as PERF in the heatmap below) which were found using the common results from the TP and MCC classification-based model analysis: # Biomarkers from sections: # `Synergy-prediction based analysis`, `Synergy-set prediction based analysis` biomarkers.synergy.res = get_synergy_biomarkers_from_dir(predicted.synergies, biomarkers.dir, models.dir) # store biomarkers in one file save_df_to_file(biomarkers.synergy.res, file = paste0(biomarkers.dir, &quot;biomarkers_per_synergy&quot;)) # Biomarkers from section: # `Performance-related biomarkers` biomarkers.res = add_row_to_ternary_df(df = biomarkers.synergy.res, values.pos = biomarkers.perf.active, values.neg = biomarkers.perf.inhibited, row.name = &quot;PERF&quot;) # prune nodes which are not found as biomarkers for any predicted synergy or # for better model performance biomarkers.res = prune_columns_from_df(biomarkers.res, value = 0) # define a coloring biomarkers.col.fun = colorRamp2(c(-1, 0, 1), c(&quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;)) biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.res), col = biomarkers.col.fun, column_title = paste0(&quot;Biomarker results (&quot;, cell.line, &quot;)&quot;), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = &quot;Predicted synergies&quot;, row_order = nrow(biomarkers.res):1, column_dend_height = unit(0.5, &quot;inches&quot;), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 10), row_names_side = &quot;left&quot;, heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) So, in general we observe that: A total of 10 nodes were found as biomarkers (for at least one synergy) We couldn’t indentify any biomarkers at the \\(0.7\\) threshold for the PI-D1 synergy, while for the BI-D1 synergy we found 10 biomarkers. Usually we wouldn’t expect too many biomarkers that are directly related to the prediction of a specific synergy. The abudance of (false positive) biomarkers for some synergies (e.g. BI-D1) relates to the model classification method used, which does not incorporate in its internal logic that the prediction of other synergies than the ones used for the grouping itself can affect the biomarker results obtained from it The performance-related biomarkers (PERF) were exactly the same ones found for the prediction of the BI-D1 synergy "],
["du145-model-analysis.html", "DU145 Model Analysis Input Performance Statistics Biomarker analysis", " DU145 Model Analysis This chapter includes the ensemble model analysis performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). All these models were trained towards a specific steady state signaling pattern that was derived based on input data (gene expression, CNV) for the DU145 cell line (prostate carcinoma/cancer), the use of the PARADIGM software (Vaske et al. 2010) and a topology that was build for simulating a cancer cell fate decision network. The input for the simulations and the output data are in the cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input We will define the name of the cell line which must match the name of the directory that has the input files inside the cell-lines-2500 directory. Our analysis in this chapter will be done on the data for the DU145 cell line: cell.line = &quot;DU145&quot; data.dir = paste0(getwd(), &quot;/&quot;, cell.line, &quot;/&quot;) Three inputs are used in this analysis: The model_predictions file which has for each model the prediction for each drug combination tested (0 = no synergy predicted, 1 = synergy predicted, NA = couldn’t find stable states in either the drug combination inhibited model or in any of the two single-drug inhibited models) The observed_synergies file which lists the drug combinations that were observed as synergistic for the particular cell line. The models directory, which is the same as the models directory produced by Gitsbe and has one .gitsbe file per model that includes this info: The stable state of the boolean model. Note that a model can have 1 stable state or none in our simulations - but the models used in this analysis have been selected through a genetic evolution algorithm in Gitsbe and so in the end, only those with 1 stable state have higher fitness values and remain in the later generations. Higher fitness here means a better match of a model’s stable state to the cell line derived steady state (a perfect match would result in a fitness of 1) The boolean equations of the model models.stable.state.file = paste0(data.dir, &quot;models_stable_state&quot;) observed.synergies.file = paste0(data.dir, &quot;observed_synergies&quot;) model.predictions.file = paste0(data.dir, &quot;model_predictions&quot;) models.equations.file = paste0(data.dir, &quot;models_equations&quot;) models.dir = paste0(data.dir, &quot;models&quot;) Now, we parse the data into proper R objects. First the synergy predictions per model: model.predictions = get_model_predictions(model.predictions.file) # Example: first model&#39;s synergy predictions (first 12 drug combinations) pretty_print_vector_names_and_values(model.predictions[1,], n = 12) 5Z-AK: 0, 5Z-BI: 0, 5Z-CT: 0, 5Z-PD: 0, 5Z-PI: 0, 5Z-PK: 0, 5Z-JN: 0, 5Z-D1: 0, 5Z-60: 0, 5Z-SB: 0, 5Z-RU: 0, 5Z-D4: 0 So, the model.predictions object has the models as rows and each column is a different drug combination that was tested in our simulations. drug.combinations.tested = colnames(model.predictions) models = rownames(model.predictions) nodes = get_node_names(models.dir) number.of.drug.comb.tested = length(drug.combinations.tested) number.of.models = length(models) number.of.nodes = length(nodes) print_model_and_drug_stats(number.of.drug.comb.tested, number.of.models, number.of.nodes, html.output = TRUE) Drug combinations tested: 153Number of models: 7500Number of nodes: 139 Next, we get the full stable state and the equations per model: models.stable.state = as.matrix( read.table(file = models.stable.state.file, check.names = FALSE) ) # Example: first model&#39;s stable state (first 12 nodes) pretty_print_vector_names_and_values(models.stable.state[1,], n = 12) MAP3K7: 1, MAP2K6: 1, MAP2K3: 1, NLK: 1, MAP3K4: 1, MAP2K4: 1, IKBKG: 1, IKBKB: 1, AKT1: 0, BRAF: 1, SMAD3: 1, DAB2IP: 1 The rows of the models.stable.state object represent the models while its columns are the names of the nodes (proteins, genes, etc.) of the cancer cell network under study. So, each model has one stable state which means that in every model, the nodes in the network have reached a state of either 0 (inhibition) or 1 (activation). models.equations = as.matrix( read.table(file = models.equations.file, check.names = FALSE) ) # Example: first model&#39;s link operators (first 12 nodes) pretty_print_vector_names_and_values(models.equations[1,], n = 12) MAP3K4: 0, MAP2K4: 0, IKBKB: 1, AKT1: 0, SMAD3: 1, GSK3B: 0, RAF1: 1, GAB2: 0, CTNNB1: 1, NR3C1: 0, CREB1: 0, RAC1: 1 For the models.equations, if we look at a specific row (a model so to speak), the columns (node names) correspond to the targets of regulation (and the network has been built so that every node is a target - i.e. it has other nodes activating and/or inhibiting it). The general form of a boolean equation is: general.equation = &quot;Target *= (Activator OR Activator OR...) AND NOT (Inhibitor OR Inhibitor OR...)&quot; pretty_print_bold_string(general.equation) Target *= (Activator OR Activator OR…) AND NOT (Inhibitor OR Inhibitor OR…) The difference between the models’ boolean equations is the link operator (OR NOT/AND NOT) which has been mutated (changed) through the evolutionary process of the genetic algorithm in Gitsbe. For example, if a model has for the column ERK_f (of the models.equations object) a value of 1, the correspoding equation is: ERK_f *= (MEK_f) OR NOT ((DUSP6) OR PPP1CA). A value of 0 would correspond to the same equation but having AND NOT as the link operator: ERK_f *= (MEK_f) AND NOT ((DUSP6) OR PPP1CA). Note that the equations that do not have link operators (meaning that they are the same for every model) are discarded (so less columns in this dataset) since in a later section we study only the equations whose link operators differentiate between the models. Lastly, the synergies observed for this particular cell line are: observed.synergies = get_observed_synergies( observed.synergies.file, drug.combinations.tested) number.of.observed.synergies = length(observed.synergies) pretty_print_vector_values(observed.synergies, vector.values.str = &quot;observed synergies&quot;) 12 observed synergies: AK-BI, 5Z-CT, JN-D1, PI-D1, AK-D4, AK-G4, AK-JN, BI-JN, JN-P5, BI-PI, JN-ST, PK-ST Performance Statistics It will be interesting to know the percentage of the above observed synergies that were actually predicted by at least one of the models (there might be combinations that no model in our dataset could predict): # Split model.predictions to positive and negative results observed.model.predictions = get_observed_model_predictions(model.predictions, observed.synergies) unobserved.model.predictions = get_unobserved_model_predictions(model.predictions, observed.synergies) stopifnot(ncol(observed.model.predictions) + ncol(unobserved.model.predictions) == number.of.drug.comb.tested) number.of.models.per.observed.synergy = colSums(observed.model.predictions, na.rm = TRUE) predicted.synergies = names(which(number.of.models.per.observed.synergy &gt; 0)) # predicted synergies is a subset of the observed (positive) ones stopifnot(all(predicted.synergies %in% observed.synergies)) pretty_print_vector_values(predicted.synergies, vector.values.str = &quot;predicted synergies&quot;) 3 predicted synergies: BI-PI, BI-JN, PI-D1 predicted.synergies.percentage = 100 * length(predicted.synergies) / number.of.observed.synergies pretty_print_string(paste0(&quot;Percentage of True Positive predicted synergies: &quot;, specify_decimal(predicted.synergies.percentage, 2), &quot;%&quot;)) Percentage of True Positive predicted synergies: 25.00% So, for this particular cell line, there were indeed observed synergies that no model could predict (e.g.  5Z-CT, AK-BI). Next, we would like to know the maximum number of observed synergies predicted by one model alone - can one model by itself predict all the true positive synergies predicted by all the models together or do we need many models to capture this diverse synergy landscape? To do that, we go even further and count the number of models that predict a specific set of observed synergies for every possible combination subset of the predicted.synergies object: # Find the number of predictive models for every synergy subset synergy.subset.stats = get_synergy_subset_stats(observed.model.predictions, predicted.synergies) # Bar plot of the number of models for every possible observed synergy combination set # Tweak the threshold.for.subset.removal and bottom.margin as desired make_barplot_on_synergy_subset_stats(synergy.subset.stats, threshold.for.subset.removal = 1, bottom.margin = 6, cell.line) From the above figure (where we excluded sets of synergies that were predicted by no model by setting the threshold.for.subset.removal value to 1) we observe that: Most of the models predict none of the observed synergies The PI-D1 synergy is predicted by almost all the rest of the models Next we calculate the maximum number of correctly predicted synergies (\\(TP\\) - True Positives) per model: # Count the predictions of the observed synergies per model (TP) models.synergies.tp = calculate_models_synergies_tp(observed.model.predictions) models.synergies.tp.stats = table(models.synergies.tp) # Bar plot of number of models vs correctly predicted synergies make_barplot_on_models_stats(models.synergies.tp.stats, cell.line, title = &quot;True Positive Synergy Predictions&quot;, xlab = &quot;Number of maximum correctly predicted synergies&quot;, ylab = &quot;Number of models&quot;) To summarize: There were 631 models that predicted 2 synergies - either the set BI-PI,PI-D1 or the BI-JN,PI-D1 synergy set - which is the maximum number of predicted synergies by an individual model No model could predict all 3 of the total predicted synergies The power of the ensemble model approach lies in the fact that (as we saw from the above figures) even though we may not have individual super models that can predict many observed drug combinations, there are many that predict at least one and which will be used by the drug response analysis module (Drabme) to better infer the synergistic drug combinations. It goes without saying though, that the existance of models that could predict more than a handful of synergies would be beneficial for any approach that performs drug response analysis on a multitude of models. Biomarker analysis Intro-Methods Now, we want to investigate and find possible important nodes - biomarkers - whose activity state either distinguishes good performance models from less performant ones (in terms of a performance metric - e.g. the true positive synergies predicted) or makes some models predict a specific synergy compared to others that can’t (but could predict other synergies). So, we devised two strategies to split the models in our disposal to good and bad ones (but not necessarily all of them), the demarcation line being either a performance metric (the number of \\(TP\\) or the Matthews Correlation Coefficient score) or the prediction or not of a specific synergy. Then, for each group of models (labeled as either good or bad) we find the average activity state of every node in the network (value between 0 and 1) and then we compute the average state difference for each node between the two groups: \\(\\forall i\\in nodes,mean(state_i)_{good} - mean(state_i)_{bad}\\). Our hypothesis is that if the absolute value of these average differences are larger than a user-defined threshold (e.g. 0.7) for a small number of nodes (the less the better) while for the rest of the nodes they remain close to zero, then the former nodes are considered the most important since they define the difference between the average bad model and the average good one in that particular case study. We will also deploy a network visualization method to observe these average differences. True Positives-based analysis Using our first strategy, we will split the models based on the number of true positive predictions. For example, the bad models will be the ones that predicted 0 \\(TP\\) synergies whereas the good models will be the ones that predicted 2 \\(TP\\) (we will denote the grouping as \\((0,2)\\)). This particular classification strategy will be used for every possible combination of the number of \\(TP\\) as given by the models.synergies.tp.stats object and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: diff.tp.results = get_avg_activity_diff_mat_based_on_tp_predictions( models, models.synergies.tp, models.stable.state) tp.densities = apply(abs(diff.tp.results), 1, density) make_multiple_density_plot(tp.densities, legend.title = &quot;True Positives&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) What we are actually looking for is density plots that are largely skewed to the right (so the average absolute differences of these nodes are close to zero) while there are a few areas of non-zero densities which are as close to 1 as possible. So, from the above graph, the density plot that best fit this description is the one marked as \\((1,2)\\). We will visualize the nodes’ average state differences in a network graph (Csardi and Nepusz 2006), where the color of each node will denote how much more inhibited or active that node is, in the average good model vs the average bad one. The color of the edges will denote activation (green) or inhibition (red). We first build the network from the node topology (edge list): parent.dir = get_parent_dir(data.dir) topology.file = paste0(parent.dir, &quot;/topology&quot;) coordinates.file = paste0(parent.dir, &quot;/network_xy_coordinates&quot;) net = construct_network(topology.file, models.dir) # a static layout for plotting the same network always (igraph) # nice.layout = layout_nicely(net) nice.layout = as.matrix(read.table(coordinates.file)) In the next colored graphs we can identify the important nodes whose activity state can influence the true positive prediction performance (from 0 true positive synergies to a total of 2): plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,1)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (1 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,2)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (2 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(1,2)&quot;,], layout = nice.layout, title = &quot;Bad models (1 TP) vs Good models (2 TP)&quot;) We observe from the above graphs that there are no significant nodes that characterize the difference between any two TP-based performance classification groups (none of the nodes show an absolute average state difference larger than 0.4). In order to find biomarkers, we will use a different performance evaluation metric to classify the models rather than the simple number of \\(TP\\) predictions. MCC classification-based analysis The previous method to split the models based on the number of true positive predictions is a good metric for absolute performance but a very restricted one since it ignores the other values of the confusion matrix for each model (true negatives, false positives, false negatives). Also, since our dataset is imbalanced in the sense that out of the total drug combinations tested only a few of them are observed as synergistic (and in a hypothetical larger drug screening evaluation it will be even less true positives) we will now devise a method to split the models into different performance categories based on the value of the Matthews Correlation Coefficient (MCC) score which takes into account the balance ratios of all the four confusion matrix values: # Calculate Matthews Correlation Coefficient (MCC) for every model models.mcc = calculate_models_mcc(observed.model.predictions, unobserved.model.predictions, number.of.drug.comb.tested) models.mcc.stats = table(models.mcc, useNA = &quot;ifany&quot;) make_barplot_on_models_stats(models.mcc.stats, cell.line, title = &quot;MCC scores&quot;, xlab = &quot;MCC value&quot;, ylab = &quot;Number of models&quot;, cont.values = TRUE) From the above figure we observe that: There are no relatively bad models (MCC values close to -1) Most of the models (exluding the NaN category) perform a little better than random prediction (\\(MCC&gt;0\\)) There are models that had NaN value for the MCC score Given the MCC formula: \\(MCC = (TP\\cdot TN - FP\\cdot FN)/\\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}\\), we can see that the MCC value can be NaN because of zero devision. Two of the four values in the denominator represent the number of positive \\((TP+FN)\\) and negative \\((TN+FP)\\) observations which are non-zero for every model, since they correspond to the observed and non-obsered synergies in each case. The case where both \\(TN\\) and \\(FN\\) are zero is rare (if non-existent) because of the imbalanced dataset (large proportion of negatives) and the reason that logical models which report no negatives means that they should find fixpoint attractors for every possible drug combination perturbation which also is extremely unlikely. We can actually see that the NaN are produced by models that have both TP and FP equal to zero: models.synergies.fp = calculate_models_synergies_fp(unobserved.model.predictions) pretty_print_string(sum(models.synergies.tp + models.synergies.fp == 0)) 1779 Since these models could intentify no synergies (either correctly or wrongly), we decided to put them as the lowest performant category in our MCC-based analysis. To classify the models based on their MCC score (which takes values in the \\([-1, 1]\\) interval, NaN values excluded), we will perform a univariate k-means clustering to split the previously found MCC values to different classes (Wang and Song 2011). The MCC classification is presented with a histogram: num.of.classes = 5 mcc.class.ids = 1:num.of.classes models.mcc.no.nan = models.mcc[!is.nan(models.mcc)] models.mcc.no.nan.sorted = sort(models.mcc.no.nan) # find the clusters res = Ckmeans.1d.dp(x = models.mcc.no.nan.sorted, k = num.of.classes) models.cluster.ids = res$cluster plot_mcc_classes_hist(models.mcc.no.nan.sorted, models.cluster.ids, num.of.classes, mcc.class.ids) Note that in total we have 6 MCC classes, since the NaN MCC values constitute a class on its own. Following our first strategy, we will split the models based on the MCC performance metric score. For example, the bad models will be the ones that had a NaN MCC score \\((TP+FP = 0)\\) whereas the good models will be the ones that had an MCC score belonging to the first MCC class as seen in the histogram above. This particular classification strategy will be used for every possible combination of the MCC classes and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: # add NaN class (if applicable) if (sum(is.nan(models.mcc)) &gt; 0) { mcc.class.ids = append(mcc.class.ids, values = NaN, after = 0) } mcc.class.id.comb = t(combn(1:length(mcc.class.ids), 2)) diff.mcc.results = apply(mcc.class.id.comb, 1, function(comb) { return(get_avg_activity_diff_based_on_mcc_clustering( models.mcc, models.stable.state, mcc.class.ids, models.cluster.ids, class.id.low = comb[1], class.id.high = comb[2])) }) mcc.classes.comb.names = apply(mcc.class.id.comb, 1, function(comb) { return(paste0(&quot;(&quot;, mcc.class.ids[comb[1]], &quot;,&quot;, mcc.class.ids[comb[2]], &quot;)&quot;)) }) colnames(diff.mcc.results) = mcc.classes.comb.names diff.mcc.results = t(diff.mcc.results) mcc.densities = apply(abs(diff.mcc.results), 1, density) make_multiple_density_plot(mcc.densities, legend.title = &quot;MCC classes&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;, legend.size = 0.8) Many of the density plots above are of interest to us, since they are right skewed. Next, we visualize the average state differences with our network coloring method for 2 of the above cases, in order to identify the important nodes whose activity state can influence the prediction performance based on the MCC classification: plot_avg_link_operator_diff_graph(net, diff.mcc.results[&quot;(NaN,5)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: NaN) vs Good models (MCC Class: 5)&quot;) plot_avg_link_operator_diff_graph(net, diff.mcc.results[&quot;(2,4)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 2) vs Good models (MCC Class: 4)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to their MCC classification. To do that, we set the threshold for the absolute significance level in average state differences to \\(0.7\\). A node will be marked as a biomarker (active or inhibited) if its activity state difference surpassed the aforementioned threshold (positively or negatively) for any of the tested groups (e.g. 1st MCC Class vs 2nd MCC Class). First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 29 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, BRAF, DAB2IP, PPP1CA, AR, RAF1, CHEK1, RARA, SH3RF1, PTPN1, IRAK1, STAT3, ROR2, PHLPP1, MAML1, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, LCK, TGFBR1, TRAF6, RHOA, PIK3R1 Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 23 nodes: AKT1, GSK3B, BRCA1, CHUK, PRKACA, TTC3, BMI1, AKT2, AKT3, APC, LRP6, JAK1, TYK2, JAK3, IFNGR2/INFGR1, IFNGR1, PTPN11, IFNGR2, IL2RB, IL10RA, SYK, MAP4K1, VAV1 We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.mcc = get_common_values(biomarkers.mcc.active, biomarkers.mcc.inhibited) No common nodes Performance-related biomarkers Since the TP-based classification method didn’t produce any results and we also believe that the MCC score better captures the performance categories within our imbalanced dataset, we will use the results from the MCC analysis as the performance biomarkers. Lastly, we will save these performance-related biomarkers for further analysis and comparison with the results from all the different cell lines: biomarkers.dir = paste0(data.dir, &quot;biomarkers/&quot;) biomarkers.perf.active = biomarkers.mcc.active biomarkers.perf.inhibited = biomarkers.mcc.inhibited save_vector_to_file(vector = biomarkers.perf.active, file = paste0(biomarkers.dir, &quot;biomarkers_active&quot;)) save_vector_to_file(vector = biomarkers.perf.inhibited, file = paste0(biomarkers.dir, &quot;biomarkers_inhibited&quot;)) Equation-based analysis It will be interesting to see the different patterns in the form of the boolean equations (regarding the mutation of the link operator as mentioned in the Input section) when comparing higher performance models vs the low performant ones. We could also check if any of the biomarkers found above relate to a different link operator on average between models with different performance characteristics (e.g. higher predictive models should have the OR NOT as the link operator in a boolean equation where a specific biomarker is the regulation target) or if they constitute targets of exclusively activating nodes or inhibiting ones (an equation with no link operator). The performance metric we will first use to sort the models is the number of true positive predictions. We will now illustrate the heatmap of the models.equations object raw-order by the number of \\(TP\\) predictions: # order based on number of true positives models.synergies.tp.sorted = sort(models.synergies.tp) models.sorted = names(models.synergies.tp.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring eq.link.colors = c(&quot;red&quot;, &quot;lightyellow&quot;) eq.link.col.fun = colorRamp2(breaks = c(0, 1), colors = eq.link.colors) tp.values = sort(unique(models.synergies.tp)) tp.col.fun = colorRamp2(breaks = c(min(tp.values), max(tp.values)), colors = c(&quot;red&quot;, &quot;green&quot;)) # color biomarker names in the heatmap bottom.nodes.colors = rep(&quot;black&quot;, length(colnames(models.equations.sorted))) names(bottom.nodes.colors) = colnames(models.equations.sorted) bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.active] = &quot;blue&quot; bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.inhibited] = &quot;magenta&quot; # define the TP color bar tp.annot = rowAnnotation( tp = anno_simple(x = models.synergies.tp.sorted, col = tp.col.fun), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (TP sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = tp.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 3 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) tp.values = min(tp.values):max(tp.values) # maybe some integers are missing tp.legend = Legend(at = tp.values, title = &quot;TP&quot;, legend_gp = gpar(fill = tp.col.fun(tp.values))) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, tp.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the heatmap above, an equation whose link operator is AND NOT is represented with red color while an OR NOT link operator is represented with light yellow color. The targets whose equations do not have a link operator are not represented. The rows are ordered by the number of true positive predictions (ascending). We have colored the names of the network nodes that were also found as biomarkers (green color is used for the active biomarkers and red color for the inhibited biomarkers). We observe that: Most of the biomarkers are nodes that do not have both activators and inhibitors and so are absent from the above heatmap There doesn’t seem to exist a pattern between the models’ link operators and their corresponding performance (at least not for all of the nodes) when using the true positive predictions as a classifier for the models There exist a lot of target nodes that need to have the OR NOT link operator in their respective boolean equation in order for the corresponding logical model to show a higher number of true positive predictions. By assigning the OR NOT link operator to a target’s boolean regulation equation, we allow more flexibility to the target’s output active result state - meaning that the inhibitors play less role and the output state has a higher probability of being active - compared to assigning the AND NOT link operator to the equation We will also illustrate the heatmap of the models.equations object raw-order by the MCC score which is a better performance classifier. Models who had a NaN MCC score will be again placed in the lower performant category: # order based on the MCC value models.mcc.sorted = sort(models.mcc, na.last = FALSE) models.sorted = names(models.mcc.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring mcc.col.fun = colorRamp2(breaks = c(min(models.mcc.no.nan), max(models.mcc.no.nan)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define the MCC color bar mcc.annot = rowAnnotation( mcc = anno_simple(x = models.mcc.sorted, col = mcc.col.fun, na_col = &quot;black&quot;), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (MCC sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = mcc.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 4 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) mcc.legend = Legend(title = &quot;MCC&quot;, col_fun = mcc.col.fun) na.legend = Legend(labels = &quot;NA&quot;, legend_gp = gpar(fill = &quot;black&quot;)) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, mcc.legend, na.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the MCC-ordered heatmap above we observe that there is better correlation between the boolean equations’ link operators and the performance of a model compared to the \\(TP\\) classification. For example, the node PtsIns(3,4,5)P3 and the biomarker STAT3 show distinguished patterns for the higher performance models (use of AND NOT and OR NOT link operators respectively) when the models are sorted by the MCC score. Synergy-prediction based analysis We will now use the second strategy to split the models, based on whether they predict a specific observed synergy or not. This will allow us to find biomarkers that affect the prediction of a specific synergy. For example, the good models could be the ones that predicted the hypothetical synergy A-B while the bad models all the rest that identified the particular combination as non-synergistic. In another case scenario, the good models could be those that predicted a triple synergy set A-B,C-D,A-C, while the bad models could be the ones that predicted the double synergy subset A-B,C-D (excluding the common models that predicted both the triple synergy set and subsequently its given subset). In such a case scenario, we want to find out which nodes are responsible for making the good models predict the extra synergy - in this hypothetical case the synergy A-C - demonstrating thus better model performance. Note that the models selected in each case as good or bad, could have predicted other synergies as well (correctly as \\(TP\\) or wrongly as \\(FP\\)) which means that the biomarker selection method could be somewhat innacurate, since we can’t really know the prediction of which extra synergy or synergies the biomarkers’ state affected. To account for this, we label as good models those that predict large synergy sets (so fewer models) which capture almost all the true positive predictions and also minimize the possible extra different synergies predicted by models of the same classification category (e.g. the good models). Starting with the first model classification method (prediction vs non-prediction of a particular synergy), we generate the density distribution of the nodes’ average state differences between the good and bad models for each predicted synergy: diff.predicted.synergies.results = sapply(predicted.synergies, function(drug.comb) { get_avg_activity_diff_based_on_specific_synergy_prediction( model.predictions, models.stable.state, drug.comb) }) diff.predicted.synergies.results = t(diff.predicted.synergies.results) densities = apply(abs(diff.predicted.synergies.results), 1, density) make_multiple_density_plot(densities, legend.title = &quot;Predicted Synergies&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Next, we will plot the biomarkers with the network visualization method (for all predicted synergies) and output the respective biomarkers in each case. The biomarker results for each predicted synergy will be stored for further comparison with the results from the other cell lines. threshold = 0.7 for (drug.comb in predicted.synergies) { diff = diff.predicted.synergies.results[drug.comb, ] biomarkers.active = diff[diff &gt; threshold] biomarkers.inhibited = diff[diff &lt; -threshold] save_vector_to_file(vector = biomarkers.active, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_active&quot;), with.row.names = TRUE) save_vector_to_file(vector = biomarkers.inhibited, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_inhibited&quot;), with.row.names = TRUE) } threshold = 0.7 for (drug.comb in predicted.synergies) { title.text = paste0(&quot;Prediction of &quot;, drug.comb, &quot; synergy: Good models vs Bad Models&quot;) diff = diff.predicted.synergies.results[drug.comb, ] plot_avg_state_diff_graph(net, diff, layout = nice.layout, title = title.text) } print_biomarkers_per_predicted_synergy(biomarkers.dir, predicted.synergies) Biomarkers for BI-PI synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: Biomarkers for BI-JN synergy predictionActive biomarkers3 nodes: MAPK8, APP, SIRT1Inhibited biomarkers1 node: LATBiomarkers for PI-D1 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: We notice that for some predicted synergies the above method identified zero biomarkers. We will now study cases where the main goal is the better identification and/or refinement of the biomarkers responsible for allowing the models to predict one extra synergy from a specific synergy set. If we find biomarkers for a predicted synergy using this strategy, we compare them to the ones already found with the previous method and if none of them is common we just add the new ones to the list of biomarkers for that specific synergy. On the other hand, if the synergy-set comparison method identifies a subset of the previously found biomarkers for a specific synergy (one common node at least), we will only keep the later method’s biomarkers since we believe that the synergy-set prediction based method is more accurate at identifying biomarkers for a specific synergy because of the fewer models involved in each contrasting category which also minimizes the total false positive synergy predictions taken into account. Note that if the second method finds even more biomarkers than the first, we have the option to prune the end result to only the common biomarkers between the two methods. We will focus our analysis on the predicted synergies PI-D1, BI-PI and BI-JN. Synergy-set prediction based analysis PI-D1 synergy The first use case will contrast the models that predicted the synergy set BI-PI,PI-D1 vs the models that predicted the single synergy BI-PI and the models that predicted the synergy set BI-JN,PI-D1 vs the models that predicted the single synergy BI-JN. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PI-D1 synergy: synergy.set.str.1 = &quot;BI-PI,PI-D1&quot; synergy.subset.str.1 = &quot;BI-PI&quot; diff.PI.D1.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;BI-JN,PI-D1&quot; synergy.subset.str.2 = &quot;BI-JN&quot; diff.PI.D1.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text.1 = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.1, layout = nice.layout, title = title.text.1) title.text.2 = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.2, layout = nice.layout, title = title.text.2) We provide the number of models used in the first comparison between the synergy set BI-PI,PI-D1 and the single synergy BI-PI: pretty_print_string(count_models_that_predict_synergies( as.list(strsplit(&quot;BI-PI,PI-D1&quot;, &quot;,&quot;)), model.predictions) ) 626 pretty_print_string(count_models_that_predict_synergies( as.list(strsplit(&quot;BI-PI&quot;, &quot;,&quot;)), model.predictions) ) 627 So, in this case the ‘good’ models is just one model and the rest 626 are the ‘bad’ ones that couldn’t predict the extra PI-D1 synergy. This imbalanced comparison does not give us good results as we notice from the above network graph (too many important nodes were identified). We will report the active biomarker found using the results from the second comparison (BI-JN,PI-D1 vs BI-JN): biomarkers.PI.D1.active = diff.PI.D1.2[diff.PI.D1.2 &gt; threshold] pretty_print_vector_names(biomarkers.PI.D1.active) 1 node: GSK3A The inhibited biomarkers found is: biomarkers.PI.D1.inhibited = diff.PI.D1.2[diff.PI.D1.2 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.D1.inhibited) 1 node: GATA6 Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;PI-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.PI.D1.active, biomarkers.PI.D1.inhibited) BI-PI synergy The second use case will contrast the models that predicted the synergy set BI-PI,PI-D1 vs the models that predicted the single synergy PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-PI synergy: synergy.set.str = &quot;BI-PI,PI-D1&quot; synergy.subset.str = &quot;PI-D1&quot; diff.BI.PI = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI, layout = nice.layout, title = title.text) Sadly, no biomarkers were found at the \\(0.7\\) threshold in either active or inhibited states: biomarkers.BI.PI.active = diff.BI.PI[diff.BI.PI &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active) 0 nodes: biomarkers.BI.PI.inhibited = diff.BI.PI[diff.BI.PI &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited) 0 nodes: BI-JN synergy The third use case will contrast the models that predicted the synergy set BI-JN,PI-D1 vs the models that predicted the single synergy PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-JN synergy: synergy.set.str = &quot;BI-JN,PI-D1&quot; synergy.subset.str = &quot;PI-D1&quot; diff.BI.JN = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.JN, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.BI.JN.active = diff.BI.JN[diff.BI.JN &gt; threshold] pretty_print_vector_names(biomarkers.BI.JN.active) 4 nodes: GSK3A, MAPK8, APP, SIRT1 Note that the above active biomarkers are the same as the ones we found with the previous method (plus one extra). We also report the inhibited biomarkers: biomarkers.BI.JN.inhibited = diff.BI.JN[diff.BI.JN &lt; -threshold] pretty_print_vector_names(biomarkers.BI.JN.inhibited) 2 nodes: GATA6, LAT We note that with this method, one more extra inhibited biomarker was found. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-JN&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.JN.active, biomarkers.BI.JN.inhibited) Biomarker results In this section, we will compare the biomarkers found per predicted synergy for this particular cell line as well as the performance biomarkers (notated as PERF in the heatmap below) which were found using the results from the MCC classification-based model analysis: # Biomarkers from sections: # `Synergy-prediction based analysis`, `Synergy-set prediction based analysis` biomarkers.synergy.res = get_synergy_biomarkers_from_dir(predicted.synergies, biomarkers.dir, models.dir) # store biomarkers in one file save_df_to_file(biomarkers.synergy.res, file = paste0(biomarkers.dir, &quot;biomarkers_per_synergy&quot;)) # Biomarkers from section: # `Performance-related biomarkers` biomarkers.res = add_row_to_ternary_df(df = biomarkers.synergy.res, values.pos = biomarkers.perf.active, values.neg = biomarkers.perf.inhibited, row.name = &quot;PERF&quot;) # prune nodes which are not found as biomarkers for any predicted synergy or # for better model performance biomarkers.res = prune_columns_from_df(biomarkers.res, value = 0) # define a coloring biomarkers.col.fun = colorRamp2(c(-1, 0, 1), c(&quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;)) biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.res), col = biomarkers.col.fun, column_title = paste0(&quot;Biomarker results (&quot;, cell.line, &quot;)&quot;), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = &quot;Predicted synergies&quot;, row_order = nrow(biomarkers.res):1, column_dend_height = unit(1, &quot;inches&quot;), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 7), row_names_side = &quot;left&quot;, heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) So, in general we observe that: A total of 58 nodes were found as biomarkers (for at least one synergy) None of the performance-related biomarkers (PERF) were also observed as biomarkers for the prediction of a specific synergy(ies) There exist common biomarkers across different predicted synergies, e.g.  GATA6 and GSK3A are common inhibited and active biomarkers across 2 synergistic drug combinations The results between the different synergies correlate in the sense that there is no active biomarker for a particular synergy that was found as inhibited in another and vise versa We couldn’t indentify any biomarkers at the \\(0.7\\) threshold for the BI-PI synergy "],
["colo205-model-analysis.html", "Colo205 Model Analysis Input Performance Statistics Biomarker analysis", " Colo205 Model Analysis This chapter includes the ensemble model analysis performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). All these models were trained towards a specific steady state signaling pattern that was derived based on input data (gene expression, CNV) for the colo205 cell line (colorectal adenocarcinoma, a colon cancer), the use of the PARADIGM software (Vaske et al. 2010) and a topology that was build for simulating a cancer cell fate decision network. The input for the simulations and the output data are in the cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input We will define the name of the cell line which must match the name of the directory that has the input files inside the cell-lines-2500 directory. Our analysis in this chapter will be done on the data for the colo205 cell line: cell.line = &quot;colo205&quot; data.dir = paste0(getwd(), &quot;/&quot;, cell.line, &quot;/&quot;) Three inputs are used in this analysis: The model_predictions file which has for each model the prediction for each drug combination tested (0 = no synergy predicted, 1 = synergy predicted, NA = couldn’t find stable states in either the drug combination inhibited model or in any of the two single-drug inhibited models) The observed_synergies file which lists the drug combinations that were observed as synergistic for the particular cell line. The models directory, which is the same as the models directory produced by Gitsbe and has one .gitsbe file per model that includes this info: The stable state of the boolean model. Note that a model can have 1 stable state or none in our simulations - but the models used in this analysis have been selected through a genetic evolution algorithm in Gitsbe and so in the end, only those with 1 stable state have higher fitness values and remain in the later generations. Higher fitness here means a better match of a model’s stable state to the cell line derived steady state (a perfect match would result in a fitness of 1) The boolean equations of the model models.stable.state.file = paste0(data.dir, &quot;models_stable_state&quot;) observed.synergies.file = paste0(data.dir, &quot;observed_synergies&quot;) model.predictions.file = paste0(data.dir, &quot;model_predictions&quot;) models.equations.file = paste0(data.dir, &quot;models_equations&quot;) models.dir = paste0(data.dir, &quot;models&quot;) Now, we parse the data into proper R objects. First the synergy predictions per model: model.predictions = get_model_predictions(model.predictions.file) # Example: first model&#39;s synergy predictions (first 12 drug combinations) pretty_print_vector_names_and_values(model.predictions[1,], n = 12) 5Z-AK: 0, 5Z-BI: 0, 5Z-CT: 0, 5Z-PD: 0, 5Z-PI: 0, 5Z-PK: 0, 5Z-JN: 0, 5Z-D1: 0, 5Z-60: 0, 5Z-SB: 0, 5Z-RU: 0, 5Z-D4: 0 So, the model.predictions object has the models as rows and each column is a different drug combination that was tested in our simulations. drug.combinations.tested = colnames(model.predictions) models = rownames(model.predictions) nodes = get_node_names(models.dir) number.of.drug.comb.tested = length(drug.combinations.tested) number.of.models = length(models) number.of.nodes = length(nodes) print_model_and_drug_stats(number.of.drug.comb.tested, number.of.models, number.of.nodes, html.output = TRUE) Drug combinations tested: 153Number of models: 7500Number of nodes: 139 Next, we get the full stable state and the equations per model: models.stable.state = as.matrix( read.table(file = models.stable.state.file, check.names = FALSE) ) # Example: first model&#39;s stable state (first 12 nodes) pretty_print_vector_names_and_values(models.stable.state[1,], n = 12) MAP3K7: 1, MAP2K6: 1, MAP2K3: 1, NLK: 1, MAP3K4: 1, MAP2K4: 1, IKBKG: 1, IKBKB: 1, AKT1: 0, BRAF: 0, SMAD3: 1, DAB2IP: 1 The rows of the models.stable.state object represent the models while its columns are the names of the nodes (proteins, genes, etc.) of the cancer cell network under study. So, each model has one stable state which means that in every model, the nodes in the network have reached a state of either 0 (inhibition) or 1 (activation). models.equations = as.matrix( read.table(file = models.equations.file, check.names = FALSE) ) # Example: first model&#39;s link operators (first 12 nodes) pretty_print_vector_names_and_values(models.equations[1,], n = 12) MAP3K4: 1, MAP2K4: 0, IKBKB: 1, AKT1: 0, SMAD3: 1, GSK3B: 1, RAF1: 0, GAB2: 0, CTNNB1: 0, NR3C1: 0, CREB1: 1, RAC1: 0 For the models.equations, if we look at a specific row (a model so to speak), the columns (node names) correspond to the targets of regulation (and the network has been built so that every node is a target - i.e. it has other nodes activating and/or inhibiting it). The general form of a boolean equation is: general.equation = &quot;Target *= (Activator OR Activator OR...) AND NOT (Inhibitor OR Inhibitor OR...)&quot; pretty_print_bold_string(general.equation) Target *= (Activator OR Activator OR…) AND NOT (Inhibitor OR Inhibitor OR…) The difference between the models’ boolean equations is the link operator (OR NOT/AND NOT) which has been mutated (changed) through the evolutionary process of the genetic algorithm in Gitsbe. For example, if a model has for the column ERK_f (of the models.equations object) a value of 1, the correspoding equation is: ERK_f *= (MEK_f) OR NOT ((DUSP6) OR PPP1CA). A value of 0 would correspond to the same equation but having AND NOT as the link operator: ERK_f *= (MEK_f) AND NOT ((DUSP6) OR PPP1CA). Note that the equations that do not have link operators (meaning that they are the same for every model) are discarded (so less columns in this dataset) since in a later section we study only the equations whose link operators differentiate between the models. Lastly, the synergies observed for this particular cell line are: observed.synergies = get_observed_synergies( observed.synergies.file, drug.combinations.tested) number.of.observed.synergies = length(observed.synergies) pretty_print_vector_values(observed.synergies, vector.values.str = &quot;observed synergies&quot;) 11 observed synergies: AK-60, AK-BI, PI-D1, AK-G4, AK-JN, BI-JN, BI-P5, JN-P5, AK-PI, BI-PI, PK-ST Performance Statistics It will be interesting to know the percentage of the above observed synergies that were actually predicted by at least one of the models (there might be combinations that no model in our dataset could predict): # Split model.predictions to positive and negative results observed.model.predictions = get_observed_model_predictions(model.predictions, observed.synergies) unobserved.model.predictions = get_unobserved_model_predictions(model.predictions, observed.synergies) stopifnot(ncol(observed.model.predictions) + ncol(unobserved.model.predictions) == number.of.drug.comb.tested) number.of.models.per.observed.synergy = colSums(observed.model.predictions, na.rm = TRUE) predicted.synergies = names(which(number.of.models.per.observed.synergy &gt; 0)) # predicted synergies is a subset of the observed (positive) ones stopifnot(all(predicted.synergies %in% observed.synergies)) pretty_print_vector_values(predicted.synergies, vector.values.str = &quot;predicted synergies&quot;) 2 predicted synergies: BI-PI, PI-D1 predicted.synergies.percentage = 100 * length(predicted.synergies) / number.of.observed.synergies pretty_print_string(paste0(&quot;Percentage of True Positive predicted synergies: &quot;, specify_decimal(predicted.synergies.percentage, 2), &quot;%&quot;)) Percentage of True Positive predicted synergies: 18.18% So, for this particular cell line, there were indeed observed synergies that no model could predict (e.g.  AK-BI, AK-PI). Next, we would like to know the maximum number of observed synergies predicted by one model alone - can one model by itself predict all the true positive synergies predicted by all the models together or do we need many models to capture this diverse synergy landscape? To do that, we go even further and count the number of models that predict a specific set of observed synergies for every possible combination subset of the predicted.synergies object: # Find the number of predictive models for every synergy subset synergy.subset.stats = get_synergy_subset_stats(observed.model.predictions, predicted.synergies) # Bar plot of the number of models for every possible observed synergy combination set # Tweak the threshold.for.subset.removal and bottom.margin as desired make_barplot_on_synergy_subset_stats(synergy.subset.stats, threshold.for.subset.removal = 1, bottom.margin = 6, cell.line) From the above figure (where we excluded sets of synergies that were predicted by no model by setting the threshold.for.subset.removal value to 1) we observe that: Most of the models predict none of the observed synergies The PI-D1 synergy is predicted by almost all the rest of the models Next we calculate the maximum number of correctly predicted synergies (\\(TP\\) - True Positives) per model: # Count the predictions of the observed synergies per model (TP) models.synergies.tp = calculate_models_synergies_tp(observed.model.predictions) models.synergies.tp.stats = table(models.synergies.tp) # Bar plot of number of models vs correctly predicted synergies make_barplot_on_models_stats(models.synergies.tp.stats, cell.line, title = &quot;True Positive Synergy Predictions&quot;, xlab = &quot;Number of maximum correctly predicted synergies&quot;, ylab = &quot;Number of models&quot;) To summarize: There were 29 models that predicted 2 synergies - the set BI-PI,PI-D1 - which is the maximum number of predicted synergies by an individual model and also the number of total predicted synergies by all models together The power of the ensemble model approach lies in the fact that (as we saw from the above figures) even though we may not have individual super models that can predict many observed drug combinations, there are many that predict at least one and which will be used by the drug response analysis module (Drabme) to better infer the synergistic drug combinations. It goes without saying though, that the existance of models that could predict more than a handful of synergies would be beneficial for any approach that performs drug response analysis on a multitude of models. Biomarker analysis Intro-Methods Now, we want to investigate and find possible important nodes - biomarkers - whose activity state either distinguishes good performance models from less performant ones (in terms of a performance metric - e.g. the true positive synergies predicted) or makes some models predict a specific synergy compared to others that can’t (but could predict other synergies). So, we devised two strategies to split the models in our disposal to good and bad ones (but not necessarily all of them), the demarcation line being either a performance metric (the number of \\(TP\\) or the Matthews Correlation Coefficient score) or the prediction or not of a specific synergy. Then, for each group of models (labeled as either good or bad) we find the average activity state of every node in the network (value between 0 and 1) and then we compute the average state difference for each node between the two groups: \\(\\forall i\\in nodes,mean(state_i)_{good} - mean(state_i)_{bad}\\). Our hypothesis is that if the absolute value of these average differences are larger than a user-defined threshold (e.g. 0.7) for a small number of nodes (the less the better) while for the rest of the nodes they remain close to zero, then the former nodes are considered the most important since they define the difference between the average bad model and the average good one in that particular case study. We will also deploy a network visualization method to observe these average differences. True Positives-based analysis Using our first strategy, we will split the models based on the number of true positive predictions. For example, the bad models will be the ones that predicted 0 \\(TP\\) synergies whereas the good models will be the ones that predicted 2 \\(TP\\) (we will denote the grouping as \\((0,2)\\)). This particular classification strategy will be used for every possible combination of the number of \\(TP\\) as given by the models.synergies.tp.stats object and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: diff.tp.results = get_avg_activity_diff_mat_based_on_tp_predictions( models, models.synergies.tp, models.stable.state) tp.densities = apply(abs(diff.tp.results), 1, density) make_multiple_density_plot(tp.densities, legend.title = &quot;True Positives&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) What we are actually looking for is density plots that are largely skewed to the right (so the average absolute differences of these nodes are close to zero) while there are a few areas of non-zero densities which are as close to 1 as possible. So, from the above graph, the density plot that fits this description is the one marked as \\((1,2)\\). We will visualize the nodes’ average state differences in a network graph (Csardi and Nepusz 2006), where the color of each node will denote how much more inhibited or active that node is, in the average good model vs the average bad one. The color of the edges will denote activation (green) or inhibition (red). We first build the network from the node topology (edge list): parent.dir = get_parent_dir(data.dir) topology.file = paste0(parent.dir, &quot;/topology&quot;) coordinates.file = paste0(parent.dir, &quot;/network_xy_coordinates&quot;) net = construct_network(topology.file, models.dir) # a static layout for plotting the same network always (igraph) # nice.layout = layout_nicely(net) nice.layout = as.matrix(read.table(coordinates.file)) In the next colored graphs we can identify the important nodes whose activity state can influence the true positive prediction performance (from 0 true positive synergies to a total of 2): plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,1)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (1 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,2)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (2 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(1,2)&quot;,], layout = nice.layout, title = &quot;Bad models (1 TP) vs Good models (2 TP)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to the number of true positive synergies that they predict. Comparing the graphs above, we observe that there exist common nodes that maintain the same significant influence in all of the graphs. We set the threshold for the absolute significance level in average state differences to \\(0.7\\). A node will be marked as a biomarker (active or inhibited) if its activity state difference surpassed the aforementioned threshold (positively or negatively) for any of the tested groups (e.g. 1 \\(TP\\) vs 2 \\(TP\\)). So, the nodes that have to be in a more active state are: biomarkers.tp.active = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.tp.active) 3 nodes: MAPK8, APP, SIRT1 Also, the nodes that have to be in a more inhibited state are: biomarkers.tp.inhibited = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.tp.inhibited) 2 nodes: CASP3, LAT We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.tp = get_common_values(biomarkers.tp.active, biomarkers.tp.inhibited) No common nodes MCC classification-based analysis The previous method to split the models based on the number of true positive predictions is a good metric for absolute performance but a very restricted one since it ignores the other values of the confusion matrix for each model (true negatives, false positives, false negatives). Also, since our dataset is imbalanced in the sense that out of the total drug combinations tested only a few of them are observed as synergistic (and in a hypothetical larger drug screening evaluation it will be even less true positives) we will now devise a method to split the models into different performance categories based on the value of the Matthews Correlation Coefficient (MCC) score which takes into account the balance ratios of all the four confusion matrix values: # Calculate Matthews Correlation Coefficient (MCC) for every model models.mcc = calculate_models_mcc(observed.model.predictions, unobserved.model.predictions, number.of.drug.comb.tested) models.mcc.stats = table(models.mcc, useNA = &quot;ifany&quot;) make_barplot_on_models_stats(models.mcc.stats, cell.line, title = &quot;MCC scores&quot;, xlab = &quot;MCC value&quot;, ylab = &quot;Number of models&quot;, cont.values = TRUE) From the above figure we observe that: There are no relatively bad models (MCC values close to -1) Some models (exluding the NaN category) perform close to random prediction (\\(MCC\\approx0\\)) There are models that had NaN value for the MCC score Given the MCC formula: \\(MCC = (TP\\cdot TN - FP\\cdot FN)/\\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}\\), we can see that the MCC value can be NaN because of zero devision. Two of the four values in the denominator represent the number of positive \\((TP+FN)\\) and negative \\((TN+FP)\\) observations which are non-zero for every model, since they correspond to the observed and non-obsered synergies in each case. The case where both \\(TN\\) and \\(FN\\) are zero is rare (if non-existent) because of the imbalanced dataset (large proportion of negatives) and the reason that logical models which report no negatives means that they should find fixpoint attractors for every possible drug combination perturbation which also is extremely unlikely. We can actually see that the NaN are produced by models that have both TP and FP equal to zero: models.synergies.fp = calculate_models_synergies_fp(unobserved.model.predictions) pretty_print_string(sum(models.synergies.tp + models.synergies.fp == 0)) 1343 Since these models could intentify no synergies (either correctly or wrongly), we decided to put them as the lowest performant category in our MCC-based analysis. To classify the models based on their MCC score (which takes values in the \\([-1, 1]\\) interval, NaN values excluded), we will perform a univariate k-means clustering to split the previously found MCC values to different classes (Wang and Song 2011). The MCC classification is presented with a histogram: num.of.classes = 5 mcc.class.ids = 1:num.of.classes models.mcc.no.nan = models.mcc[!is.nan(models.mcc)] models.mcc.no.nan.sorted = sort(models.mcc.no.nan) # find the clusters res = Ckmeans.1d.dp(x = models.mcc.no.nan.sorted, k = num.of.classes) models.cluster.ids = res$cluster plot_mcc_classes_hist(models.mcc.no.nan.sorted, models.cluster.ids, num.of.classes, mcc.class.ids) Note that in total we have 6 MCC classes, since the NaN MCC values constitute a class on its own. Following our first strategy, we will split the models based on the MCC performance metric score. For example, the bad models will be the ones that had an MCC score belonging to the first MCC class whereas the good models will be the ones that had an MCC score belonging to the third MCC class as seen in the histogram above. This particular classification strategy will be used for every possible combination of the MCC classes and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: # add NaN class (if applicable) if (sum(is.nan(models.mcc)) &gt; 0) { mcc.class.ids = append(mcc.class.ids, values = NaN, after = 0) } mcc.class.id.comb = t(combn(1:length(mcc.class.ids), 2)) diff.mcc.results = apply(mcc.class.id.comb, 1, function(comb) { return(get_avg_activity_diff_based_on_mcc_clustering( models.mcc, models.stable.state, mcc.class.ids, models.cluster.ids, class.id.low = comb[1], class.id.high = comb[2])) }) mcc.classes.comb.names = apply(mcc.class.id.comb, 1, function(comb) { return(paste0(&quot;(&quot;, mcc.class.ids[comb[1]], &quot;,&quot;, mcc.class.ids[comb[2]], &quot;)&quot;)) }) colnames(diff.mcc.results) = mcc.classes.comb.names diff.mcc.results = t(diff.mcc.results) mcc.densities = apply(abs(diff.mcc.results), 1, density) make_multiple_density_plot(mcc.densities, legend.title = &quot;MCC classes&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;, legend.size = 0.7) Many of the density plots above are of interest to us, since they are right skewed. Next, we visualize the average state differences with our network coloring method for 2 of the above cases, in order to identify the important nodes whose activity state can influence the prediction performance based on the MCC classification: plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(NaN,4)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: NaN) vs Good models (MCC Class: 4)&quot;) plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(1,5)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 1) vs Good models (MCC Class: 5)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to their MCC classification, using the same method as in the True Positives-based analysis section. First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 10 nodes: DLX5, RAC1, MAP3K11, FGFR1, TAB1, CASP3, PTPN7, MAX, MAPK8IP1, MAPK9 Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 6 nodes: DLX5, MAP3K11, MAPK14, RPS6KA5, DUSP1, RXRA We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.mcc = get_common_values(biomarkers.mcc.active, biomarkers.mcc.inhibited) 2 nodes: DLX5, MAP3K11 Since there are common nodes that were found to surpass the significance threshold level for the average state difference between two MCC classes both negatively and positively, we will keep these biomarkers only in the state which corresponds to the comparison of the highest classification categories. For example, if for the comparison of the MCC classes \\((1,3)\\) the node of interest had an average difference of \\(-0.89\\) while for the comparison of the \\((3,4)\\) MCC classes it had a value of \\(0.91\\), then we will keep that node only in the active biomarker list. The logic behind this is that the higher the MCC classes we compare, the more sure we are that the average state difference corresponds to a better indicator of the state of the biomarker found. # remove the common biomarkers biomarkers.mcc.active = biomarkers.mcc.active[!biomarkers.mcc.active %in% common.biomarkers.mcc] biomarkers.mcc.inhibited = biomarkers.mcc.inhibited[!biomarkers.mcc.inhibited %in% common.biomarkers.mcc] # find the proper state of the biomarkers and add them threshold = 0.7 for (biomarker in common.biomarkers.mcc) { logical.vector = diff.mcc.results[, biomarker] &gt; threshold | diff.mcc.results[, biomarker] &lt; -threshold comparison.index = max(which(logical.vector == TRUE)) if (diff.mcc.results[comparison.index, biomarker] &gt; threshold) biomarkers.mcc.active = append(biomarkers.mcc.active, biomarker) else biomarkers.mcc.inhibited = append(biomarkers.mcc.inhibited, biomarker) } # printing MCC biomarkers pretty_print_vector_values(biomarkers.mcc.active) 9 nodes: RAC1, FGFR1, TAB1, CASP3, PTPN7, MAX, MAPK8IP1, MAPK9, DLX5 pretty_print_vector_values(biomarkers.mcc.inhibited) 5 nodes: MAPK14, RPS6KA5, DUSP1, RXRA, MAP3K11 0.0.1 Performance-related biomarkers Comparing the two methods we used for the classification of the models’ prediction performance (TP and MCC), we observe that there exist no common biomarkers in either active or inhibited state cases while the results regarding the state of the node CASP3 are contradictory: common.biomarkers.mixed.1 = get_common_values(biomarkers.mcc.active, biomarkers.tp.inhibited) 1 node: CASP3 common.biomarkers.mixed.2 = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.active) No common nodes biomarkers.perf.active = get_common_values(biomarkers.mcc.active, biomarkers.tp.active) No common nodes biomarkers.perf.inhibited = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.inhibited) No common nodes We believe that the MCC score better captures the performance categories within our imbalanced dataset so we will use the results from the MCC analysis as the performance biomarkers. Lastly, we will save these performance-related biomarkers for further analysis and comparison with the results from all the different cell lines: biomarkers.dir = paste0(data.dir, &quot;biomarkers/&quot;) biomarkers.perf.active = biomarkers.mcc.active biomarkers.perf.inhibited = biomarkers.mcc.inhibited save_vector_to_file(vector = biomarkers.perf.active, file = paste0(biomarkers.dir, &quot;biomarkers_active&quot;)) save_vector_to_file(vector = biomarkers.perf.inhibited, file = paste0(biomarkers.dir, &quot;biomarkers_inhibited&quot;)) Equation-based analysis It will be interesting to see the different patterns in the form of the boolean equations (regarding the mutation of the link operator as mentioned in the Input section) when comparing higher performance models vs the low performant ones. We could also check if any of the biomarkers found above relate to a different link operator on average between models with different performance characteristics (e.g. higher predictive models should have the OR NOT as the link operator in a boolean equation where a specific biomarker is the regulation target) or if they constitute targets of exclusively activating nodes or inhibiting ones (an equation with no link operator). The performance metric we will first use to sort the models is the number of true positive predictions. We will now illustrate the heatmap of the models.equations object raw-order by the number of \\(TP\\) predictions: # order based on number of true positives models.synergies.tp.sorted = sort(models.synergies.tp) models.sorted = names(models.synergies.tp.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring eq.link.colors = c(&quot;red&quot;, &quot;lightyellow&quot;) eq.link.col.fun = colorRamp2(breaks = c(0, 1), colors = eq.link.colors) tp.values = sort(unique(models.synergies.tp)) tp.col.fun = colorRamp2(breaks = c(min(tp.values), max(tp.values)), colors = c(&quot;red&quot;, &quot;green&quot;)) # color biomarker names in the heatmap bottom.nodes.colors = rep(&quot;black&quot;, length(colnames(models.equations.sorted))) names(bottom.nodes.colors) = colnames(models.equations.sorted) bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.active] = &quot;blue&quot; bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.inhibited] = &quot;magenta&quot; # define the TP color bar tp.annot = rowAnnotation( tp = anno_simple(x = models.synergies.tp.sorted, col = tp.col.fun), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (TP sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = tp.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 3 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) tp.values = min(tp.values):max(tp.values) # maybe some integers are missing tp.legend = Legend(at = tp.values, title = &quot;TP&quot;, legend_gp = gpar(fill = tp.col.fun(tp.values))) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, tp.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the heatmap above, an equation whose link operator is AND NOT is represented with red color while an OR NOT link operator is represented with light yellow color. The targets whose equations do not have a link operator are not represented. The rows are ordered by the number of true positive predictions (ascending). We have colored the names of the network nodes that were also found as biomarkers (green color is used for the active biomarkers and red color for the inhibited biomarkers). We observe that: Most of the biomarkers are nodes that do not have both activators and inhibitors and so are absent from the above heatmap There doesn’t seem to exist a pattern between the models’ link operators and their corresponding performance (at least not for all of the nodes) when using the true positive predictions as a classifier for the models There exist a lot of target nodes that need to have the OR NOT link operator in their respective boolean equation in order for the corresponding logical model to show a higher number of true positive predictions. By assigning the OR NOT link operator to a target’s boolean regulation equation, we allow more flexibility to the target’s output active result state - meaning that the inhibitors play less role and the output state has a higher probability of being active - compared to assigning the AND NOT link operator to the equation We will also illustrate the heatmap of the models.equations object raw-order by the MCC score which is a better performance classifier. Models who had a NaN MCC score will be again placed in the lower performant category: # order based on the MCC value models.mcc.sorted = sort(models.mcc, na.last = FALSE) models.sorted = names(models.mcc.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring mcc.col.fun = colorRamp2(breaks = c(min(models.mcc.no.nan), max(models.mcc.no.nan)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define the MCC color bar mcc.annot = rowAnnotation( mcc = anno_simple(x = models.mcc.sorted, col = mcc.col.fun, na_col = &quot;black&quot;), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (MCC sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = mcc.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 4 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) mcc.legend = Legend(title = &quot;MCC&quot;, col_fun = mcc.col.fun) na.legend = Legend(labels = &quot;NA&quot;, legend_gp = gpar(fill = &quot;black&quot;)) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, mcc.legend, na.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the MCC-ordered heatmap above we observe that there is better correlation between the boolean equations’ link operators and the performance of a model compared to the \\(TP\\) classification. For example, the nodes PtsIns(3,4,5)P3 and STAT3 show distinguished patterns for the higher performance models (use of AND NOT and OR NOT link operators respectively) when the models are sorted by the MCC score. Synergy-prediction based analysis We will now use the second strategy to split the models, based on whether they predict a specific observed synergy or not. This will allow us to find biomarkers that affect the prediction of a specific synergy. For example, the good models could be the ones that predicted the hypothetical synergy A-B while the bad models all the rest that identified the particular combination as non-synergistic. In another case scenario, the good models could be those that predicted a triple synergy set A-B,C-D,A-C, while the bad models could be the ones that predicted the double synergy subset A-B,C-D (excluding the common models that predicted both the triple synergy set and subsequently its given subset). In such a case scenario, we want to find out which nodes are responsible for making the good models predict the extra synergy - in this hypothetical case the synergy A-C - demonstrating thus better model performance. Note that the models selected in each case as good or bad, could have predicted other synergies as well (correctly as \\(TP\\) or wrongly as \\(FP\\)) which means that the biomarker selection method could be somewhat innacurate, since we can’t really know the prediction of which extra synergy or synergies the biomarkers’ state affected. To account for this, we label as good models those that predict large synergy sets (so fewer models) which capture almost all the true positive predictions and also minimize the possible extra different synergies predicted by models of the same classification category (e.g. the good models). Starting with the first model classification method (prediction vs non-prediction of a particular synergy), we generate the density distribution of the nodes’ average state differences between the good and bad models for each predicted synergy: diff.predicted.synergies.results = sapply(predicted.synergies, function(drug.comb) { get_avg_activity_diff_based_on_specific_synergy_prediction( model.predictions, models.stable.state, drug.comb) }) diff.predicted.synergies.results = t(diff.predicted.synergies.results) densities = apply(abs(diff.predicted.synergies.results), 1, density) make_multiple_density_plot(densities, legend.title = &quot;Predicted Synergies&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Next, we will plot the biomarkers with the network visualization method (for all predicted synergies) and output the respective biomarkers in each case. The biomarker results for each predicted synergy will be stored for further comparison with the results from the other cell lines. threshold = 0.7 for (drug.comb in predicted.synergies) { diff = diff.predicted.synergies.results[drug.comb, ] biomarkers.active = diff[diff &gt; threshold] biomarkers.inhibited = diff[diff &lt; -threshold] save_vector_to_file(vector = biomarkers.active, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_active&quot;), with.row.names = TRUE) save_vector_to_file(vector = biomarkers.inhibited, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_inhibited&quot;), with.row.names = TRUE) } threshold = 0.7 for (drug.comb in predicted.synergies) { title.text = paste0(&quot;Prediction of &quot;, drug.comb, &quot; synergy: Good models vs Bad Models&quot;) diff = diff.predicted.synergies.results[drug.comb, ] plot_avg_state_diff_graph(net, diff, layout = nice.layout, title = title.text) } print_biomarkers_per_predicted_synergy(biomarkers.dir, predicted.synergies) Biomarkers for BI-PI synergy predictionActive biomarkers6 nodes: MAPK14, RPS6KA5, DUSP1, MAPK8, APP, SIRT1Inhibited biomarkers6 nodes: FGFR1, TAB1, CASP3, PTPN7, MAX, LATBiomarkers for PI-D1 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: We notice that for some predicted synergies the above method identified zero biomarkers. We will now study cases where the main goal is the better identification and/or refinement of the biomarkers responsible for allowing the models to predict one extra synergy from a specific synergy set. If we find biomarkers for a predicted synergy using this strategy, we compare them to the ones already found with the previous method and if none of them is common we just add the new ones to the list of biomarkers for that specific synergy. On the other hand, if the synergy-set comparison method identifies a subset of the previously found biomarkers for a specific synergy (one common node at least), we will only keep the later method’s biomarkers since we believe that the synergy-set prediction based method is more accurate at identifying biomarkers for a specific synergy because of the fewer models involved in each contrasting category which also minimizes the total false positive synergy predictions taken into account. Note that if the second method finds even more biomarkers than the first, we have the option to prune the end result to only the common biomarkers between the two methods. We will focus our analysis on the predicted synergy BI-PI. Synergy-set prediction based analysis BI-PI synergy The first use case will contrast the models that predicted the synergy set BI-PI,PI-D1 vs the models that predicted the single synergy subset PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-PI synergy: synergy.set.str = &quot;BI-PI,PI-D1&quot; synergy.subset.str = &quot;PI-D1&quot; diff.BI.PI = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.BI.PI.active = diff.BI.PI[diff.BI.PI &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active) 3 nodes: MAPK8, APP, SIRT1 Note that with the previous method of classifying the models (those that predict the BI-PI synergy and those that don’t), we had already identified these 3 active biomarkers. The same holds true for the inhibited biomarkers: biomarkers.BI.PI.inhibited = diff.BI.PI[diff.BI.PI &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited) 2 nodes: CASP3, LAT Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-PI&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.PI.active, biomarkers.BI.PI.inhibited) Biomarker results In this section, we will compare the biomarkers found per predicted synergy for this particular cell line as well as the performance biomarkers (notated as PERF in the heatmap below) which are based on the results from the MCC classification-based model analysis: # Biomarkers from sections: # `Synergy-prediction based analysis`, `Synergy-set prediction based analysis` biomarkers.synergy.res = get_synergy_biomarkers_from_dir(predicted.synergies, biomarkers.dir, models.dir) # store biomarkers in one file save_df_to_file(biomarkers.synergy.res, file = paste0(biomarkers.dir, &quot;biomarkers_per_synergy&quot;)) # Biomarkers from section: # `Performance-related biomarkers` biomarkers.res = add_row_to_ternary_df(df = biomarkers.synergy.res, values.pos = biomarkers.perf.active, values.neg = biomarkers.perf.inhibited, row.name = &quot;PERF&quot;) # prune nodes which are not found as biomarkers for any predicted synergy or # for better model performance biomarkers.res = prune_columns_from_df(biomarkers.res, value = 0) # define a coloring biomarkers.col.fun = colorRamp2(c(-1, 0, 1), c(&quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;)) biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.res), col = biomarkers.col.fun, column_title = paste0(&quot;Biomarker results (&quot;, cell.line, &quot;)&quot;), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = &quot;Predicted synergies&quot;, row_order = nrow(biomarkers.res):1, column_dend_height = unit(0.5, &quot;inches&quot;), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 10), row_names_side = &quot;left&quot;, heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) So, in general we observe that: A total of 18 nodes were found as biomarkers (for at least one synergy) We couldn’t indentify any biomarkers at the \\(0.7\\) threshold for the PI-D1 synergy, while for the BI-PI synergy we found 5 biomarkers The CASP3 biomarker state is found contradictory between the performance-related biomarkers (PERF) and the BI-PI synergy ones. Note though that only 29 models predicted the BI-PI synergy and the performance-related state of that biomarker was produced through the more rigorous MCC classification. Thus, we place a larger confidence on the activity state of the performance-related biomarker result "],
["sw620-model-analysis.html", "SW620 Model Analysis Input Performance Statistics Biomarker analysis", " SW620 Model Analysis This chapter includes the ensemble model analysis performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). All these models were trained towards a specific steady state signaling pattern that was derived based on input data (gene expression, CNV) for the SW620 cell line (colorectal adenocarcinoma, a colon cancer), the use of the PARADIGM software (Vaske et al. 2010) and a topology that was build for simulating a cancer cell fate decision network. The input for the simulations and the output data are in the cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input We will define the name of the cell line which must match the name of the directory that has the input files inside the cell-lines-2500 directory. Our analysis in this chapter will be done on the data for the SW620 cell line: cell.line = &quot;SW620&quot; data.dir = paste0(getwd(), &quot;/&quot;, cell.line, &quot;/&quot;) Three inputs are used in this analysis: The model_predictions file which has for each model the prediction for each drug combination tested (0 = no synergy predicted, 1 = synergy predicted, NA = couldn’t find stable states in either the drug combination inhibited model or in any of the two single-drug inhibited models) The observed_synergies file which lists the drug combinations that were observed as synergistic for the particular cell line. The models directory, which is the same as the models directory produced by Gitsbe and has one .gitsbe file per model that includes this info: The stable state of the boolean model. Note that a model can have 1 stable state or none in our simulations - but the models used in this analysis have been selected through a genetic evolution algorithm in Gitsbe and so in the end, only those with 1 stable state have higher fitness values and remain in the later generations. Higher fitness here means a better match of a model’s stable state to the cell line derived steady state (a perfect match would result in a fitness of 1) The boolean equations of the model models.stable.state.file = paste0(data.dir, &quot;models_stable_state&quot;) observed.synergies.file = paste0(data.dir, &quot;observed_synergies&quot;) model.predictions.file = paste0(data.dir, &quot;model_predictions&quot;) models.equations.file = paste0(data.dir, &quot;models_equations&quot;) models.dir = paste0(data.dir, &quot;models&quot;) Now, we parse the data into proper R objects. First the synergy predictions per model: model.predictions = get_model_predictions(model.predictions.file) # Example: first model&#39;s synergy predictions (first 12 drug combinations) pretty_print_vector_names_and_values(model.predictions[1,], n = 12) 5Z-AK: 0, 5Z-BI: NA, 5Z-CT: 0, 5Z-PD: 0, 5Z-PI: 0, 5Z-PK: 0, 5Z-JN: 0, 5Z-D1: 0, 5Z-60: 0, 5Z-SB: 0, 5Z-RU: 0, 5Z-D4: 0 So, the model.predictions object has the models as rows and each column is a different drug combination that was tested in our simulations. drug.combinations.tested = colnames(model.predictions) models = rownames(model.predictions) nodes = get_node_names(models.dir) number.of.drug.comb.tested = length(drug.combinations.tested) number.of.models = length(models) number.of.nodes = length(nodes) print_model_and_drug_stats(number.of.drug.comb.tested, number.of.models, number.of.nodes, html.output = TRUE) Drug combinations tested: 153Number of models: 7500Number of nodes: 139 Next, we get the full stable state and the equations per model: models.stable.state = as.matrix( read.table(file = models.stable.state.file, check.names = FALSE) ) # Example: first model&#39;s stable state (first 12 nodes) pretty_print_vector_names_and_values(models.stable.state[1,], n = 12) MAP3K7: 1, MAP2K6: 1, MAP2K3: 1, NLK: 1, MAP3K4: 0, MAP2K4: 1, IKBKG: 1, IKBKB: 0, AKT1: 0, BRAF: 0, SMAD3: 1, DAB2IP: 1 The rows of the models.stable.state object represent the models while its columns are the names of the nodes (proteins, genes, etc.) of the cancer cell network under study. So, each model has one stable state which means that in every model, the nodes in the network have reached a state of either 0 (inhibition) or 1 (activation). models.equations = as.matrix( read.table(file = models.equations.file, check.names = FALSE) ) # Example: first model&#39;s link operators (first 12 nodes) pretty_print_vector_names_and_values(models.equations[1,], n = 12) MAP3K4: 0, MAP2K4: 0, IKBKB: 0, AKT1: 0, SMAD3: 1, GSK3B: 1, RAF1: 1, GAB2: 0, CTNNB1: 0, NR3C1: 1, CREB1: 1, RAC1: 1 For the models.equations, if we look at a specific row (a model so to speak), the columns (node names) correspond to the targets of regulation (and the network has been built so that every node is a target - i.e. it has other nodes activating and/or inhibiting it). The general form of a boolean equation is: general.equation = &quot;Target *= (Activator OR Activator OR...) AND NOT (Inhibitor OR Inhibitor OR...)&quot; pretty_print_bold_string(general.equation) Target *= (Activator OR Activator OR…) AND NOT (Inhibitor OR Inhibitor OR…) The difference between the models’ boolean equations is the link operator (OR NOT/AND NOT) which has been mutated (changed) through the evolutionary process of the genetic algorithm in Gitsbe. For example, if a model has for the column ERK_f (of the models.equations object) a value of 1, the correspoding equation is: ERK_f *= (MEK_f) OR NOT ((DUSP6) OR PPP1CA). A value of 0 would correspond to the same equation but having AND NOT as the link operator: ERK_f *= (MEK_f) AND NOT ((DUSP6) OR PPP1CA). Note that the equations that do not have link operators (meaning that they are the same for every model) are discarded (so less columns in this dataset) since in a later section we study only the equations whose link operators differentiate between the models. Lastly, the synergies observed for this particular cell line are: observed.synergies = get_observed_synergies( observed.synergies.file, drug.combinations.tested) number.of.observed.synergies = length(observed.synergies) pretty_print_vector_values(observed.synergies, vector.values.str = &quot;observed synergies&quot;) 11 observed synergies: AK-BI, 5Z-D1, BI-D1, CT-D1, JN-D1, PI-D1, BI-JN, BI-P5, D1-P5, BI-PI, PK-ST Performance Statistics It will be interesting to know the percentage of the above observed synergies that were actually predicted by at least one of the models (there might be combinations that no model in our dataset could predict): # Split model.predictions to positive and negative results observed.model.predictions = get_observed_model_predictions(model.predictions, observed.synergies) unobserved.model.predictions = get_unobserved_model_predictions(model.predictions, observed.synergies) stopifnot(ncol(observed.model.predictions) + ncol(unobserved.model.predictions) == number.of.drug.comb.tested) number.of.models.per.observed.synergy = colSums(observed.model.predictions, na.rm = TRUE) predicted.synergies = names(which(number.of.models.per.observed.synergy &gt; 0)) # predicted synergies is a subset of the observed (positive) ones stopifnot(all(predicted.synergies %in% observed.synergies)) pretty_print_vector_values(predicted.synergies, vector.values.str = &quot;predicted synergies&quot;) 5 predicted synergies: BI-PI, BI-JN, BI-D1, PI-D1, JN-D1 predicted.synergies.percentage = 100 * length(predicted.synergies) / number.of.observed.synergies pretty_print_string(paste0(&quot;Percentage of True Positive predicted synergies: &quot;, specify_decimal(predicted.synergies.percentage, 2), &quot;%&quot;)) Percentage of True Positive predicted synergies: 45.45% So, for this particular cell line, there were indeed observed synergies that no model could predict (e.g.  5Z-D1, AK-BI). Next, we would like to know the maximum number of observed synergies predicted by one model alone - can one model by itself predict all the true positive synergies predicted by all the models together or do we need many models to capture this diverse synergy landscape? To do that, we go even further and count the number of models that predict a specific set of observed synergies for every possible combination subset of the predicted.synergies object: # Find the number of predictive models for every synergy subset synergy.subset.stats = get_synergy_subset_stats(observed.model.predictions, predicted.synergies) # Bar plot of the number of models for every possible observed synergy combination set # Tweak the threshold.for.subset.removal and bottom.margin as desired make_barplot_on_synergy_subset_stats(synergy.subset.stats, threshold.for.subset.removal = 1, bottom.margin = 9, cell.line) From the above figure (where we excluded sets of synergies that were predicted by no model by setting the threshold.for.subset.removal value to 1) we observe that: Most of the models predict none of the observed synergies The PI-D1 synergy is predicted by almost all the rest of the models The 3 two-synergy sets are predicted by the same 2 models that predicted the three-synergy set BI-PI,BI-D1,PI-D1 Next we calculate the maximum number of correctly predicted synergies (\\(TP\\) - True Positives) per model: # Count the predictions of the observed synergies per model (TP) models.synergies.tp = calculate_models_synergies_tp(observed.model.predictions) models.synergies.tp.stats = table(models.synergies.tp) # Bar plot of number of models vs correctly predicted synergies make_barplot_on_models_stats(models.synergies.tp.stats, cell.line, title = &quot;True Positive Synergy Predictions&quot;, xlab = &quot;Number of maximum correctly predicted synergies&quot;, ylab = &quot;Number of models&quot;) To summarize: There were only 2 models that predicted 3 synergies - the set BI-PI,BI-D1,PI-D1 - which is the maximum number of predicted synergies by an individual model No model could predict all 5 of the total predicted synergies The power of the ensemble model approach lies in the fact that (as we saw from the above figures) even though we may not have individual super models that can predict many observed drug combinations, there are many that predict at least one and which will be used by the drug response analysis module (Drabme) to better infer the synergistic drug combinations. It goes without saying though, that the existance of models that could predict more than a handful of synergies would be beneficial for any approach that performs drug response analysis on a multitude of models. Biomarker analysis Intro-Methods Now, we want to investigate and find possible important nodes - biomarkers - whose activity state either distinguishes good performance models from less performant ones (in terms of a performance metric - e.g. the true positive synergies predicted) or makes some models predict a specific synergy compared to others that can’t (but could predict other synergies). So, we devised two strategies to split the models in our disposal to good and bad ones (but not necessarily all of them), the demarcation line being either a performance metric (the number of \\(TP\\) or the Matthews Correlation Coefficient score) or the prediction or not of a specific synergy. Then, for each group of models (labeled as either good or bad) we find the average activity state of every node in the network (value between 0 and 1) and then we compute the average state difference for each node between the two groups: \\(\\forall i\\in nodes,mean(state_i)_{good} - mean(state_i)_{bad}\\). Our hypothesis is that if the absolute value of these average differences are larger than a user-defined threshold (e.g. 0.7) for a small number of nodes (the less the better) while for the rest of the nodes they remain close to zero, then the former nodes are considered the most important since they define the difference between the average bad model and the average good one in that particular case study. We will also deploy a network visualization method to observe these average differences. True Positives-based analysis Using our first strategy, we will split the models based on the number of true positive predictions. For example, the bad models will be the ones that predicted 0 \\(TP\\) synergies whereas the good models will be the ones that predicted 3 \\(TP\\) (we will denote the grouping as \\((0,3)\\)). This particular classification strategy will be used for every possible combination of the number of \\(TP\\) as given by the models.synergies.tp.stats object and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: diff.tp.results = get_avg_activity_diff_mat_based_on_tp_predictions( models, models.synergies.tp, models.stable.state) tp.densities = apply(abs(diff.tp.results), 1, density) make_multiple_density_plot(tp.densities, legend.title = &quot;True Positives&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) What we are actually looking for is density plots that are largely skewed to the right (so the average absolute differences of these nodes are close to zero) while there are a few areas of non-zero densities which are as close to 1 as possible. So, from the above graph, the density plots that fit this description are the ones marked as \\((0,3)\\) and \\((1,3)\\). We will visualize the nodes’ average state differences in a network graph (Csardi and Nepusz 2006), where the color of each node will denote how much more inhibited or active that node is, in the average good model vs the average bad one. The color of the edges will denote activation (green) or inhibition (red). We first build the network from the node topology (edge list): parent.dir = get_parent_dir(data.dir) topology.file = paste0(parent.dir, &quot;/topology&quot;) coordinates.file = paste0(parent.dir, &quot;/network_xy_coordinates&quot;) net = construct_network(topology.file, models.dir) # a static layout for plotting the same network always (igraph) # nice.layout = layout_nicely(net) nice.layout = as.matrix(read.table(coordinates.file)) In the next colored graphs we can identify the important nodes whose activity state can influence the true positive prediction performance (from 0 true positive synergies to a total of 3): plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,3)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (3 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(1,3)&quot;,], layout = nice.layout, title = &quot;Bad models (1 TP) vs Good models (3 TP)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to the number of true positive synergies that they predict. Comparing the graphs above, we observe that there exist common nodes that maintain the same significant influence in all of the graphs. We set the threshold for the absolute significance level in average state differences to \\(0.7\\). A node will be marked as a biomarker (active or inhibited) if its activity state difference surpassed the aforementioned threshold (positively or negatively) for any of the tested groups (e.g. 0 \\(TP\\) vs 3 \\(TP\\)). So, the nodes that have to be in a more active state are: biomarkers.tp.active = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.tp.active) 36 nodes: MAP3K4, AKT1, BRCA1, PRKACA, CTNNB1, TTC3, GSK3A, ROR2, PHLPP1, MAML1, PIK3CA, PtsIns(3,4,5)P3, PI3K, PIK3CG, TCF4, LEF1, MAPK8, MAPK8IP1, APP, SIRT1, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1, SYK, MAP4K1, VAV1 Also, the nodes that have to be in a more inhibited state are: biomarkers.tp.inhibited = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.tp.inhibited) 17 nodes: SMAD3, DAB2IP, GSK3B, PPP1CA, AR, CHEK1, RARA, NR3C1, IRAK1, AKT2, CASP3, GATA6, APC, CEBPA, RXRA, LAT, LCK We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.tp = get_common_values(biomarkers.tp.active, biomarkers.tp.inhibited) No common nodes MCC classification-based analysis The previous method to split the models based on the number of true positive predictions is a good metric for absolute performance but a very restricted one since it ignores the other values of the confusion matrix for each model (true negatives, false positives, false negatives). Also, since our dataset is imbalanced in the sense that out of the total drug combinations tested only a few of them are observed as synergistic (and in a hypothetical larger drug screening evaluation it will be even less true positives) we will now devise a method to split the models into different performance categories based on the value of the Matthews Correlation Coefficient (MCC) score which takes into account the balance ratios of all the four confusion matrix values: # Calculate Matthews Correlation Coefficient (MCC) for every model models.mcc = calculate_models_mcc(observed.model.predictions, unobserved.model.predictions, number.of.drug.comb.tested) models.mcc.stats = table(models.mcc, useNA = &quot;no&quot;) make_barplot_on_models_stats(models.mcc.stats, cell.line, title = &quot;MCC scores&quot;, xlab = &quot;MCC value&quot;, ylab = &quot;Number of models&quot;, cont.values = TRUE) From the above figure we observe that: There are no relatively bad models (MCC values close to -1) Some models (exluding the NaN category) perform close to random prediction (\\(MCC\\approx0\\)) There are models that had NaN value for the MCC score (not shown in the graph above) Given the MCC formula: \\(MCC = (TP\\cdot TN - FP\\cdot FN)/\\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}\\), we can see that the MCC value can be NaN because of zero devision. Two of the four values in the denominator represent the number of positive \\((TP+FN)\\) and negative \\((TN+FP)\\) observations which are non-zero for every model, since they correspond to the observed and non-obsered synergies in each case. The case where both \\(TN\\) and \\(FN\\) are zero is rare (if non-existent) because of the imbalanced dataset (large proportion of negatives) and the reason that logical models which report no negatives means that they should find fixpoint attractors for every possible drug combination perturbation which also is extremely unlikely. We can actually see that the NaN are produced by models that have both TP and FP equal to zero: models.synergies.fp = calculate_models_synergies_fp(unobserved.model.predictions) pretty_print_string(sum(models.synergies.tp + models.synergies.fp == 0)) 73 Since these models could intentify no synergies (either correctly or wrongly), we decided to put them as the lowest performant category in our MCC-based analysis. To classify the models based on their MCC score (which takes values in the \\([-1, 1]\\) interval, NaN values excluded), we will perform a univariate k-means clustering to split the previously found MCC values to different classes (Wang and Song 2011). The MCC classification is presented with a histogram: num.of.classes = 5 mcc.class.ids = 1:num.of.classes models.mcc.no.nan = models.mcc[!is.nan(models.mcc)] models.mcc.no.nan.sorted = sort(models.mcc.no.nan) # find the clusters res = Ckmeans.1d.dp(x = models.mcc.no.nan.sorted, k = num.of.classes) models.cluster.ids = res$cluster plot_mcc_classes_hist(models.mcc.no.nan.sorted, models.cluster.ids, num.of.classes, mcc.class.ids) Note that in total we will have 5 MCC classes in our subsequent analysis, excluding the NaN MCC class, because of the small number of models (73) that belong to this class compared to the other MCC class sizes (the results regarding the MCC classification are very unbalanced, especially if you see the density of the 2nd class above). Following our first strategy, we will split the models based on the MCC performance metric score. For example, the bad models will be the ones that had a NaN MCC score \\((TP+FP = 0)\\) whereas the good models will be the ones that had an MCC score belonging to the first MCC class as seen in the histogram above. This particular classification strategy will be used for every possible combination of the MCC classes and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: mcc.class.id.comb = t(combn(1:length(mcc.class.ids), 2)) diff.mcc.results = apply(mcc.class.id.comb, 1, function(comb) { return(get_avg_activity_diff_based_on_mcc_clustering( models.mcc, models.stable.state, mcc.class.ids, models.cluster.ids, class.id.low = comb[1], class.id.high = comb[2])) }) mcc.classes.comb.names = apply(mcc.class.id.comb, 1, function(comb) { return(paste0(&quot;(&quot;, mcc.class.ids[comb[1]], &quot;,&quot;, mcc.class.ids[comb[2]], &quot;)&quot;)) }) colnames(diff.mcc.results) = mcc.classes.comb.names diff.mcc.results = t(diff.mcc.results) mcc.densities = apply(abs(diff.mcc.results), 1, density) make_multiple_density_plot(mcc.densities, legend.title = &quot;MCC classes&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Many of the density plots above are of interest to us, since they are right skewed. Next, we visualize the average state differences with our network coloring method for 2 of the above cases, in order to identify the important nodes whose activity state can influence the prediction performance based on the MCC classification: plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(1,2)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 1) vs Good models (MCC Class: 2)&quot;) plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(1,5)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 1) vs Good models (MCC Class: 5)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to their MCC classification, using the same method as in the True Positives-based analysis section. First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 6 nodes: DLX5, MAPK14, RPS6KA5, DUSP1, RXRA, PRKCA Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 9 nodes: MAP3K11, FGFR1, TAB1, CASP3, EGFR, PTPN7, MAX, MAPK8IP1, MAPK9 We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.mcc = get_common_values(biomarkers.mcc.active, biomarkers.mcc.inhibited) No common nodes Performance-related biomarkers Comparing the two methods we used for the classification of the models’ prediction performance (TP and MCC), we observe that there exists 1 common biomarker in both active and inhibited state cases while the results regarding the state of the nodes RXRA and MAPK8IP1 are contradictory: common.biomarkers.mixed.1 = get_common_values(biomarkers.mcc.active, biomarkers.tp.inhibited) 1 node: RXRA common.biomarkers.mixed.2 = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.active) 1 node: MAPK8IP1 biomarkers.perf.active = get_common_values(biomarkers.mcc.active, biomarkers.tp.active) 1 node: PRKCA biomarkers.perf.inhibited = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.inhibited) 1 node: CASP3 We believe that the MCC score better captures the performance categories within our imbalanced dataset so we will use the results from the MCC analysis as the performance biomarkers. Lastly, we will save these performance-related biomarkers for further analysis and comparison with the results from all the different cell lines: biomarkers.dir = paste0(data.dir, &quot;biomarkers/&quot;) biomarkers.perf.active = biomarkers.mcc.active biomarkers.perf.inhibited = biomarkers.mcc.inhibited save_vector_to_file(vector = biomarkers.perf.active, file = paste0(biomarkers.dir, &quot;biomarkers_active&quot;)) save_vector_to_file(vector = biomarkers.perf.inhibited, file = paste0(biomarkers.dir, &quot;biomarkers_inhibited&quot;)) Equation-based analysis It will be interesting to see the different patterns in the form of the boolean equations (regarding the mutation of the link operator as mentioned in the Input section) when comparing higher performance models vs the low performant ones. We could also check if any of the biomarkers found above relate to a different link operator on average between models with different performance characteristics (e.g. higher predictive models should have the OR NOT as the link operator in a boolean equation where a specific biomarker is the regulation target) or if they constitute targets of exclusively activating nodes or inhibiting ones (an equation with no link operator). The performance metric we will first use to sort the models is the number of true positive predictions. We will now illustrate the heatmap of the models.equations object raw-order by the number of \\(TP\\) predictions: # order based on number of true positives models.synergies.tp.sorted = sort(models.synergies.tp) models.sorted = names(models.synergies.tp.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring eq.link.colors = c(&quot;red&quot;, &quot;lightyellow&quot;) eq.link.col.fun = colorRamp2(breaks = c(0, 1), colors = eq.link.colors) tp.values = sort(unique(models.synergies.tp)) tp.col.fun = colorRamp2(breaks = c(min(tp.values), max(tp.values)), colors = c(&quot;red&quot;, &quot;green&quot;)) # color biomarker names in the heatmap bottom.nodes.colors = rep(&quot;black&quot;, length(colnames(models.equations.sorted))) names(bottom.nodes.colors) = colnames(models.equations.sorted) bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.active] = &quot;blue&quot; bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.inhibited] = &quot;magenta&quot; # define the TP color bar tp.annot = rowAnnotation( tp = anno_simple(x = models.synergies.tp.sorted, col = tp.col.fun), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (TP sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = tp.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 3 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) tp.values = min(tp.values):max(tp.values) # maybe some integers are missing tp.legend = Legend(at = tp.values, title = &quot;TP&quot;, legend_gp = gpar(fill = tp.col.fun(tp.values))) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, tp.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the heatmap above, an equation whose link operator is AND NOT is represented with red color while an OR NOT link operator is represented with light yellow color. The targets whose equations do not have a link operator are not represented. The rows are ordered by the number of true positive predictions (ascending). We have colored the names of the network nodes that were also found as biomarkers (green color is used for the active biomarkers and red color for the inhibited biomarkers). We observe that: Most of the biomarkers are nodes that do not have both activators and inhibitors and so are absent from the above heatmap There doesn’t seem to exist a pattern between the models’ link operators and their corresponding performance (at least not for all of the nodes) when using the true positive predictions as a classifier for the models (since most of the models predict no \\(TP\\) synergies) There exist a lot of target nodes that need to have the OR NOT link operator in their respective boolean equation in order for the corresponding logical model to show a higher number of true positive predictions. By assigning the OR NOT link operator to a target’s boolean regulation equation, we allow more flexibility to the target’s output active result state - meaning that the inhibitors play less role and the output state has a higher probability of being active - compared to assigning the AND NOT link operator to the equation We will also illustrate the heatmap of the models.equations object raw-order by the MCC score which is a better performance classifier. Models who had a NaN MCC score will be again placed in the lower performant category: # order based on the MCC value models.mcc.sorted = sort(models.mcc, na.last = FALSE) models.sorted = names(models.mcc.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring mcc.col.fun = colorRamp2(breaks = c(min(models.mcc.no.nan), max(models.mcc.no.nan)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define the MCC color bar mcc.annot = rowAnnotation( mcc = anno_simple(x = models.mcc.sorted, col = mcc.col.fun, na_col = &quot;black&quot;), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (MCC sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = mcc.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 4 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) mcc.legend = Legend(title = &quot;MCC&quot;, col_fun = mcc.col.fun) na.legend = Legend(labels = &quot;NA&quot;, legend_gp = gpar(fill = &quot;black&quot;)) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, mcc.legend, na.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the MCC-ordered heatmap above we observe that there is better correlation between the boolean equations’ link operators and the performance of a model compared to the \\(TP\\) classification. For example, the biomarkers CASP3 and MAPK14 show distinguished patterns for the higher performance models (use of AND NOT and OR NOT link operators respectively) when the models are sorted by the MCC score. Synergy-prediction based analysis We will now use the second strategy to split the models, based on whether they predict a specific observed synergy or not. This will allow us to find biomarkers that affect the prediction of a specific synergy. For example, the good models could be the ones that predicted the hypothetical synergy A-B while the bad models all the rest that identified the particular combination as non-synergistic. In another case scenario, the good models could be those that predicted a triple synergy set A-B,C-D,A-C, while the bad models could be the ones that predicted the double synergy subset A-B,C-D (excluding the common models that predicted both the triple synergy set and subsequently its given subset). In such a case scenario, we want to find out which nodes are responsible for making the good models predict the extra synergy - in this hypothetical case the synergy A-C - demonstrating thus better model performance. Note that the models selected in each case as good or bad, could have predicted other synergies as well (correctly as \\(TP\\) or wrongly as \\(FP\\)) which means that the biomarker selection method could be somewhat innacurate, since we can’t really know the prediction of which extra synergy or synergies the biomarkers’ state affected. To account for this, we label as good models those that predict large synergy sets (so fewer models) which capture almost all the true positive predictions and also minimize the possible extra different synergies predicted by models of the same classification category (e.g. the good models). Starting with the first model classification method (prediction vs non-prediction of a particular synergy), we generate the density distribution of the nodes’ average state differences between the good and bad models for each predicted synergy: diff.predicted.synergies.results = sapply(predicted.synergies, function(drug.comb) { get_avg_activity_diff_based_on_specific_synergy_prediction( model.predictions, models.stable.state, drug.comb) }) diff.predicted.synergies.results = t(diff.predicted.synergies.results) densities = apply(abs(diff.predicted.synergies.results), 1, density) make_multiple_density_plot(densities, legend.title = &quot;Predicted Synergies&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Next, we will plot the biomarkers with the network visualization method (for all predicted synergies) and output the respective biomarkers in each case. The biomarker results for each predicted synergy will be stored for further comparison with the results from the other cell lines. Note though that because of the small number of models that predict some of the observed synergies (e.g. BI-PI and BI-JN) we expect to find a lot of false positive biomarkers for these synergies using this method. threshold = 0.7 for (drug.comb in predicted.synergies) { diff = diff.predicted.synergies.results[drug.comb, ] biomarkers.active = diff[diff &gt; threshold] biomarkers.inhibited = diff[diff &lt; -threshold] save_vector_to_file(vector = biomarkers.active, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_active&quot;), with.row.names = TRUE) save_vector_to_file(vector = biomarkers.inhibited, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_inhibited&quot;), with.row.names = TRUE) } threshold = 0.7 for (drug.comb in predicted.synergies) { title.text = paste0(&quot;Prediction of &quot;, drug.comb, &quot; synergy: Good models vs Bad Models&quot;) diff = diff.predicted.synergies.results[drug.comb, ] plot_avg_state_diff_graph(net, diff, layout = nice.layout, title = title.text) } print_biomarkers_per_predicted_synergy(biomarkers.dir, predicted.synergies) Biomarkers for BI-PI synergy predictionActive biomarkers32 nodes: MAP3K4, AKT1, BRCA1, PRKACA, TTC3, GSK3A, ROR2, PHLPP1, MAML1, PIK3CA, PtsIns(3,4,5)P3, PI3K, PIK3CG, MAPK8, APP, SIRT1, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1, SYK, MAP4K1, VAV1Inhibited biomarkers15 nodes: SMAD3, DAB2IP, GSK3B, PPP1CA, AR, CHEK1, RARA, NR3C1, IRAK1, CASP3, GATA6, APC, MAPK9, LAT, LCKBiomarkers for BI-JN synergy predictionActive biomarkers36 nodes: DLX5, GSK3A, MAPK14, AKT3, RPS6KA5, DUSP1, PSEN1, IRS1, PIK3CA, PtsIns(3,4,5)P3, MAPK8, APP, SIRT1, JAK1, TYK2, JAK3, IFNGR2/INFGR1, IFNGR1, PTPN11, IFNGR2, IL2RB, IL10RA, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1, FOXO3Inhibited biomarkers29 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, MAP2K4, IKBKG, MAP3K11, FGFR1, TAB1, CASP3, STAT3, EGFR, PTPN7, MAX, GATA6, MYC, JNK, LAT, SIRT2, CUL1, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1Biomarkers for BI-D1 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers1 node: CASP3Biomarkers for PI-D1 synergy predictionActive biomarkers15 nodes: AKT, PtsIns(3,4,5)P3, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1Inhibited biomarkers0 nodes: Biomarkers for JN-D1 synergy predictionActive biomarkers10 nodes: MAP3K11, FGFR1, TAB1, EGFR, PTPN7, MAX, MAPK8, MAPK8IP1, APP, SIRT1Inhibited biomarkers7 nodes: DLX5, NR3C1, MAPK14, RPS6KA5, DUSP1, RXRA, LAT We notice that for some predicted synergies the above method identified zero biomarkers. We will now study cases where the main goal is the better identification and/or refinement of the biomarkers responsible for allowing the models to predict one extra synergy from a specific synergy set. If we find biomarkers for a predicted synergy using this strategy, we compare them to the ones already found with the previous method and if none of them is common we just add the new ones to the list of biomarkers for that specific synergy. On the other hand, if the synergy-set comparison method identifies a subset of the previously found biomarkers for a specific synergy (one common node at least), we will only keep the later method’s biomarkers since we believe that the synergy-set prediction based method is more accurate at identifying biomarkers for a specific synergy because of the fewer models involved in each contrasting category which also minimizes the total false positive synergy predictions taken into account. Note that if the second method finds even more biomarkers than the first, we have the option to prune the end result to only the common biomarkers between the two methods. We will focus our analysis on the predicted synergy BI-PI. Synergy-set prediction based analysis BI-PI synergy Observing the figure titled Model Synergy Predictions per Observed synergy Subset, we see that the only predicted synergy set with more than one element is the BI-PI,BI-D1,PI-D1 set (remember that the 3 two-synergy sets in that figure are predicted by the same 2 models that predicted the three-synergy set BI-PI,BI-D1,PI-D1). So, the only synergy-set comparisons we can test here are between that three-synergy set and each one of its elements (exlucing the BI-PI synergy, because it was predicted by the same 2 models). In short we can compare: BI-D1 vs BI-PI,BI-D1,PI-D1, which will give us biomarkers for the synergy set BI-PI,PI-D1 and PI-D1 vs BI-PI,BI-D1,PI-D1, which will give us biomarkers for the synergy set BI-PI,BI-D1 Then, we can compare these two results to identify biomarkers for the synergy BI-PI. synergy.set.str.1 = &quot;BI-PI,BI-D1,PI-D1&quot; synergy.subset.str.1 = &quot;BI-D1&quot; diff.BI.PI.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;BI-PI,BI-D1,PI-D1&quot; synergy.subset.str.2 = &quot;PI-D1&quot; diff.BI.PI.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI.2, layout = nice.layout, title = title.text) We now report the active biomarkers for each of the two comparisons and find the common ones: biomarkers.BI.PI.active.1 = diff.BI.PI.1[diff.BI.PI.1 &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active.1) 29 nodes: MAP3K4, CTNNB1, CREB1, GSK3A, ROR2, PHLPP1, MAML1, MAPK1, MAPK3, MAP2K2, PIK3CA, PtsIns(3,4,5)P3, PI3K, PIK3CG, TCF4, LEF1, PTK2, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, SGK3, PRKCB, PRKCG, PAK1 biomarkers.BI.PI.active.2 = diff.BI.PI.2[diff.BI.PI.2 &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active.2) 19 nodes: MAP3K4, AKT1, BRCA1, PRKACA, CTNNB1, TTC3, GSK3A, ROR2, PHLPP1, MAML1, TCF4, LEF1, MAPK8, MAPK8IP1, APP, SIRT1, SYK, MAP4K1, VAV1 biomarkers.BI.PI.active.common.1.2 = get_common_names(biomarkers.BI.PI.active.1, biomarkers.BI.PI.active.2) 8 nodes: MAP3K4, CTNNB1, GSK3A, ROR2, PHLPP1, MAML1, TCF4, LEF1 biomarkers.BI.PI.active = biomarkers.BI.PI.active.1[names(biomarkers.BI.PI.active.1) %in% names(biomarkers.BI.PI.active.2)] We do the same for the inhibited biomarkers: biomarkers.BI.PI.inhibited.1 = diff.BI.PI.1[diff.BI.PI.1 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited.1) 9 nodes: SMAD3, GSK3B, NR3C1, GATA6, PTEN, APC, CEBPA, MAPK9, PPM1A biomarkers.BI.PI.inhibited.2 = diff.BI.PI.2[diff.BI.PI.2 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited.2) 18 nodes: SMAD3, DAB2IP, GSK3B, PPP1CA, AR, CHEK1, RARA, NR3C1, IRAK1, AKT2, AKT3, GATA6, AKT, APC, CEBPA, RXRA, LAT, LCK biomarkers.BI.PI.inhibited.common.1.2 = get_common_names(biomarkers.BI.PI.inhibited.1, biomarkers.BI.PI.inhibited.2) 6 nodes: SMAD3, GSK3B, NR3C1, GATA6, APC, CEBPA biomarkers.BI.PI.inhibited = biomarkers.BI.PI.inhibited.1[names(biomarkers.BI.PI.inhibited.1) %in% names(biomarkers.BI.PI.inhibited.2)] Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-PI&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.PI.active, biomarkers.BI.PI.inhibited) Biomarker results In this section, we will compare the biomarkers found per predicted synergy for this particular cell line as well as the performance biomarkers (notated as PERF in the heatmap below) which were found using the results from the MCC classification-based model analysis: # Biomarkers from sections: # `Synergy-prediction based analysis`, `Synergy-set prediction based analysis` biomarkers.synergy.res = get_synergy_biomarkers_from_dir(predicted.synergies, biomarkers.dir, models.dir) # store biomarkers in one file save_df_to_file(biomarkers.synergy.res, file = paste0(biomarkers.dir, &quot;biomarkers_per_synergy&quot;)) # Biomarkers from section: # `Performance-related biomarkers` biomarkers.res = add_row_to_ternary_df(df = biomarkers.synergy.res, values.pos = biomarkers.perf.active, values.neg = biomarkers.perf.inhibited, row.name = &quot;PERF&quot;) # prune nodes which are not found as biomarkers for any predicted synergy or # for better model performance biomarkers.res = prune_columns_from_df(biomarkers.res, value = 0) # define a coloring biomarkers.col.fun = colorRamp2(c(-1, 0, 1), c(&quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;)) biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.res), col = biomarkers.col.fun, column_title = paste0(&quot;Biomarker results (&quot;, cell.line, &quot;)&quot;), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = &quot;Predicted synergies&quot;, row_order = nrow(biomarkers.res):1, column_dend_height = unit(1, &quot;inches&quot;), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 7), row_names_side = &quot;left&quot;, heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) So, in general we observe that: A total of 81 nodes were found as biomarkers (for at least one synergy) We found a lot of biomarkers for some of the predicted synergies. Usually we wouldn’t expect too many biomarkers that are directly related to the prediction of a specific synergy. The abudance of (false positive) biomarkers for some synergies (e.g. BI-JN) relates to the model classification method used, which does not incorporate in its internal logic that the prediction of other synergies than the ones used for the grouping itself can affect the biomarker results obtained from it. Also, as stated previously, when comparing unequal size groups where only a small number of models have predicted a specific synergy, you get many false positive biomarkers as well All the performance-related biomarkers (PERF) with the exception of MAPK9 node, were also observed as biomarkers for the prediction of a specific synergy(ies) The states of the performance-related biomarkers (PERF) are contradictory with the states of the same biomarkers as found for the JN-D1 synergy There exist common biomarkers across different predicted synergies, e.g. LAT is a common inhibited biomarker across 2 synergistic drug combinations The results between the different synergies are sometimes contradictory, meaning that there are active biomarkers for a particular synergy that were found as inhibited in another and vise versa (e.g. the MAX biomarker) "],
["sf295-model-analysis.html", "SF295 Model Analysis Input Performance Statistics Biomarker analysis", " SF295 Model Analysis This chapter includes the ensemble model analysis performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). All these models were trained towards a specific steady state signaling pattern that was derived based on input data (gene expression, CNV) for the SF295 cell line, the (Glioblastoma, a brain cancer), the use of the PARADIGM software (Vaske et al. 2010) and a topology that was build for simulating a cancer cell fate decision network. The input for the simulations and the output data are in the cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input We will define the name of the cell line which must match the name of the directory that has the input files inside the cell-lines-2500 directory. Our analysis in this chapter will be done on the data for the SF295 cell line: cell.line = &quot;SF295&quot; data.dir = paste0(getwd(), &quot;/&quot;, cell.line, &quot;/&quot;) Three inputs are used in this analysis: The model_predictions file which has for each model the prediction for each drug combination tested (0 = no synergy predicted, 1 = synergy predicted, NA = couldn’t find stable states in either the drug combination inhibited model or in any of the two single-drug inhibited models) The observed_synergies file which lists the drug combinations that were observed as synergistic for the particular cell line. The models directory, which is the same as the models directory produced by Gitsbe and has one .gitsbe file per model that includes this info: The stable state of the boolean model. Note that a model can have 1 stable state or none in our simulations - but the models used in this analysis have been selected through a genetic evolution algorithm in Gitsbe and so in the end, only those with 1 stable state have higher fitness values and remain in the later generations. Higher fitness here means a better match of a model’s stable state to the cell line derived steady state (a perfect match would result in a fitness of 1) The boolean equations of the model models.stable.state.file = paste0(data.dir, &quot;models_stable_state&quot;) observed.synergies.file = paste0(data.dir, &quot;observed_synergies&quot;) model.predictions.file = paste0(data.dir, &quot;model_predictions&quot;) models.equations.file = paste0(data.dir, &quot;models_equations&quot;) models.dir = paste0(data.dir, &quot;models&quot;) Now, we parse the data into proper R objects. First the synergy predictions per model: model.predictions = get_model_predictions(model.predictions.file) # Example: first model&#39;s synergy predictions (first 12 drug combinations) pretty_print_vector_names_and_values(model.predictions[1,], n = 12) 5Z-AK: 0, 5Z-BI: NA, 5Z-CT: NA, 5Z-PD: 0, 5Z-PI: 0, 5Z-PK: 0, 5Z-JN: 0, 5Z-D1: 0, 5Z-60: 0, 5Z-SB: 0, 5Z-RU: 0, 5Z-D4: 0 So, the model.predictions object has the models as rows and each column is a different drug combination that was tested in our simulations. drug.combinations.tested = colnames(model.predictions) models = rownames(model.predictions) nodes = get_node_names(models.dir) number.of.drug.comb.tested = length(drug.combinations.tested) number.of.models = length(models) number.of.nodes = length(nodes) print_model_and_drug_stats(number.of.drug.comb.tested, number.of.models, number.of.nodes, html.output = TRUE) Drug combinations tested: 153Number of models: 7500Number of nodes: 139 Next, we get the full stable state and the equations per model: models.stable.state = as.matrix( read.table(file = models.stable.state.file, check.names = FALSE) ) # Example: first model&#39;s stable state (first 12 nodes) pretty_print_vector_names_and_values(models.stable.state[1,], n = 12) MAP3K7: 0, MAP2K6: 0, MAP2K3: 0, NLK: 0, MAP3K4: 0, MAP2K4: 1, IKBKG: 0, IKBKB: 1, AKT1: 0, BRAF: 0, SMAD3: 0, DAB2IP: 1 The rows of the models.stable.state object represent the models while its columns are the names of the nodes (proteins, genes, etc.) of the cancer cell network under study. So, each model has one stable state which means that in every model, the nodes in the network have reached a state of either 0 (inhibition) or 1 (activation). models.equations = as.matrix( read.table(file = models.equations.file, check.names = FALSE) ) # Example: first model&#39;s link operators (first 12 nodes) pretty_print_vector_names_and_values(models.equations[1,], n = 12) MAP3K4: 1, MAP2K4: 1, IKBKB: 1, AKT1: 0, SMAD3: 0, GSK3B: 1, RAF1: 0, GAB2: 0, CTNNB1: 1, NR3C1: 0, CREB1: 0, RAC1: 1 For the models.equations, if we look at a specific row (a model so to speak), the columns (node names) correspond to the targets of regulation (and the network has been built so that every node is a target - i.e. it has other nodes activating and/or inhibiting it). The general form of a boolean equation is: general.equation = &quot;Target *= (Activator OR Activator OR...) AND NOT (Inhibitor OR Inhibitor OR...)&quot; pretty_print_bold_string(general.equation) Target *= (Activator OR Activator OR…) AND NOT (Inhibitor OR Inhibitor OR…) The difference between the models’ boolean equations is the link operator (OR NOT/AND NOT) which has been mutated (changed) through the evolutionary process of the genetic algorithm in Gitsbe. For example, if a model has for the column ERK_f (of the models.equations object) a value of 1, the correspoding equation is: ERK_f *= (MEK_f) OR NOT ((DUSP6) OR PPP1CA). A value of 0 would correspond to the same equation but having AND NOT as the link operator: ERK_f *= (MEK_f) AND NOT ((DUSP6) OR PPP1CA). Note that the equations that do not have link operators (meaning that they are the same for every model) are discarded (so less columns in this dataset) since in a later section we study only the equations whose link operators differentiate between the models. Lastly, the synergies observed for this particular cell line are: observed.synergies = get_observed_synergies( observed.synergies.file, drug.combinations.tested) number.of.observed.synergies = length(observed.synergies) pretty_print_vector_values(observed.synergies, vector.values.str = &quot;observed synergies&quot;) 23 observed synergies: AK-60, PI-60, AK-BI, AK-D1, BI-D1, JN-D1, PI-D1, AK-G2, PI-G2, AK-JN, BI-JN, PI-JN, AK-P5, BI-P5, D1-P5, G2-P5, JN-P5, PI-P5, AK-PI, BI-PI, CT-PI, AK-ST, PK-ST Performance Statistics It will be interesting to know the percentage of the above observed synergies that were actually predicted by at least one of the models (there might be combinations that no model in our dataset could predict): combinations that no model in our dataset could predict): # Split model.predictions to positive and negative results observed.model.predictions = get_observed_model_predictions(model.predictions, observed.synergies) unobserved.model.predictions = get_unobserved_model_predictions(model.predictions, observed.synergies) stopifnot(ncol(observed.model.predictions) + ncol(unobserved.model.predictions) == number.of.drug.comb.tested) number.of.models.per.observed.synergy = colSums(observed.model.predictions, na.rm = TRUE) predicted.synergies = names(which(number.of.models.per.observed.synergy &gt; 0)) # predicted synergies is a subset of the observed (positive) ones stopifnot(all(predicted.synergies %in% observed.synergies)) pretty_print_vector_values(predicted.synergies, vector.values.str = &quot;predicted synergies&quot;) 5 predicted synergies: BI-PI, BI-D1, PI-D1, JN-D1, D1-P5 predicted.synergies.percentage = 100 * length(predicted.synergies) / number.of.observed.synergies pretty_print_string(paste0(&quot;Percentage of True Positive predicted synergies: &quot;, specify_decimal(predicted.synergies.percentage, 2), &quot;%&quot;)) Percentage of True Positive predicted synergies: 21.74% So, for this particular cell line, there were indeed observed synergies that no model could predict (e.g.  AK-BI, AK-PI). Next, we would like to know the maximum number of observed synergies predicted by one model alone - can one model by itself predict all the true positive synergies predicted by all the models together or do we need many models to capture this diverse synergy landscape? To do that, we go even further and count the number of models that predict a specific set of observed synergies for every possible combination subset of the predicted.synergies object: # Find the number of predictive models for every synergy subset synergy.subset.stats = get_synergy_subset_stats(observed.model.predictions, predicted.synergies) # Bar plot of the number of models for every possible observed synergy combination set # Tweak the threshold.for.subset.removal and bottom.margin as desired make_barplot_on_synergy_subset_stats(synergy.subset.stats, threshold.for.subset.removal = 1, bottom.margin = 9, cell.line) From the above figure (where we excluded sets of synergies that were predicted by no model by setting the threshold.for.subset.removal value to 1) we observe that: Most of the models predict none of the observed synergies The PI-D1 synergy is predicted by almost all the rest of the models Next we calculate the maximum number of correctly predicted synergies (\\(TP\\) - True Positives) per model: # Count the predictions of the observed synergies per model (TP) models.synergies.tp = calculate_models_synergies_tp(observed.model.predictions) models.synergies.tp.stats = table(models.synergies.tp) # Bar plot of number of models vs correctly predicted synergies make_barplot_on_models_stats(models.synergies.tp.stats, cell.line, title = &quot;True Positive Synergy Predictions&quot;, xlab = &quot;Number of maximum correctly predicted synergies&quot;, ylab = &quot;Number of models&quot;) To summarize: There were only 17 models that predicted 3 synergies - the set BI-PI,BI-D1,PI-D1 - which is the maximum number of predicted synergies by an individual model No model could predict all 5 of the total predicted synergies The power of the ensemble model approach lies in the fact that (as we saw from the above figures) even though we may not have individual super models that can predict many observed drug combinations, there are many that predict at least one and which will be used by the drug response analysis module (Drabme) to better infer the synergistic drug combinations. It goes without saying though, that the existance of models that could predict more than a handful of synergies would be beneficial for any approach that performs drug response analysis on a multitude of models. Biomarker analysis Intro-Methods Now, we want to investigate and find possible important nodes - biomarkers - whose activity state either distinguishes good performance models from less performant ones (in terms of a performance metric - e.g. the true positive synergies predicted) or makes some models predict a specific synergy compared to others that can’t (but could predict other synergies). So, we devised two strategies to split the models in our disposal to good and bad ones (but not necessarily all of them), the demarcation line being either a performance metric (the number of \\(TP\\) or the Matthews Correlation Coefficient score) or the prediction or not of a specific synergy. Then, for each group of models (labeled as either good or bad) we find the average activity state of every node in the network (value between 0 and 1) and then we compute the average state difference for each node between the two groups: \\(\\forall i\\in nodes,mean(state_i)_{good} - mean(state_i)_{bad}\\). Our hypothesis is that if the absolute value of these average differences are larger than a user-defined threshold (e.g. 0.7) for a small number of nodes (the less the better) while for the rest of the nodes they remain close to zero, then the former nodes are considered the most important since they define the difference between the average bad model and the average good one in that particular case study. We will also deploy a network visualization method to observe these average differences. True Positives-based analysis Using our first strategy, we will split the models based on the number of true positive predictions. For example, the bad models will be the ones that predicted 0 \\(TP\\) synergies whereas the good models will be the ones that predicted 2 \\(TP\\) (we will denote the grouping as \\((0,2)\\)). This particular classification strategy will be used for every possible combination of the number of \\(TP\\) as given by the models.synergies.tp.stats object and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: diff.tp.results = get_avg_activity_diff_mat_based_on_tp_predictions( models, models.synergies.tp, models.stable.state) tp.densities = apply(abs(diff.tp.results), 1, density) make_multiple_density_plot(tp.densities, legend.title = &quot;True Positives&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) What we are actually looking for is density plots that are largely skewed to the right (so the average absolute differences of these nodes are close to zero) while there are a few areas of non-zero densities which are as close to 1 as possible. So, from the above graph, the density plots that fit this description are the ones marked as \\((0,3)\\) and \\((2,3)\\). We will visualize the nodes’ average state differences in a network graph (Csardi and Nepusz 2006), where the color of each node will denote how much more inhibited or active that node is, in the average good model vs the average bad one. The color of the edges will denote activation (green) or inhibition (red). We first build the network from the node topology (edge list): parent.dir = get_parent_dir(data.dir) topology.file = paste0(parent.dir, &quot;/topology&quot;) coordinates.file = paste0(parent.dir, &quot;/network_xy_coordinates&quot;) net = construct_network(topology.file, models.dir) # a static layout for plotting the same network always (igraph) # nice.layout = layout_nicely(net) nice.layout = as.matrix(read.table(coordinates.file)) In the next colored graphs we can identify the important nodes whose activity state can influence the true positive prediction performance (from 0 true positive synergies to a total of 3): plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,3)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (3 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(1,3)&quot;,], layout = nice.layout, title = &quot;Bad models (1 TP) vs Good models (3 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(2,3)&quot;,], layout = nice.layout, title = &quot;Bad models (2 TP) vs Good models (3 TP)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to the number of true positive synergies that they predict. Comparing the graphs above, we observe that there exist common nodes that maintain the same significant influence in all of the graphs. We set the threshold for the absolute significance level in average state differences to \\(0.7\\). A node will be marked as a biomarker (active or inhibited) if its activity state difference surpassed the aforementioned threshold (positively or negatively) for any of the tested groups (e.g. 2 \\(TP\\) vs 3 \\(TP\\)). So, the nodes that have to be in a more active state are: biomarkers.tp.active = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.tp.active) 4 nodes: PSEN1, MAPK8IP1, MAPK8IP3, MAPK9 Also, the nodes that have to be in a more inhibited state are: biomarkers.tp.inhibited = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.tp.inhibited) 1 node: RXRA We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.tp = get_common_values(biomarkers.tp.active, biomarkers.tp.inhibited) No common nodes MCC classification-based analysis The previous method to split the models based on the number of true positive predictions is a good metric for absolute performance but a very restricted one since it ignores the other values of the confusion matrix for each model (true negatives, false positives, false negatives). Also, since our dataset is imbalanced in the sense that out of the total drug combinations tested only a few of them are observed as synergistic (and in a hypothetical larger drug screening evaluation it will be even less true positives) we will now devise a method to split the models into different performance categories based on the value of the Matthews Correlation Coefficient (MCC) score which takes into account the balance ratios of all the four confusion matrix values: # Calculate Matthews Correlation Coefficient (MCC) for every model models.mcc = calculate_models_mcc(observed.model.predictions, unobserved.model.predictions, number.of.drug.comb.tested) models.mcc.stats = table(models.mcc, useNA = &quot;ifany&quot;) make_barplot_on_models_stats(models.mcc.stats, cell.line, title = &quot;MCC scores&quot;, xlab = &quot;MCC value&quot;, ylab = &quot;Number of models&quot;, cont.values = TRUE) From the above figure we observe that: There are no relatively bad models (MCC values close to -1) Most of the models (exluding the NaN category) perform a little better than random prediction (\\(MCC&gt;0\\)) There are models that had NaN value for the MCC score Given the MCC formula: \\(MCC = (TP\\cdot TN - FP\\cdot FN)/\\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}\\), we can see that the MCC value can be NaN because of zero devision. Two of the four values in the denominator represent the number of positive \\((TP+FN)\\) and negative \\((TN+FP)\\) observations which are non-zero for every model, since they correspond to the observed and non-obsered synergies in each case. The case where both \\(TN\\) and \\(FN\\) are zero is rare (if non-existent) because of the imbalanced dataset (large proportion of negatives) and the reason that logical models which report no negatives means that they should find fixpoint attractors for every possible drug combination perturbation which also is extremely unlikely. We can actually see that the NaN are produced by models that have both TP and FP equal to zero: models.synergies.fp = calculate_models_synergies_fp(unobserved.model.predictions) pretty_print_string(sum(models.synergies.tp + models.synergies.fp == 0)) 3400 Since these models could intentify no synergies (either correctly or wrongly), we decided to put them as the lowest performant category in our MCC-based analysis. To classify the models based on their MCC score (which takes values in the \\([-1, 1]\\) interval, NaN values excluded), we will perform a univariate k-means clustering to split the previously found MCC values to different classes (Wang and Song 2011). The MCC classification is presented with a histogram: num.of.classes = 5 mcc.class.ids = 1:num.of.classes models.mcc.no.nan = models.mcc[!is.nan(models.mcc)] models.mcc.no.nan.sorted = sort(models.mcc.no.nan) # find the clusters res = Ckmeans.1d.dp(x = models.mcc.no.nan.sorted, k = num.of.classes) models.cluster.ids = res$cluster plot_mcc_classes_hist(models.mcc.no.nan.sorted, models.cluster.ids, num.of.classes, mcc.class.ids) Note that in total we have 6 MCC classes, since the NaN MCC values constitute a class on its own. Following our first strategy, we will split the models based on the MCC performance metric score. For example, the bad models will be the ones that had a NaN MCC score \\((TP+FP = 0)\\) whereas the good models will be the ones that had an MCC score belonging to the first MCC class as seen in the histogram above. This particular classification strategy will be used for every possible combination of the MCC classes and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: # add NaN class (if applicable) if (sum(is.nan(models.mcc)) &gt; 0) { mcc.class.ids = append(mcc.class.ids, values = NaN, after = 0) } mcc.class.id.comb = t(combn(1:length(mcc.class.ids), 2)) diff.mcc.results = apply(mcc.class.id.comb, 1, function(comb) { return(get_avg_activity_diff_based_on_mcc_clustering( models.mcc, models.stable.state, mcc.class.ids, models.cluster.ids, class.id.low = comb[1], class.id.high = comb[2])) }) mcc.classes.comb.names = apply(mcc.class.id.comb, 1, function(comb) { return(paste0(&quot;(&quot;, mcc.class.ids[comb[1]], &quot;,&quot;, mcc.class.ids[comb[2]], &quot;)&quot;)) }) colnames(diff.mcc.results) = mcc.classes.comb.names diff.mcc.results = t(diff.mcc.results) mcc.densities = apply(abs(diff.mcc.results), 1, density) make_multiple_density_plot(mcc.densities, legend.title = &quot;MCC classes&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;, legend.size = 0.8) Many of the density plots above are of interest to us, since they are right skewed. Next, we visualize the average state differences with our network coloring method for 2 of the above cases, in order to identify the important nodes whose activity state can influence the prediction performance based on the MCC classification: plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(NaN,3)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: NaN) vs Good models (MCC Class: 3)&quot;) plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(1,5)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 1) vs Good models (MCC Class: 5)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to their MCC classification, using the same method as in the True Positives-based analysis section. First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 1 node: PSEN1 Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 1 node: PSEN1 Since we identified only one (common) biomarker in each category state, we will use a less strict threshold for identifying further biomarkers. First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.6, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 12 nodes: GSK3B, AKT2, GSK3B/Axin/APC, MYC, APC, LRP6, PSEN1, ROR2, PHLPP1, MAML1, SIRT2, CUL1 Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.6, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 12 nodes: GSK3B, AKT2, GSK3B/Axin/APC, MYC, APC, LRP6, PSEN1, ROR2, PHLPP1, MAML1, SIRT2, CUL1 We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.mcc = get_common_values(biomarkers.mcc.active, biomarkers.mcc.inhibited) 12 nodes: GSK3B, AKT2, GSK3B/Axin/APC, MYC, APC, LRP6, PSEN1, ROR2, PHLPP1, MAML1, SIRT2, CUL1 Since there are common nodes that were found to surpass the significance threshold level for the average state difference between two MCC classes both negatively and positively, we will keep these biomarkers only in the state which corresponds to the comparison of the highest classification categories. For example, if for the comparison of the MCC classes \\((1,3)\\) the node of interest had an average difference of \\(-0.89\\) while for the comparison of the \\((3,4)\\) MCC classes it had a value of \\(0.91\\), then we will keep that node only in the active biomarker list. The logic behind this is that the higher the MCC classes we compare, the more sure we are that the average state difference corresponds to a better indicator of the state of the biomarker found. # remove the common biomarkers biomarkers.mcc.active = biomarkers.mcc.active[!biomarkers.mcc.active %in% common.biomarkers.mcc] biomarkers.mcc.inhibited = biomarkers.mcc.inhibited[!biomarkers.mcc.inhibited %in% common.biomarkers.mcc] # find the proper state of the biomarkers and add them threshold = 0.6 for (biomarker in common.biomarkers.mcc) { logical.vector = diff.mcc.results[, biomarker] &gt; threshold | diff.mcc.results[, biomarker] &lt; -threshold comparison.index = max(which(logical.vector == TRUE)) if (diff.mcc.results[comparison.index, biomarker] &gt; threshold) biomarkers.mcc.active = append(biomarkers.mcc.active, biomarker) else biomarkers.mcc.inhibited = append(biomarkers.mcc.inhibited, biomarker) } # printing MCC biomarkers pretty_print_vector_values(biomarkers.mcc.active) 4 nodes: GSK3B, AKT2, APC, LRP6 pretty_print_vector_values(biomarkers.mcc.inhibited) 8 nodes: GSK3B/Axin/APC, MYC, PSEN1, ROR2, PHLPP1, MAML1, SIRT2, CUL1 Performance-related biomarkers Comparing the two methods we used for the classification of the models’ prediction performance (TP and MCC), we observe that there exist no common biomarkers in either active or inhibited state cases while the results regarding the state of the node PSEN1 are contradictory: common.biomarkers.mixed.1 = get_common_values(biomarkers.mcc.active, biomarkers.tp.inhibited) No common nodes common.biomarkers.mixed.2 = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.active) 1 node: PSEN1 biomarkers.perf.active = get_common_values(biomarkers.mcc.active, biomarkers.tp.active) No common nodes biomarkers.perf.inhibited = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.inhibited) No common nodes We believe that the MCC score better captures the performance categories within our imbalanced dataset so we will use the results from the MCC analysis as the performance biomarkers. Lastly, we will save these performance-related biomarkers for further analysis and comparison with the results from all the different cell lines: biomarkers.dir = paste0(data.dir, &quot;biomarkers/&quot;) biomarkers.perf.active = biomarkers.mcc.active biomarkers.perf.inhibited = biomarkers.mcc.inhibited save_vector_to_file(vector = biomarkers.perf.active, file = paste0(biomarkers.dir, &quot;biomarkers_active&quot;)) save_vector_to_file(vector = biomarkers.perf.inhibited, file = paste0(biomarkers.dir, &quot;biomarkers_inhibited&quot;)) Equation-based analysis It will be interesting to see the different patterns in the form of the boolean equations (regarding the mutation of the link operator as mentioned in the Input section) when comparing higher performance models vs the low performant ones. We could also check if any of the biomarkers found above relate to a different link operator on average between models with different performance characteristics (e.g. higher predictive models should have the OR NOT as the link operator in a boolean equation where a specific biomarker is the regulation target) or if they constitute targets of exclusively activating nodes or inhibiting ones (an equation with no link operator). The performance metric we will first use to sort the models is the number of true positive predictions. We will now illustrate the heatmap of the models.equations object raw-order by the number of \\(TP\\) predictions: # order based on number of true positives models.synergies.tp.sorted = sort(models.synergies.tp) models.sorted = names(models.synergies.tp.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring eq.link.colors = c(&quot;red&quot;, &quot;lightyellow&quot;) eq.link.col.fun = colorRamp2(breaks = c(0, 1), colors = eq.link.colors) tp.values = sort(unique(models.synergies.tp)) tp.col.fun = colorRamp2(breaks = c(min(tp.values), max(tp.values)), colors = c(&quot;red&quot;, &quot;green&quot;)) # color biomarker names in the heatmap bottom.nodes.colors = rep(&quot;black&quot;, length(colnames(models.equations.sorted))) names(bottom.nodes.colors) = colnames(models.equations.sorted) bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.active] = &quot;blue&quot; bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.inhibited] = &quot;magenta&quot; # define the TP color bar tp.annot = rowAnnotation( tp = anno_simple(x = models.synergies.tp.sorted, col = tp.col.fun), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (TP sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = tp.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 3 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) tp.values = min(tp.values):max(tp.values) # maybe some integers are missing tp.legend = Legend(at = tp.values, title = &quot;TP&quot;, legend_gp = gpar(fill = tp.col.fun(tp.values))) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, tp.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the heatmap above, an equation whose link operator is AND NOT is represented with red color while an OR NOT link operator is represented with light yellow color. The targets whose equations do not have a link operator are not represented. The rows are ordered by the number of true positive predictions (ascending). We have colored the names of the network nodes that were also found as biomarkers (green color is used for the active biomarkers and red color for the inhibited biomarkers). We observe that: Most of the biomarkers are nodes that do not have both activators and inhibitors and so are absent from the above heatmap There doesn’t seem to exist a pattern between the models’ link operators and their corresponding performance (at least not for all of the nodes) when using the true positive predictions as a classifier for the models There exist a lot of target nodes that need to have the OR NOT link operator in their respective boolean equation in order for the corresponding logical model to show a higher number of true positive predictions. By assigning the OR NOT link operator to a target’s boolean regulation equation, we allow more flexibility to the target’s output active result state - meaning that the inhibitors play less role and the output state has a higher probability of being active - compared to assigning the AND NOT link operator to the equation We will also illustrate the heatmap of the models.equations object raw-order by the MCC score which is a better performance classifier. Models who had a NaN MCC score will be again placed in the lower performant category: # order based on the MCC value models.mcc.sorted = sort(models.mcc, na.last = FALSE) models.sorted = names(models.mcc.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring mcc.col.fun = colorRamp2(breaks = c(min(models.mcc.no.nan), max(models.mcc.no.nan)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define the MCC color bar mcc.annot = rowAnnotation( mcc = anno_simple(x = models.mcc.sorted, col = mcc.col.fun, na_col = &quot;black&quot;), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (MCC sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = mcc.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 4 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) mcc.legend = Legend(title = &quot;MCC&quot;, col_fun = mcc.col.fun) na.legend = Legend(labels = &quot;NA&quot;, legend_gp = gpar(fill = &quot;black&quot;)) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, mcc.legend, na.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the MCC-ordered heatmap above we observe that there is better correlation between the boolean equations’ link operators and the performance of a model compared to the \\(TP\\) classification. For example, the biomarkers AKT2 and GSK3B show distinguished patterns for the higher performance models (use of AND NOT and OR NOT link operators respectively) when the models are sorted by the MCC score. Synergy-prediction based analysis We will now use the second strategy to split the models, based on whether they predict a specific observed synergy or not. This will allow us to find biomarkers that affect the prediction of a specific synergy. For example, the good models could be the ones that predicted the hypothetical synergy A-B while the bad models all the rest that identified the particular combination as non-synergistic. In another case scenario, the good models could be those that predicted a triple synergy set A-B,C-D,A-C, while the bad models could be the ones that predicted the double synergy subset A-B,C-D (excluding the common models that predicted both the triple synergy set and subsequently its given subset). In such a case scenario, we want to find out which nodes are responsible for making the good models predict the extra synergy - in this hypothetical case the synergy A-C - demonstrating thus better model performance. Note that the models selected in each case as good or bad, could have predicted other synergies as well (correctly as \\(TP\\) or wrongly as \\(FP\\)) which means that the biomarker selection method could be somewhat innacurate, since we can’t really know the prediction of which extra synergy or synergies the biomarkers’ state affected. To account for this, we label as good models those that predict large synergy sets (so fewer models) which capture almost all the true positive predictions and also minimize the possible extra different synergies predicted by models of the same classification category (e.g. the good models). Starting with the first model classification method (prediction vs non-prediction of a particular synergy), we generate the density distribution of the nodes’ average state differences between the good and bad models for each predicted synergy: diff.predicted.synergies.results = sapply(predicted.synergies, function(drug.comb) { get_avg_activity_diff_based_on_specific_synergy_prediction( model.predictions, models.stable.state, drug.comb) }) diff.predicted.synergies.results = t(diff.predicted.synergies.results) densities = apply(abs(diff.predicted.synergies.results), 1, density) make_multiple_density_plot(densities, legend.title = &quot;Predicted Synergies&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Next, we will plot the biomarkers with the network visualization method (for all predicted synergies) and output the respective biomarkers in each case. The biomarker results for each predicted synergy will be stored for further comparison with the results from the other cell lines. threshold = 0.7 for (drug.comb in predicted.synergies) { diff = diff.predicted.synergies.results[drug.comb, ] biomarkers.active = diff[diff &gt; threshold] biomarkers.inhibited = diff[diff &lt; -threshold] save_vector_to_file(vector = biomarkers.active, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_active&quot;), with.row.names = TRUE) save_vector_to_file(vector = biomarkers.inhibited, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_inhibited&quot;), with.row.names = TRUE) } threshold = 0.7 for (drug.comb in predicted.synergies) { title.text = paste0(&quot;Prediction of &quot;, drug.comb, &quot; synergy: Good models vs Bad Models&quot;) diff = diff.predicted.synergies.results[drug.comb, ] plot_avg_state_diff_graph(net, diff, layout = nice.layout, title = title.text) } print_biomarkers_per_predicted_synergy(biomarkers.dir, predicted.synergies) Biomarkers for BI-PI synergy predictionActive biomarkers4 nodes: NR3C1, MAPK14, RPS6KA5, DUSP1Inhibited biomarkers11 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, FGFR1, TAB1, CASP3, PTPN7, MAX, ROCK1Biomarkers for BI-D1 synergy predictionActive biomarkers3 nodes: MAPK14, RPS6KA5, DUSP1Inhibited biomarkers12 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, FGFR1, TAB1, CASP3, EGFR, PTPN7, MAX, ROCK1Biomarkers for PI-D1 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: Biomarkers for JN-D1 synergy predictionActive biomarkers22 nodes: MAP3K11, FGFR1, TAB1, CASP3, STAT3, EGFR, PTPN7, MAX, MAPK8, MAPK8IP1, MAPK8IP3, APP, SIRT1, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1Inhibited biomarkers7 nodes: DLX5, NR3C1, MAPK14, RPS6KA5, DUSP1, RXRA, LATBiomarkers for D1-P5 synergy predictionActive biomarkers3 nodes: JAK2, CSF2RA, APOA1Inhibited biomarkers0 nodes: We notice that for some predicted synergies the above method identified zero biomarkers. We will now study cases where the main goal is the better identification and/or refinement of the biomarkers responsible for allowing the models to predict one extra synergy from a specific synergy set. If we find biomarkers for a predicted synergy using this strategy, we compare them to the ones already found with the previous method and if none of them is common we just add the new ones to the list of biomarkers for that specific synergy. On the other hand, if the synergy-set comparison method identifies a subset of the previously found biomarkers for a specific synergy (one common node at least), we will only keep the later method’s biomarkers since we believe that the synergy-set prediction based method is more accurate at identifying biomarkers for a specific synergy because of the fewer models involved in each contrasting category which also minimizes the total false positive synergy predictions taken into account. Note that if the second method finds even more biomarkers than the first, we have the option to prune the end result to only the common biomarkers between the two methods. We will focus our analysis on the predicted synergies D1-P5, PI-D1, BI-D1 and BI-PI. Synergy-set prediction based analysis D1-P5 synergy The first use case will contrast the models that predicted the synergy set PI-D1,D1-P5 vs the models that predicted the signle synergy PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra D1-P5 synergy: synergy.set.str = &quot;PI-D1,D1-P5&quot; synergy.subset.str = &quot;PI-D1&quot; diff.D1.P5 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.D1.P5, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.D1.P5.active = diff.D1.P5[diff.D1.P5 &gt; threshold] pretty_print_vector_names(biomarkers.D1.P5.active) 15 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, AKT1, BRCA1, PRKACA, TTC3, JAK2, CSF2RA, APOA1, SYK, MAP4K1, VAV1 Note that the 3 active biomarkers found with the previous method are included in the list above. We also report the inhibited biomarkers: biomarkers.D1.P5.inhibited = diff.D1.P5[diff.D1.P5 &lt; -threshold] pretty_print_vector_names(biomarkers.D1.P5.inhibited) 8 nodes: DAB2IP, PPP1CA, AR, CHEK1, RARA, IRAK1, LCK, CASP9 Note that with the previous method we couldn’t identify any inhibited biomarker. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;D1-P5&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.D1.P5.active, biomarkers.D1.P5.inhibited) PI-D1 synergy The second use case will contrast the models that predicted the synergy set PI-D1,D1-P5 vs the models that predicted the single synergy D1-P5 as well as the models that predicted the synergy set BI-D1,PI-D1 vs the models that predicted the single synergy BI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PI-D1 synergy: synergy.set.str.1 = &quot;PI-D1,D1-P5&quot; synergy.subset.str.1 = &quot;D1-P5&quot; diff.PI.D1.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;BI-D1,PI-D1&quot; synergy.subset.str.2 = &quot;BI-D1&quot; diff.PI.D1.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.2, layout = nice.layout, title = title.text) Observing the graphs above, we note that the second comparison (BI-D1,PI-D1 vs BI-D1) does not produce any biomarkers. Even the first comparison’s biomarkers are below the 0.7 threshold that we use. So, in order to capture the biomarkers of the first comparison, we will use a lower threshold level (0.6). The active biomarkers are thus: biomarkers.PI.D1.active = diff.PI.D1.1[diff.PI.D1.1 &gt; 0.6] pretty_print_vector_names(biomarkers.PI.D1.active) 4 nodes: GSK3B, AKT2, APC, LRP6 Note that with the previous method where we contrasted the models that predict the PI-D1 synergy vs those that don’t, we weren’t able to identify not even one biomarker. The inhibited biomarkers found are: biomarkers.PI.D1.inhibited = diff.PI.D1.1[diff.PI.D1.1 &lt; -0.6] pretty_print_vector_names(biomarkers.PI.D1.inhibited) 5 nodes: MAP3K4, GSK3B/Axin/APC, ROR2, PHLPP1, MAML1 Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;PI-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.PI.D1.active, biomarkers.PI.D1.inhibited) BI-D1 synergy The third use case will contrast the models that predicted the synergy set BI-D1,PI-D1 vs the models that predicted the single synergy subset PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-D1 synergy: synergy.set.str = &quot;BI-D1,PI-D1&quot; synergy.subset.str = &quot;PI-D1&quot; diff.BI.D1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.D1, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.BI.D1.active = diff.BI.D1[diff.BI.D1 &gt; threshold] pretty_print_vector_names(biomarkers.BI.D1.active) 3 nodes: MAPK8IP1, MAPK8IP3, MAPK9 We also report the inhibited biomarkers: biomarkers.BI.D1.inhibited = diff.BI.D1[diff.BI.D1 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.D1.inhibited) 1 node: RXRA Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.D1.active, biomarkers.BI.D1.inhibited) BI-PI synergy The fourth use case will contrast the models that predicted the synergy set BI-PI,PI-D1 vs the models that predicted the single synergy PI-D1 as well as the models that predicted the synergy set BI-PI,BI-D1,PI-D1 vs the models that predicted the synergy subset \"BI-D1,PI-D1. These two comparisons will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-PI synergy: synergy.set.str.1 = &quot;BI-PI,PI-D1&quot; synergy.subset.str.1 = &quot;PI-D1&quot; diff.BI.PI.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;BI-PI,BI-D1,PI-D1&quot; synergy.subset.str.2 = &quot;BI-D1,PI-D1&quot; diff.BI.PI.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI.2, layout = nice.layout, title = title.text) As we see from the two graphs above, each comparison produces different biomarkers for the BI-PI synergy. We note that the second comparison’s (BI-PI,BI-D1,PI-D1 vs BI-D1,PI-D1) biomarkers are below the 0.7 threshold that we use. So, in order to capture the biomarkers of the second synergy set comparison, we will use a lower threshold level (0.6). The active biomarkers found from the two comparisons are thus: biomarkers.BI.PI.active.1 = diff.BI.PI.1[diff.BI.PI.1 &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active.1) 4 nodes: PSEN1, MAPK8IP1, MAPK8IP3, MAPK9 biomarkers.BI.PI.active.2 = diff.BI.PI.2[diff.BI.PI.2 &gt; 0.6] pretty_print_vector_names(biomarkers.BI.PI.active.2) 2 nodes: GAB2, MAP2K1 biomarkers.BI.PI.active.common.1.2 = get_common_names(biomarkers.BI.PI.active.1, biomarkers.BI.PI.active.2) No common nodes biomarkers.BI.PI.active = c(biomarkers.BI.PI.active.1, biomarkers.BI.PI.active.2) So, as the active biomarkers for this synergy we merged the (non-common) results from the two synergy set comparisons. The inhibited biomarkers found from the two comparisons are: biomarkers.BI.PI.inhibited.1 = diff.BI.PI.1[diff.BI.PI.1 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited.1) 1 node: RXRA biomarkers.BI.PI.inhibited.2 = diff.BI.PI.2[diff.BI.PI.2 &lt; -0.6] pretty_print_vector_names(biomarkers.BI.PI.inhibited.2) 0 nodes: biomarkers.BI.PI.inhibited = biomarkers.BI.PI.inhibited.1 Since the second comparison did not identify any inhibited biomarkers at the \\(0.6\\) threshold level, we use the inhibited biomarkers found from the first comparison. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-PI&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.PI.active, biomarkers.BI.PI.inhibited) Biomarker results In this section, we will compare the biomarkers found per predicted synergy for this particular cell line as well as the performance biomarkers (notated as PERF in the heatmap below) which were found using the results from the MCC classification-based model analysis: # Biomarkers from sections: # `Synergy-prediction based analysis`, `Synergy-set prediction based analysis` biomarkers.synergy.res = get_synergy_biomarkers_from_dir(predicted.synergies, biomarkers.dir, models.dir) # store biomarkers in one file save_df_to_file(biomarkers.synergy.res, file = paste0(biomarkers.dir, &quot;biomarkers_per_synergy&quot;)) # Biomarkers from section: # `Performance-related biomarkers` biomarkers.res = add_row_to_ternary_df(df = biomarkers.synergy.res, values.pos = biomarkers.perf.active, values.neg = biomarkers.perf.inhibited, row.name = &quot;PERF&quot;) # prune nodes which are not found as biomarkers for any predicted synergy or # for better model performance biomarkers.res = prune_columns_from_df(biomarkers.res, value = 0) # define a coloring biomarkers.col.fun = colorRamp2(c(-1, 0, 1), c(&quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;)) biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.res), col = biomarkers.col.fun, column_title = paste0(&quot;Biomarker results (&quot;, cell.line, &quot;)&quot;), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = &quot;Predicted synergies&quot;, row_order = nrow(biomarkers.res):1, column_dend_height = unit(1, &quot;inches&quot;), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 7), row_names_side = &quot;left&quot;, heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) So, in general we observe that: A total of 68 nodes were found as biomarkers (for at least one synergy) We found a lot of biomarkers for each predicted synergy. Usually we wouldn’t expect too many biomarkers that are directly related to the prediction of a specific synergy. The abudance of (false positive) biomarkers for some synergies (e.g. JN-D1) relates to the model classification method used, which does not incorporate in its internal logic that the prediction of other synergies than the ones used for the grouping itself can affect the biomarker results obtained from it Not all the performance-related biomarkers (PERF) were also observed as biomarkers for the prediction of a specific synergy(ies) The PSEN1 biomarker state is found contradictory between the performance-related biomarkers (PERF) and the BI-PI synergy ones. Note though that only 17 models predicted the BI-PI synergy and the performance-related state of that biomarker was produced through the more rigorous MCC classification. Thus, we place a larger confidence on the activity state of the performance-related biomarker result There exist common biomarkers across different predicted synergies, e.g. RXRA is a common inhibited biomarker across 3 synergistic drug combinations The results between the different synergies are sometimes contradictory, meaning that there are active biomarkers for a particular synergy that were found as inhibited in another and vise versa (e.g. the NLK biomarker) The biomarkers of the PI-D1 synergy are not shared with any of the other predicted synergies’ biomarkers but they are the same as some of the performance-related biomarkers "],
["uacc62-model-analysis.html", "UACC62 Model Analysis Input Performance Statistics Biomarker analysis", " UACC62 Model Analysis This chapter includes the ensemble model analysis performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). All these models were trained towards a specific steady state signaling pattern that was derived based on input data (gene expression, CNV) for the UACC62 cell line, the (Melanoma, a skin cancer), the use of the PARADIGM software (Vaske et al. 2010) and a topology that was build for simulating a cancer cell fate decision network. The input for the simulations and the output data are in the cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input We will define the name of the cell line which must match the name of the directory that has the input files inside the cell-lines-2500 directory. Our analysis in this chapter will be done on the data for the UACC62 cell line: cell.line = &quot;UACC62&quot; data.dir = paste0(getwd(), &quot;/&quot;, cell.line, &quot;/&quot;) Three inputs are used in this analysis: The model_predictions file which has for each model the prediction for each drug combination tested (0 = no synergy predicted, 1 = synergy predicted, NA = couldn’t find stable states in either the drug combination inhibited model or in any of the two single-drug inhibited models) The observed_synergies file which lists the drug combinations that were observed as synergistic for the particular cell line. The models directory, which is the same as the models directory produced by Gitsbe and has one .gitsbe file per model that includes this info: The stable state of the boolean model. Note that a model can have 1 stable state or none in our simulations - but the models used in this analysis have been selected through a genetic evolution algorithm in Gitsbe and so in the end, only those with 1 stable state have higher fitness values and remain in the later generations. Higher fitness here means a better match of a model’s stable state to the cell line derived steady state (a perfect match would result in a fitness of 1) The boolean equations of the model models.stable.state.file = paste0(data.dir, &quot;models_stable_state&quot;) observed.synergies.file = paste0(data.dir, &quot;observed_synergies&quot;) model.predictions.file = paste0(data.dir, &quot;model_predictions&quot;) models.equations.file = paste0(data.dir, &quot;models_equations&quot;) models.dir = paste0(data.dir, &quot;models&quot;) Now, we parse the data into proper R objects. First the synergy predictions per model: model.predictions = get_model_predictions(model.predictions.file) # Example: first model&#39;s synergy predictions (first 12 drug combinations) pretty_print_vector_names_and_values(model.predictions[1,], n = 12) 5Z-AK: 0, 5Z-BI: 0, 5Z-CT: 0, 5Z-PD: 0, 5Z-PI: 0, 5Z-PK: 0, 5Z-JN: 0, 5Z-D1: 0, 5Z-60: 0, 5Z-SB: 0, 5Z-RU: 0, 5Z-D4: 0 So, the model.predictions object has the models as rows and each column is a different drug combination that was tested in our simulations. drug.combinations.tested = colnames(model.predictions) models = rownames(model.predictions) nodes = get_node_names(models.dir) number.of.drug.comb.tested = length(drug.combinations.tested) number.of.models = length(models) number.of.nodes = length(nodes) print_model_and_drug_stats(number.of.drug.comb.tested, number.of.models, number.of.nodes, html.output = TRUE) Drug combinations tested: 153Number of models: 7500Number of nodes: 139 Next, we get the full stable state and the equations per model: models.stable.state = as.matrix( read.table(file = models.stable.state.file, check.names = FALSE) ) # Example: first model&#39;s stable state (first 12 nodes) pretty_print_vector_names_and_values(models.stable.state[1,], n = 12) MAP3K7: 0, MAP2K6: 0, MAP2K3: 0, NLK: 0, MAP3K4: 1, MAP2K4: 1, IKBKG: 0, IKBKB: 0, AKT1: 0, BRAF: 1, SMAD3: 1, DAB2IP: 1 The rows of the models.stable.state object represent the models while its columns are the names of the nodes (proteins, genes, etc.) of the cancer cell network under study. So, each model has one stable state which means that in every model, the nodes in the network have reached a state of either 0 (inhibition) or 1 (activation). models.equations = as.matrix( read.table(file = models.equations.file, check.names = FALSE) ) # Example: first model&#39;s link operators (first 12 nodes) pretty_print_vector_names_and_values(models.equations[1,], n = 12) MAP3K4: 1, MAP2K4: 1, IKBKB: 0, AKT1: 0, SMAD3: 0, GSK3B: 0, RAF1: 1, GAB2: 0, CTNNB1: 0, NR3C1: 1, CREB1: 1, RAC1: 1 For the models.equations, if we look at a specific row (a model so to speak), the columns (node names) correspond to the targets of regulation (and the network has been built so that every node is a target - i.e. it has other nodes activating and/or inhibiting it). The general form of a boolean equation is: general.equation = &quot;Target *= (Activator OR Activator OR...) AND NOT (Inhibitor OR Inhibitor OR...)&quot; pretty_print_bold_string(general.equation) Target *= (Activator OR Activator OR…) AND NOT (Inhibitor OR Inhibitor OR…) The difference between the models’ boolean equations is the link operator (OR NOT/AND NOT) which has been mutated (changed) through the evolutionary process of the genetic algorithm in Gitsbe. For example, if a model has for the column ERK_f (of the models.equations object) a value of 1, the correspoding equation is: ERK_f *= (MEK_f) OR NOT ((DUSP6) OR PPP1CA). A value of 0 would correspond to the same equation but having AND NOT as the link operator: ERK_f *= (MEK_f) AND NOT ((DUSP6) OR PPP1CA). Note that the equations that do not have link operators (meaning that they are the same for every model) are discarded (so less columns in this dataset) since in a later section we study only the equations whose link operators differentiate between the models. Lastly, the synergies observed for this particular cell line are: observed.synergies = get_observed_synergies( observed.synergies.file, drug.combinations.tested) number.of.observed.synergies = length(observed.synergies) pretty_print_vector_values(observed.synergies, vector.values.str = &quot;observed synergies&quot;) 21 observed synergies: AK-BI, 5Z-D1, AK-D1, BI-D1, JN-D1, PI-D1, BI-G2, PI-G2, ST-G2, D1-G4, PI-JN, AK-P5, BI-P5, D1-P5, G2-P5, JN-P5, PI-P5, BI-PI, CT-PI, AK-RU, PK-ST Performance Statistics It will be interesting to know the percentage of the above observed synergies that were actually predicted by at least one of the models (there might be combinations that no model in our dataset could predict): combinations that no model in our dataset could predict): # Split model.predictions to positive and negative results observed.model.predictions = get_observed_model_predictions(model.predictions, observed.synergies) unobserved.model.predictions = get_unobserved_model_predictions(model.predictions, observed.synergies) stopifnot(ncol(observed.model.predictions) + ncol(unobserved.model.predictions) == number.of.drug.comb.tested) number.of.models.per.observed.synergy = colSums(observed.model.predictions, na.rm = TRUE) predicted.synergies = names(which(number.of.models.per.observed.synergy &gt; 0)) # predicted synergies is a subset of the observed (positive) ones stopifnot(all(predicted.synergies %in% observed.synergies)) pretty_print_vector_values(predicted.synergies, vector.values.str = &quot;predicted synergies&quot;) 8 predicted synergies: BI-PI, BI-D1, BI-G2, PI-JN, PI-D1, PI-P5, JN-D1, D1-P5 predicted.synergies.percentage = 100 * length(predicted.synergies) / number.of.observed.synergies pretty_print_string(paste0(&quot;Percentage of True Positive predicted synergies: &quot;, specify_decimal(predicted.synergies.percentage, 2), &quot;%&quot;)) Percentage of True Positive predicted synergies: 38.10% So, for this particular cell line, there were indeed observed synergies that no model could predict (e.g.  5Z-D1, AK-BI). Next, we would like to know the maximum number of observed synergies predicted by one model alone - can one model by itself predict all the true positive synergies predicted by all the models together or do we need many models to capture this diverse synergy landscape? To do that, we go even further and count the number of models that predict a specific set of observed synergies for every possible combination subset of the predicted.synergies object: # Find the number of predictive models for every synergy subset synergy.subset.stats = get_synergy_subset_stats(observed.model.predictions, predicted.synergies) # Bar plot of the number of models for every possible observed synergy combination set # Tweak the threshold.for.subset.removal and bottom.margin as desired make_barplot_on_synergy_subset_stats(synergy.subset.stats, threshold.for.subset.removal = 1, bottom.margin = 12, cell.line) From the above figure (where we excluded sets of synergies that were predicted by no model by setting the threshold.for.subset.removal value to 1) we observe that: More than half of the models predict none of the observed synergies The BI-D1 synergy is predicted by almost all the rest of the models Next we calculate the maximum number of correctly predicted synergies (\\(TP\\) - True Positives) per model: # Count the predictions of the observed synergies per model (TP) models.synergies.tp = calculate_models_synergies_tp(observed.model.predictions) models.synergies.tp.stats = table(models.synergies.tp) # Bar plot of number of models vs correctly predicted synergies make_barplot_on_models_stats(models.synergies.tp.stats, cell.line, title = &quot;True Positive Synergy Predictions&quot;, xlab = &quot;Number of maximum correctly predicted synergies&quot;, ylab = &quot;Number of models&quot;) To summarize: There were only 62 models that predicted 4 synergies - either the set BI-PI,BI-D1,BI-G2,PI-D1 or the set BI-PI,BI-D1,BI-G2,PI-P5 which is the maximum number of predicted synergies by an individual model No model could predict all 8 of the total predicted synergies The power of the ensemble model approach lies in the fact that (as we saw from the above figures) even though we may not have individual super models that can predict many observed drug combinations, there are many that predict at least one and which will be used by the drug response analysis module (Drabme) to better infer the synergistic drug combinations. It goes without saying though, that the existance of models that could predict more than a handful of synergies would be beneficial for any approach that performs drug response analysis on a multitude of models. Biomarker analysis Intro-Methods Now, we want to investigate and find possible important nodes - biomarkers - whose activity state either distinguishes good performance models from less performant ones (in terms of a performance metric - e.g. the true positive synergies predicted) or makes some models predict a specific synergy compared to others that can’t (but could predict other synergies). So, we devised two strategies to split the models in our disposal to good and bad ones (but not necessarily all of them), the demarcation line being either a performance metric (the number of \\(TP\\) or the Matthews Correlation Coefficient score) or the prediction or not of a specific synergy. Then, for each group of models (labeled as either good or bad) we find the average activity state of every node in the network (value between 0 and 1) and then we compute the average state difference for each node between the two groups: \\(\\forall i\\in nodes,mean(state_i)_{good} - mean(state_i)_{bad}\\). Our hypothesis is that if the absolute value of these average differences are larger than a user-defined threshold (e.g. 0.7) for a small number of nodes (the less the better) while for the rest of the nodes they remain close to zero, then the former nodes are considered the most important since they define the difference between the average bad model and the average good one in that particular case study. We will also deploy a network visualization method to observe these average differences. True Positives-based analysis Using our first strategy, we will split the models based on the number of true positive predictions. For example, the bad models will be the ones that predicted 0 \\(TP\\) synergies whereas the good models will be the ones that predicted 2 \\(TP\\) (we will denote the grouping as \\((0,2)\\)). This particular classification strategy will be used for every possible combination of the number of \\(TP\\) as given by the models.synergies.tp.stats object and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: diff.tp.results = get_avg_activity_diff_mat_based_on_tp_predictions( models, models.synergies.tp, models.stable.state) tp.densities = apply(abs(diff.tp.results), 1, density) make_multiple_density_plot(tp.densities, legend.title = &quot;True Positives&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) What we are actually looking for is density plots that are largely skewed to the right (so the average absolute differences of these nodes are close to zero) while there are a few areas of non-zero densities which are as close to 1 as possible. So, from the above graph, the density plots that fit this description are the ones marked as \\((0,4)\\) and \\((1,2)\\) for example. We will visualize the nodes’ average state differences in a network graph (Csardi and Nepusz 2006), where the color of each node will denote how much more inhibited or active that node is, in the average good model vs the average bad one. The color of the edges will denote activation (green) or inhibition (red). We first build the network from the node topology (edge list): parent.dir = get_parent_dir(data.dir) topology.file = paste0(parent.dir, &quot;/topology&quot;) coordinates.file = paste0(parent.dir, &quot;/network_xy_coordinates&quot;) net = construct_network(topology.file, models.dir) # a static layout for plotting the same network always (igraph) # nice.layout = layout_nicely(net) nice.layout = as.matrix(read.table(coordinates.file)) In the next colored graphs we can identify the important nodes whose activity state can influence the true positive prediction performance (from 0 true positive synergies to a total of 3): plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,4)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (4 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(1,4)&quot;,], layout = nice.layout, title = &quot;Bad models (1 TP) vs Good models (4 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(2,4)&quot;,], layout = nice.layout, title = &quot;Bad models (2 TP) vs Good models (4 TP)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to the number of true positive synergies that they predict. Comparing the graphs above, we observe that there exist common nodes that maintain the same significant influence in all of the graphs. We set the threshold for the absolute significance level in average state differences to \\(0.7\\). A node will be marked as a biomarker (active or inhibited) if its activity state difference surpassed the aforementioned threshold (positively or negatively) for any of the tested groups (e.g. 2 \\(TP\\) vs 4 \\(TP\\)). So, the nodes that have to be in a more active state are: biomarkers.tp.active = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.tp.active) 3 nodes: MTOR, PI3K, PIK3CG Also, the nodes that have to be in a more inhibited state are: biomarkers.tp.inhibited = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.tp.inhibited) 0 nodes: MCC classification-based analysis The previous method to split the models based on the number of true positive predictions is a good metric for absolute performance but a very restricted one since it ignores the other values of the confusion matrix for each model (true negatives, false positives, false negatives). Also, since our dataset is imbalanced in the sense that out of the total drug combinations tested only a few of them are observed as synergistic (and in a hypothetical larger drug screening evaluation it will be even less true positives) we will now devise a method to split the models into different performance categories based on the value of the Matthews Correlation Coefficient (MCC) score which takes into account the balance ratios of all the four confusion matrix values: # Calculate Matthews Correlation Coefficient (MCC) for every model models.mcc = calculate_models_mcc(observed.model.predictions, unobserved.model.predictions, number.of.drug.comb.tested) models.mcc.stats = table(models.mcc, useNA = &quot;ifany&quot;) make_barplot_on_models_stats(models.mcc.stats, cell.line, title = &quot;MCC scores&quot;, xlab = &quot;MCC value&quot;, ylab = &quot;Number of models&quot;, cont.values = TRUE, threshold = 10) Note that for presentation purposes in the figure above, we pruned some MCC-bars with lower model frequency values. We observe that: There are no relatively bad models (MCC values close to -1) Most of the models (exluding the NaN category) perform a little better than random prediction (\\(MCC&gt;0\\)) There are models that had NaN value for the MCC score Given the MCC formula: \\(MCC = (TP\\cdot TN - FP\\cdot FN)/\\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}\\), we can see that the MCC value can be NaN because of zero devision. Two of the four values in the denominator represent the number of positive \\((TP+FN)\\) and negative \\((TN+FP)\\) observations which are non-zero for every model, since they correspond to the observed and non-obsered synergies in each case. The case where both \\(TN\\) and \\(FN\\) are zero is rare (if non-existent) because of the imbalanced dataset (large proportion of negatives) and the reason that logical models which report no negatives means that they should find fixpoint attractors for every possible drug combination perturbation which also is extremely unlikely. We can actually see that the NaN are produced by models that have both TP and FP equal to zero: models.synergies.fp = calculate_models_synergies_fp(unobserved.model.predictions) pretty_print_string(sum(models.synergies.tp + models.synergies.fp == 0)) 1143 Since these models could intentify no synergies (either correctly or wrongly), we decided to put them as the lowest performant category in our MCC-based analysis. To classify the models based on their MCC score (which takes values in the \\([-1, 1]\\) interval, NaN values excluded), we will perform a univariate k-means clustering to split the previously found MCC values to different classes (Wang and Song 2011). The MCC classification is presented with a histogram: num.of.classes = 5 mcc.class.ids = 1:num.of.classes models.mcc.no.nan = models.mcc[!is.nan(models.mcc)] models.mcc.no.nan.sorted = sort(models.mcc.no.nan) # find the clusters res = Ckmeans.1d.dp(x = models.mcc.no.nan.sorted, k = num.of.classes) models.cluster.ids = res$cluster plot_mcc_classes_hist(models.mcc.no.nan.sorted, models.cluster.ids, num.of.classes, mcc.class.ids) Note that in total we have 6 MCC classes, since the NaN MCC values constitute a class on its own. Following our first strategy, we will split the models based on the MCC performance metric score. For example, the bad models will be the ones that had a NaN MCC score \\((TP+FP = 0)\\) whereas the good models will be the ones that had an MCC score belonging to the first MCC class as seen in the histogram above. This particular classification strategy will be used for every possible combination of the MCC classes and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: # add NaN class (if applicable) if (sum(is.nan(models.mcc)) &gt; 0) { mcc.class.ids = append(mcc.class.ids, values = NaN, after = 0) } mcc.class.id.comb = t(combn(1:length(mcc.class.ids), 2)) diff.mcc.results = apply(mcc.class.id.comb, 1, function(comb) { return(get_avg_activity_diff_based_on_mcc_clustering( models.mcc, models.stable.state, mcc.class.ids, models.cluster.ids, class.id.low = comb[1], class.id.high = comb[2])) }) mcc.classes.comb.names = apply(mcc.class.id.comb, 1, function(comb) { return(paste0(&quot;(&quot;, mcc.class.ids[comb[1]], &quot;,&quot;, mcc.class.ids[comb[2]], &quot;)&quot;)) }) colnames(diff.mcc.results) = mcc.classes.comb.names diff.mcc.results = t(diff.mcc.results) mcc.densities = apply(abs(diff.mcc.results), 1, density) make_multiple_density_plot(mcc.densities, legend.title = &quot;MCC classes&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;, legend.size = 0.8) Many of the density plots above are of interest to us, since they are right skewed. Next, we visualize the average state differences with our network coloring method for 3 of the above cases, in order to identify the important nodes whose activity state can influence the prediction performance based on the MCC classification: plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(1,5)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 1) vs Good models (MCC Class: 5)&quot;) plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(2,5)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 2) vs Good models (MCC Class: 5)&quot;) plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(3,5)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 3) vs Good models (MCC Class: 5)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to their MCC classification, using the same method as in the True Positives-based analysis section. First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 3 nodes: MTOR, PI3K, PIK3CG Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 0 nodes: Performance-related biomarkers Comparing the two methods we used for the classification of the models’ prediction performance (TP and MCC), we observe that there exist common active biomarkers (both methods identified zero inhibited biomarkers). To sum up, we list the common biomarkers that need to be in a more active state: biomarkers.perf.active = get_common_values(biomarkers.mcc.active, biomarkers.tp.active) 3 nodes: MTOR, PI3K, PIK3CG None of the methods identified inhibited biomarkers at the \\(0.7\\) significance level: biomarkers.perf.inhibited = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.inhibited) No common nodes Lastly, we will save these common performance-related biomarkers for further analysis and comparison with the results from all the different cell lines: biomarkers.dir = paste0(data.dir, &quot;biomarkers/&quot;) save_vector_to_file(vector = biomarkers.perf.active, file = paste0(biomarkers.dir, &quot;biomarkers_active&quot;)) save_vector_to_file(vector = biomarkers.perf.inhibited, file = paste0(biomarkers.dir, &quot;biomarkers_inhibited&quot;)) Equation-based analysis It will be interesting to see the different patterns in the form of the boolean equations (regarding the mutation of the link operator as mentioned in the Input section) when comparing higher performance models vs the low performant ones. We could also check if any of the biomarkers found above relate to a different link operator on average between models with different performance characteristics (e.g. higher predictive models should have the OR NOT as the link operator in a boolean equation where a specific biomarker is the regulation target) or if they constitute targets of exclusively activating nodes or inhibiting ones (an equation with no link operator). The performance metric we will first use to sort the models is the number of true positive predictions. We will now illustrate the heatmap of the models.equations object raw-order by the number of \\(TP\\) predictions: # order based on number of true positives models.synergies.tp.sorted = sort(models.synergies.tp) models.sorted = names(models.synergies.tp.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring eq.link.colors = c(&quot;red&quot;, &quot;lightyellow&quot;) eq.link.col.fun = colorRamp2(breaks = c(0, 1), colors = eq.link.colors) tp.values = sort(unique(models.synergies.tp)) tp.col.fun = colorRamp2(breaks = c(min(tp.values), max(tp.values)), colors = c(&quot;red&quot;, &quot;green&quot;)) # color biomarker names in the heatmap bottom.nodes.colors = rep(&quot;black&quot;, length(colnames(models.equations.sorted))) names(bottom.nodes.colors) = colnames(models.equations.sorted) bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.active] = &quot;blue&quot; bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.inhibited] = &quot;magenta&quot; # define the TP color bar tp.annot = rowAnnotation( tp = anno_simple(x = models.synergies.tp.sorted, col = tp.col.fun), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (TP sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = tp.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 3 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) tp.values = min(tp.values):max(tp.values) # maybe some integers are missing tp.legend = Legend(at = tp.values, title = &quot;TP&quot;, legend_gp = gpar(fill = tp.col.fun(tp.values))) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, tp.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the heatmap above, an equation whose link operator is AND NOT is represented with red color while an OR NOT link operator is represented with light yellow color. The targets whose equations do not have a link operator are not represented. The rows are ordered by the number of true positive predictions (ascending). We have colored the names of the network nodes that were also found as biomarkers (green color is used for the active biomarkers and red color for the inhibited biomarkers). We observe that: Most of the biomarkers are nodes that do not have both activators and inhibitors and so are absent from the above heatmap There doesn’t seem to exist a pattern between the models’ link operators and their corresponding performance (at least not for all of the nodes) when using the true positive predictions as a classifier for the models There exist a lot of target nodes that need to have the OR NOT link operator in their respective boolean equation in order for the corresponding logical model to show a higher number of true positive predictions. By assigning the OR NOT link operator to a target’s boolean regulation equation, we allow more flexibility to the target’s output active result state - meaning that the inhibitors play less role and the output state has a higher probability of being active - compared to assigning the AND NOT link operator to the equation We will also illustrate the heatmap of the models.equations object raw-order by the MCC score which is a better performance classifier. Models who had a NaN MCC score will be again placed in the lower performant category: # order based on the MCC value models.mcc.sorted = sort(models.mcc, na.last = FALSE) models.sorted = names(models.mcc.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring mcc.col.fun = colorRamp2(breaks = c(min(models.mcc.no.nan), max(models.mcc.no.nan)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define the MCC color bar mcc.annot = rowAnnotation( mcc = anno_simple(x = models.mcc.sorted, col = mcc.col.fun, na_col = &quot;black&quot;), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (MCC sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = mcc.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 4 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) mcc.legend = Legend(title = &quot;MCC&quot;, col_fun = mcc.col.fun) na.legend = Legend(labels = &quot;NA&quot;, legend_gp = gpar(fill = &quot;black&quot;)) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, mcc.legend, na.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the MCC-ordered heatmap above we observe that there is better correlation between the boolean equations’ link operators and the performance of a model compared to the \\(TP\\) classification. For example, the nodes AKT2 and MAPK8 show distinguished patterns for the higher performance models (use of AND NOT and OR NOT link operators respectively) when the models are sorted by the MCC score. Synergy-prediction based analysis We will now use the second strategy to split the models, based on whether they predict a specific observed synergy or not. This will allow us to find biomarkers that affect the prediction of a specific synergy. For example, the good models could be the ones that predicted the hypothetical synergy A-B while the bad models all the rest that identified the particular combination as non-synergistic. In another case scenario, the good models could be those that predicted a triple synergy set A-B,C-D,A-C, while the bad models could be the ones that predicted the double synergy subset A-B,C-D (excluding the common models that predicted both the triple synergy set and subsequently its given subset). In such a case scenario, we want to find out which nodes are responsible for making the good models predict the extra synergy - in this hypothetical case the synergy A-C - demonstrating thus better model performance. Note that the models selected in each case as good or bad, could have predicted other synergies as well (correctly as \\(TP\\) or wrongly as \\(FP\\)) which means that the biomarker selection method could be somewhat innacurate, since we can’t really know the prediction of which extra synergy or synergies the biomarkers’ state affected. To account for this, we label as good models those that predict large synergy sets (so fewer models) which capture almost all the true positive predictions and also minimize the possible extra different synergies predicted by models of the same classification category (e.g. the good models). Starting with the first model classification method (prediction vs non-prediction of a particular synergy), we generate the density distribution of the nodes’ average state differences between the good and bad models for each predicted synergy: diff.predicted.synergies.results = sapply(predicted.synergies, function(drug.comb) { get_avg_activity_diff_based_on_specific_synergy_prediction( model.predictions, models.stable.state, drug.comb) }) diff.predicted.synergies.results = t(diff.predicted.synergies.results) densities = apply(abs(diff.predicted.synergies.results), 1, density) make_multiple_density_plot(densities, legend.title = &quot;Predicted Synergies&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Next, we will plot the biomarkers with the network visualization method (for all predicted synergies) and output the respective biomarkers in each case. The biomarker results for each predicted synergy will be stored for further comparison with the results from the other cell lines. threshold = 0.7 for (drug.comb in predicted.synergies) { diff = diff.predicted.synergies.results[drug.comb, ] biomarkers.active = diff[diff &gt; threshold] biomarkers.inhibited = diff[diff &lt; -threshold] save_vector_to_file(vector = biomarkers.active, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_active&quot;), with.row.names = TRUE) save_vector_to_file(vector = biomarkers.inhibited, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_inhibited&quot;), with.row.names = TRUE) } threshold = 0.7 for (drug.comb in predicted.synergies) { title.text = paste0(&quot;Prediction of &quot;, drug.comb, &quot; synergy: Good models vs Bad Models&quot;) diff = diff.predicted.synergies.results[drug.comb, ] plot_avg_state_diff_graph(net, diff, layout = nice.layout, title = title.text) } print_biomarkers_per_predicted_synergy(biomarkers.dir, predicted.synergies) Biomarkers for BI-PI synergy predictionActive biomarkers1 node: MTORInhibited biomarkers0 nodes: Biomarkers for BI-D1 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: Biomarkers for BI-G2 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: Biomarkers for PI-JN synergy predictionActive biomarkers23 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, MAP3K11, MTOR, FGFR1, TAB1, CASP3, STAT3, EGFR, PTPN7, MAX, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1Inhibited biomarkers5 nodes: DLX5, NR3C1, MAPK14, RPS6KA5, DUSP1Biomarkers for PI-D1 synergy predictionActive biomarkers1 node: MTORInhibited biomarkers0 nodes: Biomarkers for PI-P5 synergy predictionActive biomarkers18 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, AKT1, BRCA1, PRKACA, TTC3, MTOR, PI3K, PIK3CG, JAK2, CSF2RA, APOA1, SYK, MAP4K1, VAV1Inhibited biomarkers9 nodes: DAB2IP, PPP1CA, AR, CHEK1, RARA, SH3RF1, PTPN1, IRAK1, LCKBiomarkers for JN-D1 synergy predictionActive biomarkers22 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, MAP3K11, FGFR1, TAB1, CASP3, STAT3, EGFR, PTPN7, MAX, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1Inhibited biomarkers5 nodes: DLX5, NR3C1, MAPK14, RPS6KA5, DUSP1Biomarkers for D1-P5 synergy predictionActive biomarkers17 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, AKT1, BRCA1, PRKACA, TTC3, PI3K, PIK3CG, JAK2, CSF2RA, APOA1, SYK, MAP4K1, VAV1Inhibited biomarkers9 nodes: DAB2IP, PPP1CA, AR, CHEK1, RARA, SH3RF1, PTPN1, IRAK1, LCK We notice that for some predicted synergies the above method identified zero biomarkers. We will now study cases where the main goal is the better identification and/or refinement of the biomarkers responsible for allowing the models to predict one extra synergy from a specific synergy set. If we find biomarkers for a predicted synergy using this strategy, we compare them to the ones already found with the previous method and if none of them is common we just add the new ones to the list of biomarkers for that specific synergy. On the other hand, if the synergy-set comparison method identifies a subset of the previously found biomarkers for a specific synergy (one common node at least), we will only keep the later method’s biomarkers since we believe that the synergy-set prediction based method is more accurate at identifying biomarkers for a specific synergy because of the fewer models involved in each contrasting category which also minimizes the total false positive synergy predictions taken into account. Note that if the second method finds even more biomarkers than the first, we have the option to prune the end result to only the common biomarkers between the two methods. We will focus our analysis on each one of the 8 predicted synergies. Synergy-set prediction based analysis BI-D1 synergy The first use case will contrast the models that predicted the synergy set BI-D1,PI-P5 vs the models that predicted the single synergy subset PI-P5. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-D1 synergy: synergy.set.str = &quot;BI-D1,PI-P5&quot; synergy.subset.str = &quot;PI-P5&quot; diff.BI.D1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.D1, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.BI.D1.active = diff.BI.D1[diff.BI.D1 &gt; threshold] pretty_print_vector_names(biomarkers.BI.D1.active) 2 nodes: IRS1, PIK3CA No inhibited biomarkers were identified: biomarkers.BI.D1.inhibited = diff.BI.D1[diff.BI.D1 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.D1.inhibited) 0 nodes: Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.D1.active, biomarkers.BI.D1.inhibited) BI-PI synergy The second use case will contrast the models that predicted the synergy set BI-PI,PI-P5 vs the models that predicted the single synergy subset PI-P5 as well as the models that predicted the synergy set BI-PI,BI-D1,BI-G2 vs the models that predicted the synergy subset BI-D1,BI-G2. These comparisons will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-PI synergy: synergy.set.str.1 = &quot;BI-PI,PI-P5&quot; synergy.subset.str.1 = &quot;PI-P5&quot; diff.BI.PI.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;BI-PI,BI-D1,BI-G2&quot; synergy.subset.str.2 = &quot;BI-D1,BI-G2&quot; diff.BI.PI.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI.2, layout = nice.layout, title = title.text) We now report the active biomarkers for each of the two comparisons and find the common ones: biomarkers.BI.PI.active.1 = diff.BI.PI.1[diff.BI.PI.1 &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active.1) 2 nodes: IRS1, PIK3CA biomarkers.BI.PI.active.2 = diff.BI.PI.2[diff.BI.PI.2 &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active.2) 3 nodes: MTOR, PI3K, PIK3CG biomarkers.BI.PI.active.common.1.2 = get_common_names(biomarkers.BI.PI.active.1, biomarkers.BI.PI.active.2) No common nodes biomarkers.BI.PI.active = c(biomarkers.BI.PI.active.1, biomarkers.BI.PI.active.2) Note that the MTOR node had already been identified as a biomarker with the previous method. No inhibited biomarkers were identified for this synergy: biomarkers.BI.PI.inhibited.1 = diff.BI.PI.1[diff.BI.PI.1 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited.1) 0 nodes: biomarkers.BI.PI.inhibited.2 = diff.BI.PI.2[diff.BI.PI.2 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited.2) 0 nodes: biomarkers.BI.PI.inhibited = c() Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-PI&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.PI.active, biomarkers.BI.PI.inhibited) BI-G2 synergy The third use case will contrast the models that predicted the synergy set BI-G2,PI-P5 vs the models that predicted the single synergy subset PI-P5 as well as the models that predicted the synergy set BI-PI,BI-D1,BI-G2,PI-D1 vs the models that predicted the synergy subset BI-PI,BI-D1,PI-D1. These comparisons will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-G2 synergy: synergy.set.str.1 = &quot;BI-G2,PI-P5&quot; synergy.subset.str.1 = &quot;PI-P5&quot; diff.BI.G2.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;BI-PI,BI-D1,BI-G2,PI-D1&quot; synergy.subset.str.2 = &quot;BI-PI,BI-D1,PI-D1&quot; diff.BI.G2.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.G2.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.G2.2, layout = nice.layout, title = title.text) We will lower the significance threshold to \\(0.6\\) in order to capture the biomarkers of the second comparison. We report the active biomarkers for each of the two comparisons and merge them into a common result (since the two results produce completely different results): biomarkers.BI.G2.active.1 = diff.BI.G2.1[diff.BI.G2.1 &gt; threshold] pretty_print_vector_names(biomarkers.BI.G2.active.1) 2 nodes: IRS1, PIK3CA biomarkers.BI.G2.active.2 = diff.BI.G2.2[diff.BI.G2.2 &gt; 0.6] pretty_print_vector_names(biomarkers.BI.G2.active.2) 3 nodes: CHUK, POU5F1, BMI1 biomarkers.BI.G2.active.common.1.2 = get_common_names(biomarkers.BI.G2.active.1, biomarkers.BI.G2.active.2) No common nodes biomarkers.BI.G2.active = c(biomarkers.BI.G2.active.1, biomarkers.BI.G2.active.2) We do the same for the inhibited biomarkers: biomarkers.BI.G2.inhibited.1 = diff.BI.G2.1[diff.BI.G2.1 &lt; -threshold] pretty_print_vector_names(biomarkers.BI.G2.inhibited.1) 0 nodes: biomarkers.BI.G2.inhibited.2 = diff.BI.G2.2[diff.BI.G2.2 &lt; -0.6] pretty_print_vector_names(biomarkers.BI.G2.inhibited.2) 4 nodes: BRAF, SH3RF1, PTPN1, CCND1 biomarkers.BI.G2.inhibited.common.1.2 = get_common_names(biomarkers.BI.G2.inhibited.1, biomarkers.BI.G2.inhibited.2) No common nodes biomarkers.BI.G2.inhibited = c(biomarkers.BI.G2.inhibited.1, biomarkers.BI.G2.inhibited.2) Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-G2&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.G2.active, biomarkers.BI.G2.inhibited) PI-D1 synergy The fourth use case will contrast the models that predicted the synergy set PI-D1,JN-D1 vs the models that predicted the single synergy JN-D1, the models that predicted the synergy set BI-PI,BI-D1,PI-D1 vs the models that predicted the synergy subset BI-PI,BI-D1 and the models that predicted the synergy set BI-D1,BI-G2,PI-D1 vs the models that predicted the synergy subset BI-D1,BI-G2. These three comparisons will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PI-D1 synergy: synergy.set.str.1 = &quot;PI-D1,JN-D1&quot; synergy.subset.str.1 = &quot;JN-D1&quot; diff.PI.D1.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;BI-PI,BI-D1,PI-D1&quot; synergy.subset.str.2 = &quot;BI-PI,BI-D1&quot; diff.PI.D1.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) synergy.set.str.3 = &quot;BI-D1,BI-G2,PI-D1&quot; synergy.subset.str.3 = &quot;BI-D1,BI-G2&quot; diff.PI.D1.3 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.3, synergy.subset.str.3, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.2, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.3, &quot;) vs Bad Models (&quot;, synergy.subset.str.3, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.3, layout = nice.layout, title = title.text) As we see from the above graphs, each comparison produces different biomarkers for the PI-D1 synergy. In order to capture the biomarkers as shown in the above graphs we will lower the significance threshold to \\(0.6\\). We report the active biomarkers found from the three comparisons and merge them to a common result: biomarkers.PI.D1.active.1 = diff.PI.D1.1[diff.PI.D1.1 &gt; 0.6] pretty_print_vector_names(biomarkers.PI.D1.active.1) 3 nodes: MTOR, AKT2, PIK3CA biomarkers.PI.D1.active.2 = diff.PI.D1.2[diff.PI.D1.2 &gt; 0.6] pretty_print_vector_names(biomarkers.PI.D1.active.2) 2 nodes: BRAF, CCND1 biomarkers.PI.D1.active.3 = diff.PI.D1.3[diff.PI.D1.3 &gt; 0.6] pretty_print_vector_names(biomarkers.PI.D1.active.3) 3 nodes: MTOR, PI3K, PIK3CG biomarkers.PI.D1.active.common.1.3 = get_common_names(biomarkers.PI.D1.active.1, biomarkers.PI.D1.active.3) 1 node: MTOR biomarkers.PI.D1.active = c(biomarkers.PI.D1.active.1, biomarkers.PI.D1.active.2, biomarkers.PI.D1.active.3) biomarkers.PI.D1.active = biomarkers.PI.D1.active[unique(names(biomarkers.PI.D1.active))] Note that the MTOR node had already been identified as a biomarker with the previous method. For the inhibited biomarkers, we lower a little more the threshold to \\(0.59\\) in order to capture as many biomarkers as possible, since most of them are close to the \\(0.6\\) threshold and we don’t want to exlude them for such a small difference: biomarkers.PI.D1.inhibited.1 = diff.PI.D1.1[diff.PI.D1.1 &lt; -0.59] pretty_print_vector_names(biomarkers.PI.D1.inhibited.1) 6 nodes: SH3RF1, PTPN1, ROR2, PHLPP1, MAML1, MAP2K1 biomarkers.PI.D1.inhibited.2 = diff.PI.D1.2[diff.PI.D1.2 &lt; -0.59] pretty_print_vector_names(biomarkers.PI.D1.inhibited.2) 4 nodes: CHUK, POU5F1, BMI1, AKT3 biomarkers.PI.D1.inhibited.3 = diff.PI.D1.3[diff.PI.D1.3 &lt; -0.59] pretty_print_vector_names(biomarkers.PI.D1.inhibited.3) 0 nodes: biomarkers.PI.D1.inhibited.common.1.2 = get_common_names(biomarkers.PI.D1.inhibited.1, biomarkers.PI.D1.inhibited.2) No common nodes biomarkers.PI.D1.inhibited = c(biomarkers.PI.D1.inhibited.1, biomarkers.PI.D1.inhibited.2) Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;PI-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.PI.D1.active, biomarkers.PI.D1.inhibited) PI-JN synergy The fifth use case will contrast the models that predicted the synergy set PI-JN,PI-D1 vs the models that predicted the single synergy PI-D1 as well as the models that predicted the synergy set PI-JN,JN-D1 vs the models that predicted the single synergy JN-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PI-JN synergy: synergy.set.str.1 = &quot;PI-JN,PI-D1&quot; synergy.subset.str.1 = &quot;PI-D1&quot; diff.PI.JN.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;PI-JN,JN-D1&quot; synergy.subset.str.2 = &quot;JN-D1&quot; diff.PI.JN.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.JN.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.JN.2, layout = nice.layout, title = title.text) As we see from the above graphs, each comparison produces different biomarkers for the PI-JN synergy. We report the active biomarkers found from the two comparisons and check whether there were any common nodes found: biomarkers.PI.JN.active.1 = diff.PI.JN.1[diff.PI.JN.1 &gt; threshold] pretty_print_vector_names(biomarkers.PI.JN.active.1) 17 nodes: MAP3K11, FGFR1, TAB1, CASP3, STAT3, EGFR, PTPN7, MAX, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1 biomarkers.PI.JN.active.2 = diff.PI.JN.2[diff.PI.JN.2 &gt; threshold] pretty_print_vector_names(biomarkers.PI.JN.active.2) 1 node: MTOR biomarkers.PI.JN.active.common.1.2 = get_common_names(biomarkers.PI.JN.active.1, biomarkers.PI.JN.active.2) No common nodes biomarkers.PI.JN.active = c(biomarkers.PI.JN.active.1, biomarkers.PI.JN.active.2) So, since there were no common active biomarkers we merged the results into one. The inhibited biomarkers found by the two comparisons are: biomarkers.PI.JN.inhibited.1 = diff.PI.JN.1[diff.PI.JN.1 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.JN.inhibited.1) 5 nodes: DLX5, NR3C1, MAPK14, RPS6KA5, DUSP1 biomarkers.PI.JN.inhibited.2 = diff.PI.JN.2[diff.PI.JN.2 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.JN.inhibited.2) 0 nodes: biomarkers.PI.JN.inhibited = biomarkers.PI.JN.inhibited.1 Since the second comparison does not identify any inhibited biomarkers at the \\(0.7\\) threshold level, we use the inhibited biomarkers found from the first comparison. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;PI-JN&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.PI.JN.active, biomarkers.PI.JN.inhibited) PI-P5 synergy The sixth use case will contrast the models that predicted the synergy set BI-D1,BI-G2,PI-P5 vs the models that predicted the synergy subset BI-D1,BI-G2 as well as the models that predicted the synergy set BI-PI,BI-D1,BI-G2,PI-P5 vs the models that predicted the synergy subset BI-PI,BI-D1,BI-G2. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PI-P5 synergy: synergy.set.str.1 = &quot;BI-D1,BI-G2,PI-P5&quot; synergy.subset.str.1 = &quot;BI-D1,BI-G2&quot; diff.PI.P5.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;BI-PI,BI-D1,BI-G2,PI-P5&quot; synergy.subset.str.2 = &quot;BI-PI,BI-D1,BI-G2&quot; diff.PI.P5.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.P5.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.P5.2, layout = nice.layout, title = title.text) Observing the above graphs we see that the second comparison produces more refined/specific biomarkers than the first. We report the active biomarkers found from the two comparisons and we prune the result to the common nodes: biomarkers.PI.P5.active.1 = diff.PI.P5.1[diff.PI.P5.1 &gt; threshold] pretty_print_vector_names(biomarkers.PI.P5.active.1) 19 nodes: MAP3K7, MAP2K6, MAP2K3, NLK, IKBKG, AKT1, BRCA1, PRKACA, TTC3, IRS1, PIK3CA, PI3K, PIK3CG, JAK2, CSF2RA, APOA1, SYK, MAP4K1, VAV1 biomarkers.PI.P5.active.2 = diff.PI.P5.2[diff.PI.P5.2 &gt; threshold] pretty_print_vector_names(biomarkers.PI.P5.active.2) 4 nodes: IRS1, JAK2, CSF2RA, APOA1 biomarkers.PI.P5.active.common.1.2 = get_common_names(biomarkers.PI.P5.active.1, biomarkers.PI.P5.active.2) 4 nodes: IRS1, JAK2, CSF2RA, APOA1 biomarkers.PI.P5.active = biomarkers.PI.P5.active.1[names(biomarkers.PI.P5.active.1) %in% names(biomarkers.PI.P5.active.2)] The inhibited biomarkers found by the two comparisons are: biomarkers.PI.P5.inhibited.1 = diff.PI.P5.1[diff.PI.P5.1 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.P5.inhibited.1) 9 nodes: DAB2IP, PPP1CA, AR, CHEK1, RARA, SH3RF1, PTPN1, IRAK1, LCK biomarkers.PI.P5.inhibited.2 = diff.PI.P5.2[diff.PI.P5.2 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.P5.inhibited.2) 0 nodes: biomarkers.PI.P5.inhibited = biomarkers.PI.P5.inhibited.1 Since the second comparison does not identify any inhibited biomarkers at the \\(0.7\\) threshold level, we use the inhibited biomarkers found from the first comparison. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;PI-P5&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.PI.P5.active, biomarkers.PI.P5.inhibited) JN-D1 synergy The seventh use case will contrast the models that predicted the synergy set PI-D1,JN-D1 vs the models that predicted the single synergy subset PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra JN-D1 synergy: synergy.set.str = &quot;PI-D1,JN-D1&quot; synergy.subset.str = &quot;PI-D1&quot; diff.JN.D1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.JN.D1, layout = nice.layout, title = title.text) and report the active biomarkers found: biomarkers.JN.D1.active = diff.JN.D1[diff.JN.D1 &gt; threshold] pretty_print_vector_names(biomarkers.JN.D1.active) 17 nodes: MAP3K11, FGFR1, TAB1, CASP3, STAT3, EGFR, PTPN7, MAX, SOCS3, TGFB1, HSPA1A, SALL4, ROCK1, TGFBR1, TRAF6, RHOA, PIK3R1 The inhibited biomarkers are: biomarkers.JN.D1.inhibited = diff.JN.D1[diff.JN.D1 &lt; -threshold] pretty_print_vector_names(biomarkers.JN.D1.inhibited) 5 nodes: DLX5, NR3C1, MAPK14, RPS6KA5, DUSP1 We note that using the previous method we had identified exactly the same inhibited biomarkers while for the active ones only a subset of them are found using the synergy-set comparison method. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;JN-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.JN.D1.active, biomarkers.JN.D1.inhibited) D1-P5 synergy The eighth use case will contrast the models that predicted the synergy set PI-D1,D1-P5 vs the models that predicted the single synergy subset PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra D1-P5 synergy: synergy.set.str = &quot;PI-D1,D1-P5&quot; synergy.subset.str = &quot;PI-D1&quot; diff.D1.P5 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.D1.P5, layout = nice.layout, title = title.text) We note that this is almost the same picture we get with the previous method only now some nodes have become less important and so we get only a subset of the biomarkers we found before. We will lower the significance threshold to \\(0.6\\) in order to capture as many biomarkers as possible. First, we report the active biomarkers found: biomarkers.D1.P5.active = diff.D1.P5[diff.D1.P5 &gt; 0.6] pretty_print_vector_names(biomarkers.D1.P5.active) 10 nodes: AKT1, BRCA1, PRKACA, TTC3, JAK2, CSF2RA, APOA1, SYK, MAP4K1, VAV1 The inhibited biomarkers are: biomarkers.D1.P5.inhibited = diff.D1.P5[diff.D1.P5 &lt; -0.6] pretty_print_vector_names(biomarkers.D1.P5.inhibited) 7 nodes: DAB2IP, PPP1CA, AR, CHEK1, RARA, IRAK1, LCK Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;D1-P5&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.D1.P5.active, biomarkers.D1.P5.inhibited) Biomarker results In this section, we will compare the biomarkers found per predicted synergy for this particular cell line as well as the performance biomarkers (notated as PERF in the heatmap below) which were found using the common results from the TP and MCC classification-based model analysis: # Biomarkers from sections: # `Synergy-prediction based analysis`, `Synergy-set prediction based analysis` biomarkers.synergy.res = get_synergy_biomarkers_from_dir(predicted.synergies, biomarkers.dir, models.dir) # store biomarkers in one file save_df_to_file(biomarkers.synergy.res, file = paste0(biomarkers.dir, &quot;biomarkers_per_synergy&quot;)) # Biomarkers from section: # `Performance-related biomarkers` biomarkers.res = add_row_to_ternary_df(df = biomarkers.synergy.res, values.pos = biomarkers.perf.active, values.neg = biomarkers.perf.inhibited, row.name = &quot;PERF&quot;) # prune nodes which are not found as biomarkers for any predicted synergy or # for better model performance biomarkers.res = prune_columns_from_df(biomarkers.res, value = 0) # define a coloring biomarkers.col.fun = colorRamp2(c(-1, 0, 1), c(&quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;)) biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.res), col = biomarkers.col.fun, column_title = paste0(&quot;Biomarker results (&quot;, cell.line, &quot;)&quot;), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = &quot;Predicted synergies&quot;, row_order = nrow(biomarkers.res):1, column_dend_height = unit(1, &quot;inches&quot;), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 7), row_names_side = &quot;left&quot;, heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) So, in general we observe that: A total of 57 nodes were found as biomarkers (for at least one synergy) We found a lot of biomarkers for some synergies, but very few for some others. Usually we wouldn’t expect too many biomarkers that are directly related to the prediction of a specific synergy. The abudance of (false positive) biomarkers for some synergies (e.g. PI-JN) relates to the model classification method used, which does not incorporate in its internal logic that the prediction of other synergies than the ones used for the grouping itself can affect the biomarker results obtained from it All the performance-related biomarkers (PERF) were also observed as biomarkers for the prediction of a specific synergy(ies) There exist common biomarkers across different predicted synergies, e.g.  PIK3CA is a common active biomarker across 4 synergistic drug combinations The results between the different synergies don’t correlate in all cases: e.g.  for the BI-G2 synergy the nodes BRAF and CCND1 were found as more inhibited whereas for the PI-D1 synergy they were found as more active. "],
["mda-mb-468-model-analysis.html", "MDA-MB-468 Model Analysis Input Performance Statistics Biomarker analysis", " MDA-MB-468 Model Analysis This chapter includes the ensemble model analysis performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). All these models were trained towards a specific steady state signaling pattern that was derived based on input data (gene expression, CNV) for the MDA-MB-468 cell line, (Breast adenocarcinoma, a breast cancer), the use of the PARADIGM software (Vaske et al. 2010) and a topology that was build for simulating a cancer cell fate decision network. The input for the simulations and the output data are in the cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input We will define the name of the cell line which must match the name of the directory that has the input files inside the cell-lines-2500 directory. Our analysis in this chapter will be done on the data for the MDA-MB-468 cell line: cell.line = &quot;MDA-MB-468&quot; data.dir = paste0(getwd(), &quot;/&quot;, cell.line, &quot;/&quot;) Three inputs are used in this analysis: The model_predictions file which has for each model the prediction for each drug combination tested (0 = no synergy predicted, 1 = synergy predicted, NA = couldn’t find stable states in either the drug combination inhibited model or in any of the two single-drug inhibited models) The observed_synergies file which lists the drug combinations that were observed as synergistic for the particular cell line. The models directory, which is the same as the models directory produced by Gitsbe and has one .gitsbe file per model that includes this info: The stable state of the boolean model. Note that a model can have 1 stable state or none in our simulations - but the models used in this analysis have been selected through a genetic evolution algorithm in Gitsbe and so in the end, only those with 1 stable state have higher fitness values and remain in the later generations. Higher fitness here means a better match of a model’s stable state to the cell line derived steady state (a perfect match would result in a fitness of 1) The boolean equations of the model models.stable.state.file = paste0(data.dir, &quot;models_stable_state&quot;) observed.synergies.file = paste0(data.dir, &quot;observed_synergies&quot;) model.predictions.file = paste0(data.dir, &quot;model_predictions&quot;) models.equations.file = paste0(data.dir, &quot;models_equations&quot;) models.dir = paste0(data.dir, &quot;models&quot;) Now, we parse the data into proper R objects. First the synergy predictions per model: model.predictions = get_model_predictions(model.predictions.file) # Example: first model&#39;s synergy predictions (first 12 drug combinations) pretty_print_vector_names_and_values(model.predictions[1,], n = 12) 5Z-AK: 0, 5Z-BI: 0, 5Z-CT: 0, 5Z-PD: 1, 5Z-PI: 0, 5Z-PK: 0, 5Z-JN: 0, 5Z-D1: 0, 5Z-60: 0, 5Z-SB: 0, 5Z-RU: 0, 5Z-D4: 0 So, the model.predictions object has the models as rows and each column is a different drug combination that was tested in our simulations. drug.combinations.tested = colnames(model.predictions) models = rownames(model.predictions) nodes = get_node_names(models.dir) number.of.drug.comb.tested = length(drug.combinations.tested) number.of.models = length(models) number.of.nodes = length(nodes) print_model_and_drug_stats(number.of.drug.comb.tested, number.of.models, number.of.nodes, html.output = TRUE) Drug combinations tested: 153Number of models: 7500Number of nodes: 139 Next, we get the full stable state and the equations per model: models.stable.state = as.matrix( read.table(file = models.stable.state.file, check.names = FALSE) ) # Example: first model&#39;s stable state (first 12 nodes) pretty_print_vector_names_and_values(models.stable.state[1,], n = 12) MAP3K7: 1, MAP2K6: 1, MAP2K3: 1, NLK: 1, MAP3K4: 1, MAP2K4: 1, IKBKG: 1, IKBKB: 1, AKT1: 0, BRAF: 1, SMAD3: 1, DAB2IP: 1 The rows of the models.stable.state object represent the models while its columns are the names of the nodes (proteins, genes, etc.) of the cancer cell network under study. So, each model has one stable state which means that in every model, the nodes in the network have reached a state of either 0 (inhibition) or 1 (activation). models.equations = as.matrix( read.table(file = models.equations.file, check.names = FALSE) ) # Example: first model&#39;s link operators (first 12 nodes) pretty_print_vector_names_and_values(models.equations[1,], n = 12) MAP3K4: 1, MAP2K4: 0, IKBKB: 1, AKT1: 0, SMAD3: 1, GSK3B: 1, RAF1: 1, GAB2: 1, CTNNB1: 0, NR3C1: 1, CREB1: 0, RAC1: 1 For the models.equations, if we look at a specific row (a model so to speak), the columns (node names) correspond to the targets of regulation (and the network has been built so that every node is a target - i.e. it has other nodes activating and/or inhibiting it). The general form of a boolean equation is: general.equation = &quot;Target *= (Activator OR Activator OR...) AND NOT (Inhibitor OR Inhibitor OR...)&quot; pretty_print_bold_string(general.equation) Target *= (Activator OR Activator OR…) AND NOT (Inhibitor OR Inhibitor OR…) The difference between the models’ boolean equations is the link operator (OR NOT/AND NOT) which has been mutated (changed) through the evolutionary process of the genetic algorithm in Gitsbe. For example, if a model has for the column ERK_f (of the models.equations object) a value of 1, the correspoding equation is: ERK_f *= (MEK_f) OR NOT ((DUSP6) OR PPP1CA). A value of 0 would correspond to the same equation but having AND NOT as the link operator: ERK_f *= (MEK_f) AND NOT ((DUSP6) OR PPP1CA). Note that the equations that do not have link operators (meaning that they are the same for every model) are discarded (so less columns in this dataset) since in a later section we study only the equations whose link operators differentiate between the models. Lastly, the synergies observed for this particular cell line are: observed.synergies = get_observed_synergies( observed.synergies.file, drug.combinations.tested) number.of.observed.synergies = length(observed.synergies) pretty_print_vector_values(observed.synergies, vector.values.str = &quot;observed synergies&quot;) 14 observed synergies: AK-BI, JN-D1, PI-D1, PI-D4, BI-JN, PI-JN, BI-P5, D1-P5, G4-P5, PD-P5, PI-P5, AK-PI, BI-PI, CT-PI Performance Statistics It will be interesting to know the percentage of the above observed synergies that were actually predicted by at least one of the models (there might be combinations that no model in our dataset could predict): combinations that no model in our dataset could predict): # Split model.predictions to positive and negative results observed.model.predictions = get_observed_model_predictions(model.predictions, observed.synergies) unobserved.model.predictions = get_unobserved_model_predictions(model.predictions, observed.synergies) stopifnot(ncol(observed.model.predictions) + ncol(unobserved.model.predictions) == number.of.drug.comb.tested) number.of.models.per.observed.synergy = colSums(observed.model.predictions, na.rm = TRUE) predicted.synergies = names(which(number.of.models.per.observed.synergy &gt; 0)) # predicted synergies is a subset of the observed (positive) ones stopifnot(all(predicted.synergies %in% observed.synergies)) pretty_print_vector_values(predicted.synergies, vector.values.str = &quot;predicted synergies&quot;) 5 predicted synergies: BI-PI, PI-JN, PI-D1, JN-D1, D1-P5 predicted.synergies.percentage = 100 * length(predicted.synergies) / number.of.observed.synergies pretty_print_string(paste0(&quot;Percentage of True Positive predicted synergies: &quot;, specify_decimal(predicted.synergies.percentage, 2), &quot;%&quot;)) Percentage of True Positive predicted synergies: 35.71% So, for this particular cell line, there were indeed observed synergies that no model could predict (e.g.  AK-BI, AK-PI). Next, we would like to know the maximum number of observed synergies predicted by one model alone - can one model by itself predict all the true positive synergies predicted by all the models together or do we need many models to capture this diverse synergy landscape? To do that, we go even further and count the number of models that predict a specific set of observed synergies for every possible combination subset of the predicted.synergies object: # Find the number of predictive models for every synergy subset synergy.subset.stats = get_synergy_subset_stats(observed.model.predictions, predicted.synergies) # Bar plot of the number of models for every possible observed synergy combination set # Tweak the threshold.for.subset.removal and bottom.margin as desired make_barplot_on_synergy_subset_stats(synergy.subset.stats, threshold.for.subset.removal = 1, bottom.margin = 9, cell.line) From the above figure (where we excluded sets of synergies that were predicted by no model by setting the threshold.for.subset.removal value to 1) we observe that: More than half of the models predict none of the observed synergies The PI-D1 synergy is the most common predicted synergy for the rest of the models Next we calculate the maximum number of correctly predicted synergies (\\(TP\\) - True Positives) per model: # Count the predictions of the observed synergies per model (TP) models.synergies.tp = calculate_models_synergies_tp(observed.model.predictions) models.synergies.tp.stats = table(models.synergies.tp) # Bar plot of number of models vs correctly predicted synergies make_barplot_on_models_stats(models.synergies.tp.stats, cell.line, title = &quot;True Positive Synergy Predictions&quot;, xlab = &quot;Number of maximum correctly predicted synergies&quot;, ylab = &quot;Number of models&quot;) To summarize: There were 59 models that predicted 3 synergies - the set PI-JN,PI-D1,JN-D1 - which is the maximum number of predicted synergies by an individual model No model could predict all 5 of the total predicted synergies The power of the ensemble model approach lies in the fact that (as we saw from the above figures) even though we may not have individual super models that can predict many observed drug combinations, there are many that predict at least one and which will be used by the drug response analysis module (Drabme) to better infer the synergistic drug combinations. It goes without saying though, that the existance of models that could predict more than a handful of synergies would be beneficial for any approach that performs drug response analysis on a multitude of models. Biomarker analysis Intro-Methods Now, we want to investigate and find possible important nodes - biomarkers - whose activity state either distinguishes good performance models from less performant ones (in terms of a performance metric - e.g. the true positive synergies predicted) or makes some models predict a specific synergy compared to others that can’t (but could predict other synergies). So, we devised two strategies to split the models in our disposal to good and bad ones (but not necessarily all of them), the demarcation line being either a performance metric (the number of \\(TP\\) or the Matthews Correlation Coefficient score) or the prediction or not of a specific synergy. Then, for each group of models (labeled as either good or bad) we find the average activity state of every node in the network (value between 0 and 1) and then we compute the average state difference for each node between the two groups: \\(\\forall i\\in nodes,mean(state_i)_{good} - mean(state_i)_{bad}\\). Our hypothesis is that if the absolute value of these average differences are larger than a user-defined threshold (e.g. 0.7) for a small number of nodes (the less the better) while for the rest of the nodes they remain close to zero, then the former nodes are considered the most important since they define the difference between the average bad model and the average good one in that particular case study. We will also deploy a network visualization method to observe these average differences. True Positives-based analysis Using our first strategy, we will split the models based on the number of true positive predictions. For example, the bad models will be the ones that predicted 0 \\(TP\\) synergies whereas the good models will be the ones that predicted 2 \\(TP\\) (we will denote the grouping as \\((0,2)\\)). This particular classification strategy will be used for every possible combination of the number of \\(TP\\) as given by the models.synergies.tp.stats object and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: diff.tp.results = get_avg_activity_diff_mat_based_on_tp_predictions( models, models.synergies.tp, models.stable.state) tp.densities = apply(abs(diff.tp.results), 1, density) make_multiple_density_plot(tp.densities, legend.title = &quot;True Positives&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) What we are actually looking for is density plots that are largely skewed to the right (so the average absolute differences of these nodes are close to zero) while there are a few areas of non-zero densities which are as close to 1 as possible. So, from the above graph, the density plots that fit this description are the ones marked as \\((1,3)\\) and \\((2,3)\\). We will visualize the nodes’ average state differences in a network graph (Csardi and Nepusz 2006), where the color of each node will denote how much more inhibited or active that node is, in the average good model vs the average bad one. The color of the edges will denote activation (green) or inhibition (red). We first build the network from the node topology (edge list): parent.dir = get_parent_dir(data.dir) topology.file = paste0(parent.dir, &quot;/topology&quot;) coordinates.file = paste0(parent.dir, &quot;/network_xy_coordinates&quot;) net = construct_network(topology.file, models.dir) # a static layout for plotting the same network always (igraph) # nice.layout = layout_nicely(net) nice.layout = as.matrix(read.table(coordinates.file)) In the next colored graphs we can identify the important nodes whose activity state can influence the true positive prediction performance (from 0 true positive synergies to a total of 3): plot_avg_state_diff_graph(net, diff.tp.results[&quot;(0,3)&quot;,], layout = nice.layout, title = &quot;Bad models (0 TP) vs Good models (3 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(1,3)&quot;,], layout = nice.layout, title = &quot;Bad models (1 TP) vs Good models (3 TP)&quot;) plot_avg_state_diff_graph(net, diff.tp.results[&quot;(2,3)&quot;,], layout = nice.layout, title = &quot;Bad models (2 TP) vs Good models (3 TP)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to the number of true positive synergies that they predict. Comparing the graphs above, we observe that there exist common nodes that maintain the same significant influence in all of the graphs. We set the threshold for the absolute significance level in average state differences to \\(0.7\\). A node will be marked as a biomarker (active or inhibited) if its activity state difference surpassed the aforementioned threshold (positively or negatively) for any of the tested groups (e.g. 2 \\(TP\\) vs 3 \\(TP\\)). So, the nodes that have to be in a more active state are: biomarkers.tp.active = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.tp.active) 11 nodes: DAB2IP, PPP1CA, AR, CHEK1, GAB2, RARA, IRAK1, MAP3K11, PTEN, PPM1A, LCK Also, the nodes that have to be in a more inhibited state are: biomarkers.tp.inhibited = get_biomarkers_per_type( diff.tp.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.tp.inhibited) 10 nodes: AKT1, BRCA1, DLX5, PRKACA, TTC3, CREB1, PTK2, SYK, MAP4K1, VAV1 We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.tp = get_common_values(biomarkers.tp.active, biomarkers.tp.inhibited) No common nodes MCC classification-based analysis The previous method to split the models based on the number of true positive predictions is a good metric for absolute performance but a very restricted one since it ignores the other values of the confusion matrix for each model (true negatives, false positives, false negatives). Also, since our dataset is imbalanced in the sense that out of the total drug combinations tested only a few of them are observed as synergistic (and in a hypothetical larger drug screening evaluation it will be even less true positives) we will now devise a method to split the models into different performance categories based on the value of the Matthews Correlation Coefficient (MCC) score which takes into account the balance ratios of all the four confusion matrix values: # Calculate Matthews Correlation Coefficient (MCC) for every model models.mcc = calculate_models_mcc(observed.model.predictions, unobserved.model.predictions, number.of.drug.comb.tested) models.mcc.stats = table(models.mcc, useNA = &quot;ifany&quot;) make_barplot_on_models_stats(models.mcc.stats, cell.line, title = &quot;MCC scores&quot;, xlab = &quot;MCC value&quot;, ylab = &quot;Number of models&quot;, cont.values = TRUE, threshold = 10) Note that for presentation purposes in the figure above, we pruned some MCC-bars with lower model frequency values. We observe that: There are no relatively bad models (MCC values close to -1) Most of the models (exluding the NaN category) perform a little better than random prediction (\\(MCC&gt;0\\)) There are models that had NaN value for the MCC score Given the MCC formula: \\(MCC = (TP\\cdot TN - FP\\cdot FN)/\\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}\\), we can see that the MCC value can be NaN because of zero devision. Two of the four values in the denominator represent the number of positive \\((TP+FN)\\) and negative \\((TN+FP)\\) observations which are non-zero for every model, since they correspond to the observed and non-obsered synergies in each case. The case where both \\(TN\\) and \\(FN\\) are zero is rare (if non-existent) because of the imbalanced dataset (large proportion of negatives) and the reason that logical models which report no negatives means that they should find fixpoint attractors for every possible drug combination perturbation which also is extremely unlikely. We can actually see that the NaN are produced by models that have both TP and FP equal to zero: models.synergies.fp = calculate_models_synergies_fp(unobserved.model.predictions) pretty_print_string(sum(models.synergies.tp + models.synergies.fp == 0)) 1076 Since these models could intentify no synergies (either correctly or wrongly), we decided to put them as the lowest performant category in our MCC-based analysis. To classify the models based on their MCC score (which takes values in the \\([-1, 1]\\) interval, NaN values excluded), we will perform a univariate k-means clustering to split the previously found MCC values to different classes (Wang and Song 2011). The MCC classification is presented with a histogram: num.of.classes = 5 mcc.class.ids = 1:num.of.classes models.mcc.no.nan = models.mcc[!is.nan(models.mcc)] models.mcc.no.nan.sorted = sort(models.mcc.no.nan) # find the clusters res = Ckmeans.1d.dp(x = models.mcc.no.nan.sorted, k = num.of.classes) models.cluster.ids = res$cluster plot_mcc_classes_hist(models.mcc.no.nan.sorted, models.cluster.ids, num.of.classes, mcc.class.ids) Note that in total we have 6 MCC classes, since the NaN MCC values constitute a class on its own. Following our first strategy, we will split the models based on the MCC performance metric score. For example, the bad models will be the ones that had a NaN MCC score \\((TP+FP = 0)\\) whereas the good models will be the ones that had an MCC score belonging to the first MCC class as seen in the histogram above. This particular classification strategy will be used for every possible combination of the MCC classes and the density estimation of the nodes’ average state differences in each case will be ploted in a common graph: # add NaN class (if applicable) if (sum(is.nan(models.mcc)) &gt; 0) { mcc.class.ids = append(mcc.class.ids, values = NaN, after = 0) } mcc.class.id.comb = t(combn(1:length(mcc.class.ids), 2)) diff.mcc.results = apply(mcc.class.id.comb, 1, function(comb) { return(get_avg_activity_diff_based_on_mcc_clustering( models.mcc, models.stable.state, mcc.class.ids, models.cluster.ids, class.id.low = comb[1], class.id.high = comb[2])) }) mcc.classes.comb.names = apply(mcc.class.id.comb, 1, function(comb) { return(paste0(&quot;(&quot;, mcc.class.ids[comb[1]], &quot;,&quot;, mcc.class.ids[comb[2]], &quot;)&quot;)) }) colnames(diff.mcc.results) = mcc.classes.comb.names diff.mcc.results = t(diff.mcc.results) mcc.densities = apply(abs(diff.mcc.results), 1, density) make_multiple_density_plot(mcc.densities, legend.title = &quot;MCC classes&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;, legend.size = 0.7) Many of the density plots above are of interest to us, since they are right skewed. Next, we visualize the average state differences with our network coloring method for 2 of the above cases, in order to identify the important nodes whose activity state can influence the prediction performance based on the MCC classification: plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(NaN,4)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: NaN) vs Good models (MCC Class: 4)&quot;) plot_avg_state_diff_graph(net, diff.mcc.results[&quot;(1,4)&quot;,], layout = nice.layout, title = &quot;Bad models (MCC Class: 1) vs Good models (MCC Class: 4)&quot;) We will now list the important nodes that affect the models’ prediction performance with regards to their MCC classification, using the same method as in the True Positives-based analysis section. First, the nodes that have to be in a more active state: biomarkers.mcc.active = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;positive&quot; ) pretty_print_vector_values(biomarkers.mcc.active) 16 nodes: RAF1, PtsIns(3,4,5)P3, PI3K, PIK3CG, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, SGK3, PRKCB, PRKCG, PAK1 Secondly, the nodes that have to be in a more inhibited state: biomarkers.mcc.inhibited = get_biomarkers_per_type( diff.mcc.results, threshold = 0.7, type = &quot;negative&quot; ) pretty_print_vector_values(biomarkers.mcc.inhibited) 9 nodes: STAT3, SOCS3, TGFB1, HSPA1A, SALL4, TGFBR1, TRAF6, RHOA, PIK3R1 We check if there are nodes found by our method as biomarkers in both active and inhibited states: common.biomarkers.mcc = get_common_values(biomarkers.mcc.active, biomarkers.mcc.inhibited) No common nodes Performance-related biomarkers Comparing the two methods we used for the classification of the models’ prediction performance (TP and MCC), we observe that there exist no common biomarkers in either active or inhibited state cases: common.biomarkers.mixed.1 = get_common_values(biomarkers.mcc.active, biomarkers.tp.inhibited) No common nodes common.biomarkers.mixed.2 = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.active) No common nodes biomarkers.perf.active = get_common_values(biomarkers.mcc.active, biomarkers.tp.active) No common nodes biomarkers.perf.inhibited = get_common_values(biomarkers.mcc.inhibited, biomarkers.tp.inhibited) No common nodes We believe that the MCC score better captures the performance categories within our imbalanced dataset so we will use the results from the MCC analysis as the performance biomarkers. Lastly, we will save these performance-related biomarkers for further analysis and comparison with the results from all the different cell lines: biomarkers.dir = paste0(data.dir, &quot;biomarkers/&quot;) biomarkers.perf.active = biomarkers.mcc.active biomarkers.perf.inhibited = biomarkers.mcc.inhibited save_vector_to_file(vector = biomarkers.perf.active, file = paste0(biomarkers.dir, &quot;biomarkers_active&quot;)) save_vector_to_file(vector = biomarkers.perf.inhibited, file = paste0(biomarkers.dir, &quot;biomarkers_inhibited&quot;)) Equation-based analysis It will be interesting to see the different patterns in the form of the boolean equations (regarding the mutation of the link operator as mentioned in the Input section) when comparing higher performance models vs the low performant ones. We could also check if any of the biomarkers found above relate to a different link operator on average between models with different performance characteristics (e.g. higher predictive models should have the OR NOT as the link operator in a boolean equation where a specific biomarker is the regulation target) or if they constitute targets of exclusively activating nodes or inhibiting ones (an equation with no link operator). The performance metric we will first use to sort the models is the number of true positive predictions. We will now illustrate the heatmap of the models.equations object raw-order by the number of \\(TP\\) predictions: # order based on number of true positives models.synergies.tp.sorted = sort(models.synergies.tp) models.sorted = names(models.synergies.tp.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring eq.link.colors = c(&quot;red&quot;, &quot;lightyellow&quot;) eq.link.col.fun = colorRamp2(breaks = c(0, 1), colors = eq.link.colors) tp.values = sort(unique(models.synergies.tp)) tp.col.fun = colorRamp2(breaks = c(min(tp.values), max(tp.values)), colors = c(&quot;red&quot;, &quot;green&quot;)) # color biomarker names in the heatmap bottom.nodes.colors = rep(&quot;black&quot;, length(colnames(models.equations.sorted))) names(bottom.nodes.colors) = colnames(models.equations.sorted) bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.active] = &quot;blue&quot; bottom.nodes.colors[names(bottom.nodes.colors) %in% biomarkers.perf.inhibited] = &quot;magenta&quot; # define the TP color bar tp.annot = rowAnnotation( tp = anno_simple(x = models.synergies.tp.sorted, col = tp.col.fun), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (TP sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = tp.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 3 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) tp.values = min(tp.values):max(tp.values) # maybe some integers are missing tp.legend = Legend(at = tp.values, title = &quot;TP&quot;, legend_gp = gpar(fill = tp.col.fun(tp.values))) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, tp.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the heatmap above, an equation whose link operator is AND NOT is represented with red color while an OR NOT link operator is represented with light yellow color. The targets whose equations do not have a link operator are not represented. The rows are ordered by the number of true positive predictions (ascending). We have colored the names of the network nodes that were also found as biomarkers (green color is used for the active biomarkers and red color for the inhibited biomarkers). We observe that: Most of the biomarkers are nodes that do not have both activators and inhibitors and so are absent from the above heatmap There doesn’t seem to exist a pattern between the models’ link operators and their corresponding performance (at least not for all of the nodes) when using the true positive predictions as a classifier for the models There exist a lot of target nodes that need to have the OR NOT link operator in their respective boolean equation in order for the corresponding logical model to show a higher number of true positive predictions. By assigning the OR NOT link operator to a target’s boolean regulation equation, we allow more flexibility to the target’s output active result state - meaning that the inhibitors play less role and the output state has a higher probability of being active - compared to assigning the AND NOT link operator to the equation We will also illustrate the heatmap of the models.equations object raw-order by the MCC score which is a better performance classifier. Models who had a NaN MCC score will be again placed in the lower performant category: # order based on the MCC value models.mcc.sorted = sort(models.mcc, na.last = FALSE) models.sorted = names(models.mcc.sorted) models.equations.sorted = models.equations[models.sorted, ] # coloring mcc.col.fun = colorRamp2(breaks = c(min(models.mcc.no.nan), max(models.mcc.no.nan)), colors = c(&quot;red&quot;, &quot;green&quot;)) # define the MCC color bar mcc.annot = rowAnnotation( mcc = anno_simple(x = models.mcc.sorted, col = mcc.col.fun, na_col = &quot;black&quot;), show_annotation_name = FALSE) heatmap.eq = Heatmap(matrix = models.equations.sorted, column_title = &quot;Models Link Operators&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Models (MCC sorted)&quot;, cluster_rows = FALSE, show_row_names = FALSE, show_heatmap_legend = FALSE, column_dend_height = unit(1, &quot;inches&quot;), col = eq.link.col.fun, column_names_gp = gpar(fontsize = 9, col = bottom.nodes.colors), left_annotation = mcc.annot, use_raster = TRUE, raster_device = &quot;png&quot;, raster_quality = 10) # define the 4 legends link.op.legend = Legend(title = &quot;Link Operator&quot;, labels = c(&quot;AND&quot;, &quot;OR&quot;), legend_gp = gpar(fill = eq.link.colors)) mcc.legend = Legend(title = &quot;MCC&quot;, col_fun = mcc.col.fun) na.legend = Legend(labels = &quot;NA&quot;, legend_gp = gpar(fill = &quot;black&quot;)) biomarkers.legend = Legend(title = &quot;Biomarkers&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), legend_gp = gpar(fill = c(&quot;magenta&quot;, &quot;blue&quot;))) legend.list = packLegend(link.op.legend, mcc.legend, na.legend, biomarkers.legend, direction = &quot;vertical&quot;) draw(heatmap.eq, annotation_legend_list = legend.list, annotation_legend_side = &quot;right&quot;) In the MCC-ordered heatmap above we observe that there is better correlation between the boolean equations’ link operators and the performance of a model compared to the \\(TP\\) classification. For example, the biomarkers STAT3 and RAF1 show distinguished patterns for the higher performance models (use of AND NOT and OR NOT link operators respectively) when the models are sorted by the MCC score. Synergy-prediction based analysis We will now use the second strategy to split the models, based on whether they predict a specific observed synergy or not. This will allow us to find biomarkers that affect the prediction of a specific synergy. For example, the good models could be the ones that predicted the hypothetical synergy A-B while the bad models all the rest that identified the particular combination as non-synergistic. In another case scenario, the good models could be those that predicted a triple synergy set A-B,C-D,A-C, while the bad models could be the ones that predicted the double synergy subset A-B,C-D (excluding the common models that predicted both the triple synergy set and subsequently its given subset). In such a case scenario, we want to find out which nodes are responsible for making the good models predict the extra synergy - in this hypothetical case the synergy A-C - demonstrating thus better model performance. Note that the models selected in each case as good or bad, could have predicted other synergies as well (correctly as \\(TP\\) or wrongly as \\(FP\\)) which means that the biomarker selection method could be somewhat innacurate, since we can’t really know the prediction of which extra synergy or synergies the biomarkers’ state affected. To account for this, we label as good models those that predict large synergy sets (so fewer models) which capture almost all the true positive predictions and also minimize the possible extra different synergies predicted by models of the same classification category (e.g. the good models). Starting with the first model classification method (prediction vs non-prediction of a particular synergy), we generate the density distribution of the nodes’ average state differences between the good and bad models for each predicted synergy: diff.predicted.synergies.results = sapply(predicted.synergies, function(drug.comb) { get_avg_activity_diff_based_on_specific_synergy_prediction( model.predictions, models.stable.state, drug.comb) }) diff.predicted.synergies.results = t(diff.predicted.synergies.results) densities = apply(abs(diff.predicted.synergies.results), 1, density) make_multiple_density_plot(densities, legend.title = &quot;Predicted Synergies&quot;, x.axis.label = &quot;Activity state (absolute difference value)&quot;, title = &quot;Density Estimation for the Average State Difference&quot;) Next, we will plot the biomarkers with the network visualization method (for all predicted synergies) and output the respective biomarkers in each case. The biomarker results for each predicted synergy will be stored for further comparison with the results from the other cell lines. threshold = 0.7 for (drug.comb in predicted.synergies) { diff = diff.predicted.synergies.results[drug.comb, ] biomarkers.active = diff[diff &gt; threshold] biomarkers.inhibited = diff[diff &lt; -threshold] save_vector_to_file(vector = biomarkers.active, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_active&quot;), with.row.names = TRUE) save_vector_to_file(vector = biomarkers.inhibited, file = paste0( biomarkers.dir, drug.comb, &quot;_biomarkers_inhibited&quot;), with.row.names = TRUE) } threshold = 0.7 for (drug.comb in predicted.synergies) { title.text = paste0(&quot;Prediction of &quot;, drug.comb, &quot; synergy: Good models vs Bad Models&quot;) diff = diff.predicted.synergies.results[drug.comb, ] plot_avg_state_diff_graph(net, diff, layout = nice.layout, title = title.text) } print_biomarkers_per_predicted_synergy(biomarkers.dir, predicted.synergies) Biomarkers for BI-PI synergy predictionActive biomarkers6 nodes: NR3C1, GSK3A, MAPK14, RPS6KA5, DUSP1, PIK3CAInhibited biomarkers9 nodes: MAP2K4, FGFR1, TAB1, CASP3, PTPN7, MAX, GATA6, JNK, ROCK1Biomarkers for PI-JN synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: Biomarkers for PI-D1 synergy predictionActive biomarkers15 nodes: PtsIns(3,4,5)P3, PI3K, PIK3CG, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, SGK3, PRKCB, PRKCG, PAK1Inhibited biomarkers0 nodes: Biomarkers for JN-D1 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: Biomarkers for D1-P5 synergy predictionActive biomarkers0 nodes: Inhibited biomarkers0 nodes: We notice that for some predicted synergies the above method identified zero biomarkers. We will now study cases where the main goal is the better identification and/or refinement of the biomarkers responsible for allowing the models to predict one extra synergy from a specific synergy set. If we find biomarkers for a predicted synergy using this strategy, we compare them to the ones already found with the previous method and if none of them is common we just add the new ones to the list of biomarkers for that specific synergy. On the other hand, if the synergy-set comparison method identifies a subset of the previously found biomarkers for a specific synergy (one common node at least), we will only keep the later method’s biomarkers since we believe that the synergy-set prediction based method is more accurate at identifying biomarkers for a specific synergy because of the fewer models involved in each contrasting category which also minimizes the total false positive synergy predictions taken into account. Note that if the second method finds even more biomarkers than the first, we have the option to prune the end result to only the common biomarkers between the two methods. We will focus our analysis on the predicted synergies PI-JN, JN-D1, D1-P5, PI-D1 and BI-PI. Synergy-set prediction based analysis PI-JN synergy The first use case will contrast the models that predicted the synergy set PI-JN,JN-D1 vs the models that predicted the single synergy JN-D1 as well as the models that predicted the synergy set PI-JN,PI-D1 vs the models that predicted the single synergy PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PI-JN synergy: synergy.set.str.1 = &quot;PI-JN,JN-D1&quot; synergy.subset.str.1 = &quot;JN-D1&quot; diff.PI.JN.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;PI-JN,PI-D1&quot; synergy.subset.str.2 = &quot;PI-D1&quot; diff.PI.JN.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.JN.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.JN.2, layout = nice.layout, title = title.text) As we see from the above graphs, each comparison produces different biomarkers for the PI-JN synergy. Note that with the previous method where we contrasted the models that predict the PI-JN synergy vs those that don’t, we weren’t able to identify not even one biomarker. We report the active biomarkers found from the two comparisons and check whether there were any common nodes found: biomarkers.PI.JN.active.1 = diff.PI.JN.1[diff.PI.JN.1 &gt; threshold] pretty_print_vector_names(biomarkers.PI.JN.active.1) 16 nodes: PtsIns(3,4,5)P3, PI3K, PIK3CG, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1 biomarkers.PI.JN.active.2 = diff.PI.JN.2[diff.PI.JN.2 &gt; threshold] pretty_print_vector_names(biomarkers.PI.JN.active.2) 9 nodes: DAB2IP, PPP1CA, AR, CHEK1, GAB2, RARA, IRAK1, MAP3K11, LCK biomarkers.PI.JN.active.common.1.2 = get_common_names(biomarkers.PI.JN.active.1, biomarkers.PI.JN.active.2) No common nodes biomarkers.PI.JN.active = c(biomarkers.PI.JN.active.1, biomarkers.PI.JN.active.2) So, since there were no common active biomarkers we merged the results into one. The inhibited biomarkers found by the two comparisons are: biomarkers.PI.JN.inhibited.1 = diff.PI.JN.1[diff.PI.JN.1 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.JN.inhibited.1) 0 nodes: biomarkers.PI.JN.inhibited.2 = diff.PI.JN.2[diff.PI.JN.2 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.JN.inhibited.2) 8 nodes: AKT1, BRCA1, DLX5, PRKACA, TTC3, SYK, MAP4K1, VAV1 biomarkers.PI.JN.inhibited = biomarkers.PI.JN.inhibited.2 Since the first comparison does not identify any inhibited biomarkers at the \\(0.7\\) threshold level, we use the inhibited biomarkers found from the second comparison. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;PI-JN&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.PI.JN.active, biomarkers.PI.JN.inhibited) JN-D1 synergy The second use case will contrast the models that predicted the synergy set PI-JN,JN-D1 vs the models that predicted the single synergy PI-JN as well as the models that predicted the synergy set PI-D1,JN-D1 vs the models that predicted the single synergy PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra JN-D1 synergy: synergy.set.str.1 = &quot;PI-JN,JN-D1&quot; synergy.subset.str.1 = &quot;PI-JN&quot; diff.JN.D1.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;PI-D1,JN-D1&quot; synergy.subset.str.2 = &quot;PI-D1&quot; diff.JN.D1.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.JN.D1.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.JN.D1.2, layout = nice.layout, title = title.text) As we see from the above graphs, each comparison produces different biomarkers for the JN-D1 synergy. Note that with the previous method where we contrasted the models that predict the JN-D1 synergy vs those that don’t, we weren’t able to identify not even one biomarker. We report the active biomarkers found from the two comparisons and check whether there were any common nodes found: biomarkers.JN.D1.active.1 = diff.JN.D1.1[diff.JN.D1.1 &gt; threshold] pretty_print_vector_names(biomarkers.JN.D1.active.1) 23 nodes: GAB2, AKT3, PPARG, MAP2K2, PtsIns(3,4,5)P3, PI3K, PIK3CG, JAK2, CSF2RA, APOA1, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1 biomarkers.JN.D1.active.2 = diff.JN.D1.2[diff.JN.D1.2 &gt; threshold] pretty_print_vector_names(biomarkers.JN.D1.active.2) 9 nodes: DAB2IP, PPP1CA, AR, CHEK1, GAB2, RARA, IRAK1, MAP3K11, LCK biomarkers.JN.D1.active.common.1.2 = get_common_names(biomarkers.JN.D1.active.1, biomarkers.JN.D1.active.2) 1 node: GAB2 biomarkers.JN.D1.active = c(biomarkers.JN.D1.active.1, biomarkers.JN.D1.active.2) biomarkers.JN.D1.active = biomarkers.JN.D1.active[unique(names(biomarkers.JN.D1.active))] Since there was just one common node, we merged the results and removed the duplicated node. The inhibited biomarkers found by the two comparisons are: biomarkers.JN.D1.inhibited.1 = diff.JN.D1.1[diff.JN.D1.1 &lt; -threshold] pretty_print_vector_names(biomarkers.JN.D1.inhibited.1) 0 nodes: biomarkers.JN.D1.inhibited.2 = diff.JN.D1.2[diff.JN.D1.2 &lt; -threshold] pretty_print_vector_names(biomarkers.JN.D1.inhibited.2) 8 nodes: AKT1, BRCA1, DLX5, PRKACA, TTC3, SYK, MAP4K1, VAV1 biomarkers.JN.D1.inhibited.common.1.2 = get_common_names(biomarkers.JN.D1.inhibited.1, biomarkers.JN.D1.inhibited.2) No common nodes biomarkers.JN.D1.inhibited = biomarkers.JN.D1.inhibited.2 Since the first comparison does not identify any inhibited biomarkers at the \\(0.7\\) threshold level, we use the inhibited biomarkers found from the second comparison. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;JN-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.JN.D1.active, biomarkers.JN.D1.inhibited) D1-P5 synergy The third use case will contrast the models that predicted the synergy set PI-D1,D1-P5 vs the models that predicted the single synergy PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra D1-P5 synergy: synergy.set.str = &quot;PI-D1,D1-P5&quot; synergy.subset.str = &quot;PI-D1&quot; diff.D1.P5 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.D1.P5, layout = nice.layout, title = title.text) Sadly, no biomarkers were found at the \\(0.7\\) threshold in either active or inhibited states: biomarkers.D1.P5.active = diff.D1.P5[diff.D1.P5 &gt; threshold] pretty_print_vector_names(biomarkers.D1.P5.active) 0 nodes: biomarkers.D1.P5.inhibited = diff.D1.P5[diff.D1.P5 &lt; -threshold] pretty_print_vector_names(biomarkers.D1.P5.inhibited) 0 nodes: PI-D1 synergy The fourth use case will contrast the models that predicted the synergy set PI-D1,D1-P5 vs the models that predicted the single synergy D1-P5 as well as the models that predicted the synergy set PI-D1,JN-D1 vs the models that predicted the single synergy JN-D1 and the models that predicted the synergy set PI-JN,PI-D1 vs the models that predicted the single synergy PI-JN. These three comparisons will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra PI-D1 synergy: synergy.set.str.1 = &quot;PI-D1,D1-P5&quot; synergy.subset.str.1 = &quot;D1-P5&quot; diff.PI.D1.1 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.1, synergy.subset.str.1, model.predictions, models.stable.state) synergy.set.str.2 = &quot;PI-D1,JN-D1&quot; synergy.subset.str.2 = &quot;JN-D1&quot; diff.PI.D1.2 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.2, synergy.subset.str.2, model.predictions, models.stable.state) synergy.set.str.3 = &quot;PI-JN,PI-D1&quot; synergy.subset.str.3 = &quot;PI-JN&quot; diff.PI.D1.3 = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str.3, synergy.subset.str.3, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str.1, &quot;) vs Bad Models (&quot;, synergy.subset.str.1, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.1, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.2, &quot;) vs Bad Models (&quot;, synergy.subset.str.2, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.2, layout = nice.layout, title = title.text) title.text = paste0(&quot;Good models (&quot;, synergy.set.str.3, &quot;) vs Bad Models (&quot;, synergy.subset.str.3, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.PI.D1.3, layout = nice.layout, title = title.text) As we see from the above graphs, each comparison produces different biomarkers for the PI-D1 synergy. We note that the two last comparisons have almost the same results as with the previous method where we contrasted the models that predict the PI-D1 synergy vs those that don’t. We report the active biomarkers found from the three comparisons and check whether there were any common nodes found: biomarkers.PI.D1.active.1 = diff.PI.D1.1[diff.PI.D1.1 &gt; threshold] pretty_print_vector_names(biomarkers.PI.D1.active.1) 10 nodes: FGFR1, TAB1, CASP3, PTPN7, MAX, JNK, MAPK8, APP, SIRT1, ROCK1 biomarkers.PI.D1.active.2 = diff.PI.D1.2[diff.PI.D1.2 &gt; threshold] pretty_print_vector_names(biomarkers.PI.D1.active.2) 16 nodes: PtsIns(3,4,5)P3, PI3K, PIK3CG, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1 biomarkers.PI.D1.active.3 = diff.PI.D1.3[diff.PI.D1.3 &gt; threshold] pretty_print_vector_names(biomarkers.PI.D1.active.3) 23 nodes: GAB2, AKT3, PPARG, MAP2K2, PtsIns(3,4,5)P3, PI3K, PIK3CG, JAK2, CSF2RA, APOA1, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1 biomarkers.PI.D1.active.common.2.3 = get_common_names(biomarkers.PI.D1.active.2, biomarkers.PI.D1.active.3) 16 nodes: PtsIns(3,4,5)P3, PI3K, PIK3CG, RPS6K, PDPK1, RPS6KB1, PLK1, RPS6KA3, PRKCD, PRKCZ, PKN1, PRKCA, SGK3, PRKCB, PRKCG, PAK1 biomarkers.PI.D1.active.common.1.2 = get_common_names(biomarkers.PI.D1.active.1, biomarkers.PI.D1.active.2) No common nodes biomarkers.PI.D1.active = c(biomarkers.PI.D1.active.1, biomarkers.PI.D1.active.2) So, as the active biomarkers for this synergy we took the common biomarkers from comparisons 2 and 3 and merged them with the ones from the first comparison (since there were no common nodes). The inhibited biomarkers found from the three comparisons are: biomarkers.PI.D1.inhibited.1 = diff.PI.D1.1[diff.PI.D1.1 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.D1.inhibited.1) 6 nodes: NR3C1, MAPK14, RPS6KA5, DUSP1, PIK3CA, LAT biomarkers.PI.D1.inhibited.2 = diff.PI.D1.1[diff.PI.D1.2 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.D1.inhibited.2) 0 nodes: biomarkers.PI.D1.inhibited.3 = diff.PI.D1.3[diff.PI.D1.3 &lt; -threshold] pretty_print_vector_names(biomarkers.PI.D1.inhibited.3) 0 nodes: biomarkers.PI.D1.inhibited = biomarkers.PI.D1.inhibited.1 Since the second and third comparison did not identify any inhibited biomarkers at the \\(0.7\\) threshold level, we use the inhibited biomarkers found from the first comparison. Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;PI-D1&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.PI.D1.active, biomarkers.PI.D1.inhibited) BI-PI synergy The fifth use case will contrast the models that predicted the synergy set BI-PI,PI-D1 vs the models that predicted the single synergy PI-D1. This will allow us to find important nodes whose state can influence the prediction performance of a model and make it predict the extra BI-PI synergy: synergy.set.str = &quot;BI-PI,PI-D1&quot; synergy.subset.str = &quot;PI-D1&quot; diff.BI.PI = get_avg_activity_diff_based_on_synergy_set_cmp( synergy.set.str, synergy.subset.str, model.predictions, models.stable.state) We now visualize the average state differences: title.text = paste0(&quot;Good models (&quot;, synergy.set.str, &quot;) vs Bad Models (&quot;, synergy.subset.str, &quot;)&quot;) plot_avg_state_diff_graph(net, diff.BI.PI, layout = nice.layout, title = title.text) The above graph gives us a better image of the nodes necessary for the prediction of this synergy than the graph where we compared all the models who predicted this syenrgy vs the ones that did not. We report the active biomarkers found in this case: biomarkers.BI.PI.active = diff.BI.PI[diff.BI.PI &gt; threshold] pretty_print_vector_names(biomarkers.BI.PI.active) 6 nodes: NR3C1, GSK3A, MAPK14, RPS6KA5, DUSP1, PIK3CA The inhibited biomarkers are: biomarkers.BI.PI.inhibited = diff.BI.PI[diff.BI.PI &lt; -threshold] pretty_print_vector_names(biomarkers.BI.PI.inhibited) 8 nodes: FGFR1, TAB1, CASP3, PTPN7, MAX, GATA6, JNK, ROCK1 Lastly, we update the biomarkers for this specific synergy in the respective file: drug.comb = &quot;BI-PI&quot; update_biomarker_files(biomarkers.dir, drug.comb, biomarkers.BI.PI.active, biomarkers.BI.PI.inhibited) Biomarker results In this section, we will compare the biomarkers found per predicted synergy for this particular cell line as well as the performance biomarkers (notated as PERF in the heatmap below) which are based on the results from the MCC classification-based model analysis: # Biomarkers from sections: # `Synergy-prediction based analysis`, `Synergy-set prediction based analysis` biomarkers.synergy.res = get_synergy_biomarkers_from_dir(predicted.synergies, biomarkers.dir, models.dir) # store biomarkers in one file save_df_to_file(biomarkers.synergy.res, file = paste0(biomarkers.dir, &quot;biomarkers_per_synergy&quot;)) # Biomarkers from section: # `Performance-related biomarkers` biomarkers.res = add_row_to_ternary_df(df = biomarkers.synergy.res, values.pos = biomarkers.perf.active, values.neg = biomarkers.perf.inhibited, row.name = &quot;PERF&quot;) # prune nodes which are not found as biomarkers for any predicted synergy or # for better model performance biomarkers.res = prune_columns_from_df(biomarkers.res, value = 0) # define a coloring biomarkers.col.fun = colorRamp2(c(-1, 0, 1), c(&quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;)) biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.res), col = biomarkers.col.fun, column_title = paste0(&quot;Biomarker results (&quot;, cell.line, &quot;)&quot;), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = &quot;Predicted synergies&quot;, row_order = nrow(biomarkers.res):1, column_dend_height = unit(1, &quot;inches&quot;), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 7), row_names_side = &quot;left&quot;, heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) So, in general we observe that: A total of 67 nodes were found as biomarkers (for at least one synergy) Most synergies have more than 10 biomarkers. Usually we wouldn’t expect too many biomarkers that are directly related to the prediction of a specific synergy. The abudance of (false positive) biomarkers for some synergies (e.g. PI-D1) relates to the model classification method used, which does not incorporate in its internal logic that the prediction of other synergies than the ones used for the grouping itself can affect the biomarker results obtained from it We couldn’t identify any biomarkers at the \\(0.7\\) threshold for the D1-P5 synergy All the active performance-related biomarkers (PERF) were also observed as biomarkers for the prediction of a specific synergy(ies) with the exception of the RAF1 node There exist common biomarkers across different predicted synergies, e.g. SGK3 is a common active biomarker across 3 synergistic drug combinations We observe that between the two predicted synergies PI-D1 and BI-PI there are conflicted biomarkers in the sense that they have to be in an more active state for the first synergy and more inhibited for the other (and vise versa) The synergies JN-D1, PI-D1 and PI-JN share many common biomarkers as well as with the performance-related biomarkers "],
["biomarker-comparison.html", "Biomarker comparison Input Random Model Analysis Performance Biomarkers Observed synergies Synergy Biomarkers", " Biomarker comparison In this chapter we will compare the biomarker results from 8 different cell lines. These results were obtained through an ensemble model analysis, which was performed on the models generated by the Gitsbe module when running the DrugLogics computational pipeline for finding synergistic drug combinations (drug pairs). The models in each different cell line setup were trained towards a specific signaling activity profile matching the activity state of that particular cell line. For more info about the cell line specific model &amp; biomarker analysis, see the respective chapters: A498 Model Analysis AGS Model Analysis DU145 Model Analysis Colo205 Model Analysis SW620 Model Analysis SF295 Model Analysis UACC62 Model Analysis MDA-MB-468 Model Analysis Note that the biomarkers identified in the aforementioned chapters, were classified as: Performance-related biomarkers, which represent important nodes that are essential for our models to achieve a higher model performance classification (the methodology was based on the number of true positives (\\(TP\\)) and the Matthews Correlation Coefficient score (\\(MCC\\)) Per synergy predicted biomarkers, which represent important nodes that are essential for our models to predict some of the synergies that were observed in the lab In each category, the biomarkers can be either in an active state or in an inhibited state. The input for the simulations and the output data are in the cell-lines-2500 directory (the 2500 number denotes the number of simulations executed). The analysis will be presented step by step in the sections below. Input Firstly, we define the necessary input (cell line names, directories and files of interest, etc.): cell.lines = c(&quot;A498&quot;, &quot;AGS&quot;, &quot;DU145&quot;, &quot;colo205&quot;, &quot;SW620&quot;, &quot;SF295&quot;, &quot;UACC62&quot;, &quot;MDA-MB-468&quot;) cell.line.dirs = sapply(cell.lines, function(cell.line) { paste0(getwd(), &quot;/&quot;, cell.line) }) biomarkers.dirs = sapply(cell.line.dirs, function(cell.line.dir) { paste0(cell.line.dir, &quot;/biomarkers&quot;) }) observed.synergies.files = sapply(cell.line.dirs, function(cell.line.dir) { paste0(cell.line.dir, &quot;/observed_synergies&quot;) }) # get the drug combinations tested model.predictions.file = paste0(cell.line.dirs[1], &quot;/model_predictions&quot;) model.predictions = get_model_predictions(model.predictions.file) drug.combos = colnames(model.predictions) # get the node names (same topology for all cell lines) models.dir = paste0(cell.line.dirs[1], &quot;/models&quot;) node.names = get_node_names(models.dir) Random Model Analysis In this section we provide a fast way to obtain the results regarding the random (or topology-based) model analysis, which is the same for all cell lines: these models were generated while trained/fitted to a general cell proliferation phenotype. By changing the observed synergies per different cell line and using the general analysis functions offered by the emba R package, we can easily get the analysis raw results (without extra refinements that were done in each subsequent per cell-line model analysis). First, some further input: random.dir = paste0(getwd(), &quot;/random&quot;) random.model.predictions = get_model_predictions(paste0(random.dir, &quot;/model_predictions&quot;)) random.models.stable.state = as.matrix( read.table(file = paste0(random.dir, &quot;/models_stable_state&quot;), check.names = FALSE) ) observed.synergies.per.cell.line = sapply(observed.synergies.files, function(file) { get_observed_synergies(file) } ) For the performance-related biomarker analysis, we use the MCC classification as the default strategy for splitting the models to different performance classes. # Performance Biomarkers for cell proliferation models random.mcc.analysis.res = lapply(observed.synergies.per.cell.line, function(observed.synergies) { biomarker_mcc_analysis(random.model.predictions, random.models.stable.state, models.link.operator = NULL, observed.synergies, threshold = 0.6, num.of.mcc.classes = 5, include.NaN.mcc.class = FALSE )}) # Synergy Biomarkers for cell proliferation models random.synergy.analysis.res = lapply(observed.synergies.per.cell.line, function(observed.synergies) { biomarker_synergy_analysis(random.model.predictions, random.models.stable.state, models.link.operator = NULL, observed.synergies, threshold = 0.6)}) Performance Biomarkers Next, we will visualize the performance biomarkers found from the cell-specific and random model analysis combined (per cell line): # Cell-specific performance biomarkers biomarkers.perf.res.cell.specific = get_perf_biomarkers_per_cell_line(biomarkers.dirs, node.names) # Random models performance biomarkers biomarkers.perf.res.random = as.data.frame(matrix(data = NA, nrow = 0, ncol = length(node.names))) colnames(biomarkers.perf.res.random) = node.names for (cell.line in cell.lines) { biomarkers.perf.res.random = add_row_to_ternary_df(df = biomarkers.perf.res.random, values.pos = random.mcc.analysis.res[[cell.line]][[&quot;biomarkers.mcc.active&quot;]], values.neg = random.mcc.analysis.res[[cell.line]][[&quot;biomarkers.mcc.inhibited&quot;]], row.name = cell.line) } # Combine results biomarkers.perf.res = as.data.frame(matrix(data = NA, nrow = 0, ncol = length(node.names))) colnames(biomarkers.perf.res) = node.names count = 0 for (cell.line in cell.lines) { for (node.name in node.names) { cell.spec.value = biomarkers.perf.res.cell.specific[cell.line, node.name] random.value = biomarkers.perf.res.random[cell.line, node.name] diff = cell.spec.value - random.value if (diff != 2) biomarkers.perf.res[cell.line, node.name] = cell.spec.value + random.value else # diff == 2, e.g. (1 vs -1) or (-1 vs 1) { biomarkers.perf.res[cell.line, node.name] = random.value count = count + 1 } } } # remove nodes which are not biomarkers for any cell line biomarkers.perf.res = prune_columns_from_df(biomarkers.perf.res, value = 0) Note that when a performance biomarker was found at the same state (active or inhibited) in both the random and the cell-specific analyses, a value of \\(2\\) or \\(-2\\) respectively was kept in the final result. If a biomarker was reported as active/inhibited by one analysis but not as a biomarker in the other, we keep it as a biomarker nonetheless in the state specified in one of the two analyses. Lastly, if the results are complete opposites - meaning that a common biomarker was found for a cell line in different states in the two analyses (we have 4 cases only of this), we keep the state of that biomarker as it is reported by the cell-specific analysis (which was a bit more subtle and elaborate). # define a coloring biomarkers.col.fun = colorRamp2(c(-2,-1, 0, 1,2), c(&quot;red&quot;, &quot;tomato&quot;, &quot;grey&quot;, &quot;gold&quot;, &quot;yellow&quot;)) perf.biomarkers.heatmap = Heatmap(matrix = as.matrix(biomarkers.perf.res), col = biomarkers.col.fun, column_title = &quot;Performance biomarkers per cell line&quot;, column_title_gp = gpar(fontsize = 20), row_title = &quot;Cell Lines&quot;, row_title_side = &quot;left&quot;, row_dend_side = &quot;right&quot;, row_names_side = &quot;left&quot;, column_names_gp = gpar(fontsize = 5), rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), heatmap_legend_param = list(at = c(-2, -1, 1, 2), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited (Cell-specific+Random)&quot;, &quot;Inhibited&quot;, &quot;Active&quot;, &quot;Active (Cell-specific+Random)&quot;), color_bar = &quot;discrete&quot;, ncol = 2, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;)) draw(perf.biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) Across all cell lines, a total of 94 performance biomarkers were found The three gastrointestinal cell lines (AGS,SW620,colo205) have a lot of common biomarkers. These common biomarkers between the cell lines can be in either the same activity state (SW620 vs AGS) or the reverse (SW620 vs colo205) In general the biomarker results are different between the different type of cell lines There exist unique biomarkers per cell line which are not shared with any of the other cell lines We save the cell-specific and random model analysis results separately: save_df_to_file(df = biomarkers.perf.res.cell.specific, file = &quot;perf_biomarkers_per_cell_line&quot;) save_df_to_file(df = biomarkers.perf.res.random, file = &quot;./random/perf_biomarkers_per_cell_line&quot;) Observed synergies Each of the cell lines studied has a different set of observed synergies (drug combinations that were found synergistic across all the 153 tested ones). In this section, we will visualize the cell lines’ observed synergies and mark the synergies that were also predicted by the cell-specific models and the random-generated ones. First, we get the biomarkers for these synergies from each cell line: synergy.biomarkers.cell.specific = get_synergy_biomarkers_per_cell_line(biomarkers.dirs) total.predicted.synergies.cell.specific = unique(unlist(sapply(synergy.biomarkers.cell.specific, function(df) { rownames(df) }))) total.predicted.synergies.cell.specific.num = length(total.predicted.synergies.cell.specific) The same for the random models: synergy.biomarkers.random = sapply(cell.lines, function(cell.line) { random.synergy.analysis.res[[cell.line]][[&#39;activity.biomarkers&#39;]] }, simplify = FALSE) total.predicted.synergies.random = unique(unlist(sapply(synergy.biomarkers.random, function(df) { rownames(df) }))) total.predicted.synergies.random.num = length(total.predicted.synergies.random) Then, we get the observed synergies from each cell line: observed.synergies.res = get_observed_synergies_per_cell_line(cell.line.dirs, drug.combos) # remove drug combinations which are not observed in any of the cell lines observed.synergies.res = prune_columns_from_df(observed.synergies.res, value = 0) total.observed.synergies = colnames(observed.synergies.res) total.observed.synergies.num = length(total.observed.synergies) Lastly, we visualize the observed and predicted synergies for all cell lines in one heatmap: # color the cell-specific predicted synergies predicted.synergies.colors = rep(&quot;black&quot;, total.observed.synergies.num) names(predicted.synergies.colors) = total.observed.synergies common.predicted.synergies = intersect(total.predicted.synergies.cell.specific, total.predicted.synergies.random) cell.specific.only.predicted.synergies = total.predicted.synergies.cell.specific[!total.predicted.synergies.cell.specific %in% total.predicted.synergies.random] random.only.predicted.synergies = total.predicted.synergies.random[!total.predicted.synergies.random %in% total.predicted.synergies.cell.specific] predicted.synergies.colors[total.observed.synergies %in% common.predicted.synergies] = &quot;blue&quot; predicted.synergies.colors[total.observed.synergies %in% cell.specific.only.predicted.synergies] = &quot;orange&quot; predicted.synergies.colors[total.observed.synergies %in% random.only.predicted.synergies] = &quot;purple&quot; # define a coloring obs.synergies.col.fun = colorRamp2(c(0, 1), c(&quot;red&quot;, &quot;green&quot;)) observed.synergies.heatmap = Heatmap(matrix = as.matrix(observed.synergies.res), col = obs.synergies.col.fun, column_title = &quot;Observed synergies per cell line&quot;, column_title_gp = gpar(fontsize = 20), column_names_gp = gpar(col = predicted.synergies.colors), row_title = &quot;Cell Lines&quot;, row_title_side = &quot;left&quot;, row_dend_side = &quot;right&quot;, row_names_side = &quot;left&quot;, rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), heatmap_legend_param = list(at = c(1, 0), labels = c(&quot;YES&quot;, &quot;NO&quot;), color_bar = &quot;discrete&quot;, title = &quot;Observed&quot;, direction = &quot;vertical&quot;)) lgd = Legend(at = c(&quot;Cell-specific&quot;, &quot;Random&quot;, &quot;Both&quot;), title = &quot;Predicted&quot;, legend_gp = gpar(fill = c(&quot;orange&quot;, &quot;purple&quot;, &quot;blue&quot;))) draw(observed.synergies.heatmap, heatmap_legend_list = list(lgd), heatmap_legend_side = &quot;right&quot;) The cell-specific models predicted 12 of the 40 observed synergies found across the 8 cell lines, whereas the random models predicted 11 of the them. Thus, the total true positive coverage for all the models across all cell lines is 0.325% Note that there exist synergies which were observed in all cell lines (AK-BI, PI-D1) BI-JN is an observed synergy across almost all cell lines and only the cell-specific models could predict it. The synergies PD-G2 and AK-PD in the A498 cell line were identified only by the random and cell-specific models respectively (and these synergies were observed in no other cell line). This shows us that a complimentary approach is needed when searching for biomarkers as the two different kind of models (trained to a specific activity state profile vs trained to proliferation) although they share common true positives regarding the synergies they predict, there are also synergies only a specific class of models could predict. Synergy Biomarkers In this section, we will produce heatmaps showing the biomarkers across the 8 cell lines for every observed synergy that was also predicted by the cell-specific and/or random models. First, we manipulate the biomarker result data to fit our purposes: synergy.biomarkers.cell.specific.res = ldf_arrange_by_rownames(synergy.biomarkers.cell.specific) synergy.biomarkers.random.res = ldf_arrange_by_rownames(synergy.biomarkers.random) synergy.biomarkers.res = synergy.biomarkers.cell.specific.res for (synergy in names(synergy.biomarkers.random.res)) { df = synergy.biomarkers.random.res[[synergy]] if (!is.null(df) &amp;&amp; ncol(df) &gt; 0) { row.df = df[1, ] # models do not differ per cell line so biomarkers are the same for all rows rownames(row.df) = &quot;Random&quot; if (synergy %in% names(synergy.biomarkers.res)) { synergy.biomarkers.res[[synergy]] = rbind(synergy.biomarkers.res[[synergy]], row.df) } else { synergy.biomarkers.res[[synergy]] = row.df } } } # For every synergy, remove cell lines (or the Random-specific analysis results) # that didn&#39;t predict the observed synergies at all or for which we couldn&#39;t # find any biomarkers (row pruning). # Also remove nodes which are not biomarkers for any cell line (column pruning) for (synergy in names(synergy.biomarkers.res)) { df = synergy.biomarkers.res[[synergy]] df = prune_columns_from_df(df, value = 0) df = prune_rows_from_df(df, value = 0) synergy.biomarkers.res[[synergy]] = df } # re-order result list based on increasing number of rows (cell lines) synergy.biomarkers.res = synergy.biomarkers.res[ names(sort(sapply(synergy.biomarkers.res, function(x) { nrow(x) }))) ] Next, we produce the biomarker heatmaps (one per synergy predicted) found from the cell-specific and/or random models. The synergy biomarkers found from the random-models are not cell-line specific, so they are depicted as Random Cell Lines/rows in the subsequent heatmaps. If the Random row is missing for a particular synergy, then either the random models didn’t predicted it (AK-PD and BI-JN cases) or no biomarkers were found (e.g. PD-PI). Also, note that in the case of the synergy PD-G2 there are no cell line names because the cell-specific models didn’t predict it (in any cell line). for (synergy in names(synergy.biomarkers.res)) { biomarkers.res = as.matrix(synergy.biomarkers.res[[synergy]]) # customize some parameters heatmap.height = ifelse(nrow(biomarkers.res) &lt; 3, 1, 3) show.column.dend = ifelse(nrow(biomarkers.res) == 1, FALSE, TRUE) row.title = ifelse(nrow(biomarkers.res) == 1, &quot;Cell Line&quot;, &quot;Cell Lines&quot;) biomarkers.heatmap = Heatmap(matrix = biomarkers.res, col = biomarkers.col.fun, column_title = paste0(&quot;Biomarkers for Synergy: &quot;, synergy), column_title_gp = gpar(fontsize = 20, fontface = &quot;bold&quot;), row_title = row.title, row_title_side = &quot;right&quot;, rect_gp = gpar(col = &quot;black&quot;, lwd = 0.3), column_names_gp = gpar(fontsize = 10), show_column_dend = show.column.dend, height = unit(heatmap.height, &quot;inches&quot;), heatmap_legend_param = list(at = c(-1, 1), title = &quot;Activity State&quot;, labels = c(&quot;Inhibited&quot;, &quot;Active&quot;), color_bar = &quot;discrete&quot;, title_position = &quot;leftcenter&quot;, direction = &quot;horizontal&quot;, ncol = 2)) draw(biomarkers.heatmap, heatmap_legend_side = &quot;bottom&quot;) } Last remarks: The main result here is that we observe common biomarkers across many cell lines and in the same activity state for some synergies, which hints that these biomarkers may have a pan-cancer diagnostic value. There are fewer biomarkers in general found for the random model analysis comparing to the cell-specific models. The biomarker_synergy_analysis general function that was used to find these biomarkers from the random models does not incorporate the synergy-set prediction based analysis that was done for each cell line model analysis (and which was used to better identify and/or refine the biomarkers responsible for allowing the models to predict one extra synergy from a specific (observed) synergy set). The random models biomarkers are in most cases found also by the cell-specific models in one or more cell-lines. "],
["r-session-info.html", "R Session Info", " R Session Info For the main R packages that I used in this analysis see: (Wang and Song 2011), (Gu 2019), (Gu, Eils, and Schlesner 2016), (Zobolas 2019b), (Zobolas 2019a). A very useful tutorial about network visualization in R: (Ognyanova 2019) For adding code folding buttons in bookdown::gitbook see (S 2017). I also provide for reproducibity purposes the information about the R session that is used throughout this bookdown document: xfun::session_info() R version 3.6.1 (2019-07-05) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 18.04.3 LTS Locale: LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C Package version: assertthat_0.2.1 backports_1.1.4 base64enc_0.1.3 BH_1.69.0.1 bibtex_0.4.2 bookdown_0.13 circlize_0.4.8 Ckmeans.1d.dp_4.3.0 cli_1.1.0 clue_0.3-57 cluster_2.1.0 colorspace_1.4-1 compiler_3.6.1 ComplexHeatmap_2.0.0 crayon_1.3.4 digest_0.6.20 dplyr_0.8.3 ellipsis_0.2.0.1 emba_0.1.0 evaluate_0.14 fansi_0.4.0 gbRd_0.4-11 GetoptLong_0.1.7 GlobalOptions_0.1.0 glue_1.3.1 graphics_3.6.1 grDevices_3.6.1 grid_3.6.1 highr_0.8 htmltools_0.3.6 htmlwidgets_1.3 igraph_1.2.4.1 jsonlite_1.6 knitr_1.24 lattice_0.20.38 magrittr_1.5 markdown_1.1 Matrix_1.2.17 methods_3.6.1 mime_0.7 parallel_3.6.1 pillar_1.4.2 pkgconfig_2.0.2 plogr_0.2.0 png_0.1-7 purrr_0.3.2 R6_2.4.0 RColorBrewer_1.1-2 Rcpp_1.0.2 Rdpack_0.11-0 rje_1.10.10 rjson_0.2.20 rlang_0.4.0 rmarkdown_1.15 shape_1.4.4 stats_3.6.1 stringi_1.4.3 stringr_1.4.0 tibble_2.1.3 tidyselect_0.2.5 tinytex_0.16 tools_3.6.1 usefun_0.4.0 utf8_1.1.4 utils_3.6.1 vctrs_0.2.0 visNetwork_2.0.8 xfun_0.9 yaml_2.2.0 zeallot_0.1.0 "],
["references.html", "References", " References "]
]
